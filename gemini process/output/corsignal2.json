[
{
  "job_url": "https://www.linkedin.com/jobs/view/consultant-data-at-up-advisory-4201012831",
  "titre": "consultant data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-04",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "description du poste nous recherchons un.e consultant.e amoa data, vous interviendrez principalement sur des projets de transformation digitale et d'optimisation des processus de gestion des donnees. vos taches quotidiennes incluront la collecte et l'analyse des besoins metiers, la redaction des specifications fonctionnelles, ainsi que la coordination entre les differentes parties prenantes. \n\n\nqualifications\n competences analytiques : capacite a analyser et interpreter des donnees complexes pour fournir des insights exploitables.\n competences en data science et data analytics : experience dans les techniques de science des donnees et l'analyse des donnees pour resoudre des problemes metier.\n competences en etl et data modeling : maitrise des processus d'extraction, transformation et chargement des donnees, ainsi que de la modelisation des donnees pour structurer efficacement les informations.\n d'autres qualifications appreciees incluent une bonne maitrise des outils de gestion de projet, un fort esprit d'equipe, et une experience avec des outils de visualisation de donnees tels que tableau ou power bi.",
  "company_name": "up advisory",
  "is_data_profile": true,
  "profile": "data consultant",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "sql",
    "python",
    "tableau"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "analysis"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/stage-annee-cesure-commando-market-data-at-societe-generale-4215791490",
  "titre": "stage annee cesure commando market data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-24",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "vos missions au quotidien\n\nvous serez base(e) a casablanca, au sein de la filiale sg africa technologies & services (sg ats).\n\nla mission proposee est de participer a la transformation digitale du departement.\n\nen salle de marche, vous serez amene a travailler avec des experts localises a l'international, afin de prendre part aux\n\ndifferentes activites de production et d'apporter un regard nouveau sur celles-ci.\n\nplus particulierement, vous serez amene a travailler sur differents controles de donnees de marche, ainsi que sur la\n\ngestion de compositions d'indices au sein de la banque, en contact direct avec nos partenaires trading et risque de\n\nmarche.\n\nvous pourriez en outre participer aux developpements d'outils de production afin d'ameliorer la gouvernance de\n\ndonnees de marche.\n\nde plus, vous pourriez etre amene a travailler avec le datalake et a explorer les capacites de machine learning pour\n\nameliorer notre qualite de donnees.\n\nderoule du process de selection :\n\na lissue de votre candidature, vous serez convie(e) a un entretien a distance\n\nstage remunere a partir de juin 2025 dune duree de 6 mois\n\net si cetait vous ?\n\nde formation superieure de type master, grande ecole dingenieurs ou 3eme cycle universitaire,\n\nles competences techniques requises :\n\nmaitrise des instruments derives.\n\nconnaissance des donnees de marche.\n\ncompetences en base de donnees et python obligatoires.\n\nles competences comportementales requises\n\ntres bonne communication.\n\nbon relationnel.\n\nadaptabilite, curiosite, rigoureux.\n\ncapable de travailler dans un environnement en constante evolution.\n\ncapacite danalyse et de prise de recul.\n\npourquoi nous choisir ?\n\ncreee en 2014, sg ats est une filiale du groupe societe generale qui fournit des solutions agiles et efficaces aux salles des marches sg en europe (principalement a paris et londres) afin de les aider a se developper et a repondre aux exigences de plus en plus fortes imposees par les differentes legislations bancaires internationales.\n\nforte de son succes, sg ats fournit aujourd'hui des prestations a forte valeur ajoutee a differentes lignes de metiers du groupe (en europe principalement mais egalement aux etats-unis et en asie) sur des activites de marches, mais egalement a plusieurs directions du groupe societe generale.\n\nsacree  meilleur employeur 2023  maroc  sg ats est une structure jeune, dynamique qui positionne le capital humain au centre de son developpement. sg ats souhaite donc sentourer de talents qui participeront activement a la reussite de lentreprise tout en evoluant dans un environnement international propice au developpement de competences a forte valeur ajoutee. vous serez base a casablanca au sein de la filiale sg africa technologies & services (sgt ats).\n\ndiversite et inclusion\n\nnous sommes un employeur garantissant l'egalite des chances et nous sommes fiers de faire de la diversite une force pour notre entreprise. le groupe sengage a reconnaitre et a promouvoir tous les talents, quels que soient leurs croyances, age, handicap, origine ethnique, nationalite, appartenance a une organisation politique, religieuse, syndicale ou a une minorite, ou toute autre caracteristique qui pourrait faire lobjet dune discrimination.",
  "company_name": "societe generale",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "sql",
    "machine learning"
  ],
  "soft_skills": [
    "communication",
    "adaptability",
    "analysis"
  ],
  "sector": [
    "finance"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-customer-knowledge-at-stellantis-4203343644",
  "titre": "data analyst, customer knowledge",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "company overview\n\n\nbuild your brand. tell your story. take advantage of a rare opportunity to start from the ground up and build something great.\n\n\nstellantis is a leading global automaker and mobility provider that offers clean, connected, affordable and safe mobility solutions. our companys strength lies in the breadth of our iconic brand portfolio, the diversity and passion of our people, and our deep roots in the communities in which we operate. our ambitious electrification and software strategies and the creation of an innovative ecosystem of strategic, game-changing partnerships are driving our transformation to a sustainable mobility tech company.\n\n\nwith industrial operations in nearly 30 countries, stellantis could consistently exceed the evolving needs and expectations of consumers in more than 130 markets, while creating superior value for all stakeholders.\n\n\nwe are looking for technology game changers to lead stellantis into a fundamental transformation within the automotive industry. technology is going to disrupt the automotive industry significantly in the next decade and our organization is seeking high potential candidates to transform the company with a focus on the customer experience. stellantis software organization (swx) was created to build the most captivating experiences in the latest frontier of automotive technology.\n\n\njob overview\nas part of the broader data for engineering initiative - which includes the customer knowledge activity - we are looking for an experienced data analyst. in this role, you will analyze automotive data to uncover customer behavior insights that will directly support our engineering teams in designing the vehicles of tomorrow.\n\n\nresponsibilities\n understanding and translating business needs into data requirements\n ensuring the consistency and representativeness of results through appropriate sample selection\n cleaning, transforming, and processing data from multiple sources (surveys, connected vehicles, instrumented vehicles, infrastructure, weather, etc.)\n implementing data quality checks and monitoring to ensure data accuracy and completeness\n designing, developing, and maintaining scalable data pipelines using spark, sql, and python to generate customer behavior insights\n leveraging the databricks platform to build and manage data processing workflows\n applying statistical methods to ensure the robustness and representativeness of results (e.g., weighting, normalization, and modeling)\n document data pipelines, processes and methodologies clearly and concisely.\n\n\nqualifications\n bachelors degree in computer science, information technology, or a related field (or equivalent experience).\n minimum of 5 years of experience as a data analyst or in a similar role.\n solid understanding of key automotive domains, including powertrain, electric vehicles (ev), and advanced driver-assistance systems (adas)\n strong analytical skills with the ability to understand and translate business needs into data-driven solutions\n experience in data processing and transformation from diverse sources\n strong proficiency in sql, python, and spark.\n hands-on experience with the databricks platform\n good understanding of sampling methodologies\n knowledge of statistical methods\n familiarity with data quality management\n ability to work collaboratively with cross-functional teams (engineering, business, data science)\n excellente communication and collaboration skills.\ndiversity engagement\n\n\nat stellantis, we assess candidates based on qualifications, merit and business needs. we welcome applications from people of all gender identities, age, ethnicity, nationality, religion, sexual orientation and disability. diverse teams will allow us to better meet the evolving needs of our customers and care for our future.\n\n\nwhat we offer\n\n\njoining stellantis means gaining access to a wealth of opportunities and benefits, including:\n\n\nprofessional development: opportunities for ongoing professional development and advancement, ensuring you're always at the forefront of industry trends and innovations.\n\n\nglobal exposure: exposure to a global work environment, where you'll collaborate with colleagues from diverse backgrounds and cultures, broadening your horizons and expanding your network.\n\n\ninclusive culture: an inclusive and collaborative company culture, where every voice is valued and respected, fostering a sense of belonging and camaraderie among our team members.\n\n\nexpert mentorship: mentorship from industry experts who are dedicated to sharing their knowledge and guiding you on your career journey, providing invaluable insights and support along the way.",
  "company_name": "stellantis",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 2,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "analysis"
  ],
  "sector": [
    "automotive"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/architecte-data-senior-env-cloud-et-big-data-at-astorm-group-4206519032",
  "titre": "architecte data senior - env cloud et big data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-10",
  "location": {
    "city": "settat",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "architecte data senior  direction marketing digital & experience client (mea) casablanca, maroc  hybride |  contrat freelance ou cdi longue duree\n a propos du postenous recherchons un architecte data senior passionne, strategique et operationnel, pour piloter larchitecture data dune grande entreprise operant sur lensemble de la region moyen-orient et afrique. ce poste est au cur dune transformation digitale ambitieuse, visant a renforcer lintelligence client, linnovation marketing et la performance des services digitaux.\nvous interviendrez dans un contexte multinationale, a fort impact, en collaboration avec les equipes data, marketing, produits digitaux et dsi.\n vos missions concevoir et faire evoluer larchitecture data : data lake, entrepot de donnees, base operationnelle et analytique.\n modeliser les flux et schemas de donnees (client, comportemental, transactionnel, social, etc.).\n selectionner et mettre en uvre les technologies les plus adaptees pour les traitements de donnees massives.\n garantir la qualite, securite, gouvernance et performance des ecosystemes data.\n piloter des projets complexes darchitecture et dindustrialisation, avec des enjeux strategiques a lechelle regionale.\n coordonner les equipes techniques, data engineers et partenaires, dans un mode agile ou hybride.\n assurer une veille continue sur les technologies et les pratiques du marche.\n stack technique & environnement bases de donnees : sql (postgresql, mysql, oracle), nosql\n etl / elt : talend, informatica, datastage\n big data : hadoop, spark\n cloud : gcp (google cloud platform)\n data virtualisation : starburst\n data science / ia : dataiku\n langages : python, java, scala\n profil recherche bac+5 en informatique, ingenierie des donnees ou discipline connexe\n +5 ans dexperience en architecture data et en gestion de projets data a grande echelle\n maitrise des systemes distribues, des modeles de donnees avances, et des environnements cloud\n esprit analytique, capacite a challenger les besoins metiers et a y repondre avec des solutions scalables\n leadership naturel, sens du collectif, communication claire\n anglais professionnel requis\n pourquoi postuler ? contexte strategique, international et stimulant\n acces a un environnement data moderne, ouvert aux meilleures technos du marche\n forte autonomie, montee en competences et opportunites de croissance\n impact direct sur la performance des produits digitaux et lexperience utilisateur\n interesse(e) ? envoyez postulez et partagez votre cv detaille, votre candidature sera analysee avec attention.",
  "company_name": "astorm group",
  "is_data_profile": true,
  "profile": "data architect",
  "education_level": 5,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "leadership"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/supply-chain-master-data-analyst-h-f-at-valeo-4199411472",
  "titre": "supply chain master data analyst h / f",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "tanger-tetouan-al hoceima",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "valeo est une entreprise mondiale de haute technologie qui concoit des solutions revolutionnaires pour reinventer la mobilite. nous sommes un equipementier partenaire des constructeurs automobiles et des acteurs de la nouvelle mobilite dans le monde entier. notre vision ? inventer une mobilite plus verte et plus sure, grace a des solutions axees sur la conduite intuitive et la reduction des emissions de co2. nous sommes leaders dans nos domaines d'activite et reconnus comme l'une des plus grandes entreprises innovantes au monde.\n\n\nvaleo est l'un des principaux fournisseurs automobiles mondiaux de composants et de systemes integres. en tant qu'entreprise technologique, valeo propose des produits et des systemes innovants qui contribuent a la reduction des emissions de co2, a l'amelioration des performances des vehicules et au developpement de la conduite intuitive.\n\n\nnous proposons une carriere passionnante en tant que supply chain master data analyst\n\n\nvaleo maroc offre des conditions de travail exceptionnelles, nourrit et developpe les talents a tous les niveaux de l'organisation, en offrant aux candidats des opportunites de developper leur potentiel, d'atteindre leurs objectifs de developpement de carriere et d'apporter leur contribution aux innovations technologiques de l'industrie automobile.\n\n\nvous etes a la recherche de nouveaux defis ? rejoignez-nous!\n\n\nen tant que supply chain master data analyst vos mission sont:\n\n\n gerer, maintenir et auditer les donnees techniques liees aux systemes d'information de la chaine d'approvisionnement, comme la nomenclature, le controle des materiaux et les donnees de base de la planification de la production;\n creer et gerer des procedures d'audit pour garantir l'exactitude des donnees entre les flux physiques et les systemes;\n assurer l'interface pour l'introduction de nouveaux produits, les changements d'ingenierie et la fin de vie avec le systeme d'information de la chaine d'approvisionnement;\n anticiper les eventuels problemes techniques et de systeme lors de la definition des nouveaux produits, proposer des solutions et entreprendre les actions correctives appropriees;\n analyser les produits, les flux de matieres, les stocks et la methode d'ordonnancement pour definir la meilleure structure et le meilleur parametrage de ces donnees selon les recommandations du groupe;\n assurer l'interface pour l'introduction de nouveaux produits, les changements d'ingenierie et la fin de vie;\n examiner et mettre a jour en temps voulu toutes les modifications apportees a la procedure de creation des donnees relatives aux produits;\n diriger la reunion de coordination des changements de materiaux;\n initier la saisie des nouveaux composants et produits dans les systemes d'information de la chaine d'approvisionnement;\n creer et mettre a jour les pieces, les nomenclatures dans les donnees des systemes d'information de la chaine d'approvisionnement conformement aux typologies de materiaux definies par la chaine d'approvisionnement;\n creer et mettre a jour les emplacements, les emballages et les etiquettes dans la base de donnees des systemes d'information de la chaine d'approvisionnement, conformement aux normes locales, dans la base de donnees des systemes d'information de la chaine d'approvisionnement selon les normes locales, les exigences du client et le protocole logistique defini avec nos fournisseurs.\n\n\nprofil recherche: \n\n\nformation: bac+5 en logistique\nexperience: 2 ans dans un poste similaire \ncompetences techniques: \n connaissance de la supply chain et des flux logistique \n sap: \ncompetences linguistiques: niveau courant en francais et en anglais",
  "company_name": "valeo",
  "is_data_profile": true,
  "profile": "supply chain analyst",
  "education_level": 2,
  "experience_years": 2,
  "seniority": "mid",
  "hard_skills": [
    "sql",
    "sap",
    "python"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "analysis"
  ],
  "sector": [
    "automotive"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/technical-project-manager-ai-data-professional-at-capgemini-4219196318",
  "titre": "technical project manager (ai & data professional)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-29",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "description de poste\n\nnous recherchons un(e) specialiste en donnees et ia pour la rpa pour rejoindre notre equipe innovante. dans ce role, vous dirigerez l'integration de techniques avancees d'analyse de donnees et d'intelligence artificielle dans nos solutions d'automatisation robotique des processus (rpa), stimulant l'efficacite et l'innovation pour nos clients. en etroite collaboration avec des equipes pluridisciplinaires (produit, data, developpement, partenaires externes), vous assurerez la coordination, le suivi et la bonne execution des projets a fort impact.\n\nmissions principales\n\n concevoir et mettre en uvre des solutions rpa alimentees par l'ia qui optimisent les processus metier ;\n creer et maintenir des pipelines de donnees robustes pour les projets rpa tout en garantissant leur qualite et integrite ;\n integrer des modeles d'ia dans les processus rpa pour developper l'automatisation intelligente ;\n identifier des opportunites d'automatisation avec diverses equipes et transformer les besoins metier en solutions techniques\n effectuer des analyses regulieres de performance des solutions mises en uvre et proposer des ameliorations\n se tenir au courant des tendances emergentes en ia, apprentissage automatique et rpa pour stimuler l'innovation au sein de l'organisation\n\n\nprofil recherche\n\n master en informatique, science des donnees ou dans un domaine similaires\n experience approfondie des plateformes rpa (par exemple, uipath, automation anywhere)\n maitrise des langages de programmation tels que python (pandas, tensorflow, pytorch, or scikit-learn) et java\n solide experience en techniques d'apprentissage automatique et d'ia, y compris l'apprentissage profond et le traitement du langage naturel et de computer vision\n experience des plateformes cloud (aws, azure ou gcp) et de leurs services ia/ml\n familiarity with llm frameworks such as hugging face, transformers, ollama and vllm.\n familiarite avec les outils de visualisation de donnees (tableau, power bi) certifications pertinentes telles que uipath certified advanced rpa developer, ibm ai engineering professional certificate ou equivalent\n\n\nskills (competencies)\n\naws compute and paas\n\naws (cloud platform)\n\naws airflow\n\naws apache airflow\n\naws architecture\n\naws athena\n\naws code pipeline\n\naws devops\n\naws efs\n\nazure adls gen2\n\nazure boards\n\nazure compute\n\nazure data factory\n\nazure data lake storage\n\nazure data lake storage gen2 (adls)\n\nazure databricks\n\nazure devops\n\nazure event hub\n\nazure integration services\n\nazure repos\n\ngcp big table\n\ngcp bigquery\n\ngcp cloud storage\n\ngcp dataflow\n\ngcp dataproc",
  "company_name": "capgemini",
  "is_data_profile": true,
  "profile": "unspecified",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "java",
    "aws"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "leadership"
  ],
  "sector": [
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-snowflake-mid-level-at-lumenalta-4214858108",
  "titre": "data engineer - snowflake - mid level",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-26",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "experience remote done right. with over 20 years of remote experience, our 500+ team members are 100% remote, and we continue to cultivate vibrant relationships and provide exceptional opportunities for career growth while working with stellar clients on ambitious projects.\n\n\nwhat we're working on:\nenterprise companies turn to us to help them launch innovative digital products that interact with hundreds of millions of customers, transactions, and data points. the challenges we solve daily are real and require creativity, grit, and determination. we are building a culture that challenges norms while fostering experimentation and personal growth. to grasp the scale of the problems we face, ideally, you have some exposure to logistics, fintech, transportation, insurance, media, or other complex multifactor industries.\n\n\nrequirements\n 3+ years experience in a senior developer role using python; ideally, you have delivered business-critical software to large enterprises\n you are comfortable manipulating large data sets and handling raw sql\n experience using technologies such as snowflake, aws, and etl pipelines is essential.\n have extensive experience with data warehousing and working with scalability of large volumes of structured data\n financial services industry experience preferred\n english fluency, verbal and written\n personality traits: professional, problem solver, proactive, passionate, team player.\n\n\nwhy lumenalta is an amazing place to work at\nat lumenalta, you can expect that you will:\n be 100% dedicated to one project at a time so that you can innovate and grow.\n be a part of a team of talented and friendly senior-level developers.\n work on projects that allow you to use leading tech.\n\n\nthe result? we produce meaningful outcomes for our clients that break barriers in their industries.\n\n\nthe job is 100% remote; please ensure you have a comfortable office set at your desired work location.\n\n\nlumenalta is committed to hiring exceptional talent from a wide variety of diverse backgrounds. if you share our values and enthusiasm for digital transformation, we encourage you to apply\n\n\nwhat's it like to work at lumenalta?",
  "company_name": "lumenalta",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "sql",
    "snowflake"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cbs-postdoctoral-position-artificial-intelligence-applied-to-multi-omics-data-integration-at-um6p-university-mohammed-vi-polytechnic-4222927282",
  "titre": "cbs - postdoctoral position: artificial intelligence applied to multi-omics data integration",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-04",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position overview\n\nwe are seeking an outstanding postdoctoral researcher in artificial intelligence (ai) and data science with expertise in multi-omics data integration for health and precision medicine. the successful candidate will join a multidisciplinary team developing ai-driven approaches to integrate and analyze genomics, transcriptomics, proteomics, metabolomics, and microbiome datasets to uncover biomarkers, therapeutic targets, and mechanistic insights into complex diseases.\n\nthe project addresses critical challenges in personalized medicine, disease stratification, and multi-modal data fusion, enabling next-generation solutions in precision health and biomedical research.\n\nscientific challenges addressed in the position\n\n heterogeneity and high dimensionality of multi-omics data requiring advanced ai/ml methods for robust analysis and integration.\n data sparsity, batch effects, and missing values across different omics layers and platforms.\n cross-omics data fusion and representation learning for comprehensive systems biology modeling.\n identification of causal relationships and biomarker discovery through integrative approaches.\n time-series and longitudinal multi-omics data analysis for disease progression modeling.\n explainability and interpretability of ai models to support clinical decision-making and regulatory compliance in healthcare settings.\n scalability and computational efficiency in processing and integrating massive multi-omics datasets from clinical cohorts.\n\n\nkey responsibilities\n\n design and implement ai/ml pipelines for multi-omics data integration, including supervised and unsupervised learning methods.\n develop deep learning architectures (e.g., variational autoencoders, graph neural networks, transformers) for cross-omics data representation and feature extraction.\n apply multi-view learning, transfer learning, and data fusion techniques to integrate heterogeneous omics datasets and clinical metadata.\n conduct network-based analysis (gene regulatory networks, protein-protein interaction networks, metabolic networks) to identify key disease drivers and biomarkers.\n build predictive models for disease classification, patient stratification, and treatment response prediction.\n collaborate with biologists, clinicians, and bioinformaticians for data interpretation and validation of computational findings in clinical or experimental settings.\n disseminate research outcomes through publications in high-impact journals, conference presentations, and workshops.\n mentor and support the training of graduate students and early-career researchers in ai and multi-omics integration.\n\n\nrequired qualifications\n\n ph.d. in bioinformatics, computational biology, data science, artificial intelligence, or a related field.\n proven experience in multi-omics data integration, omics data analysis (genomics, transcriptomics, proteomics, metabolomics, microbiome).\n strong expertise in machine learning, deep learning, and advanced ai frameworks (tensorflow, pytorch, scikit-learn). experience with bioinformatics tools and databases (e.g., bioconductor, galaxy, kegg, reactome, string).\n proficiency in python, r, and unix/linux-based environments for high-performance data analysis. knowledge of biological network inference, causal modeling, and graph-based ai approaches.\n experience in multi-modal data fusion, representation learning, and heterogeneous data integration.\n strong publication record in relevant peer-reviewed journals.\n excellent communication skills and ability to work in a multidisciplinary environment.\n familiarity with cloud-based computing platforms (aws, azure, google cloud) and high-performance computing (hpc) environments.\n understanding of data privacy, security, and ethical considerations in handling clinical data.\n\n\napplication process\n\ninterested candidates should submit the following documents in a single pdf:\n\n a cover letter outlining their research interests, motivation, and relevant experience.\n a detailed curriculum vitae (cv) with a list of publications.\n contact details of two academic referees.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "bioinformatics data scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "r",
    "machine learning"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "analysis"
  ],
  "sector": [
    "research",
    "education"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/administrateur-et-data-analyst-digibuy-f-h-safran-maroc-at-aerocontact-4207883572",
  "titre": "administrateur et data analyst digibuy f/h - safran maroc",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-11",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "safran est un groupe international de haute technologie operant dans les domaines de l'aeronautique (propulsion, equipements et interieurs), de l'espace et de la defense. sa mission : contribuer durablement a un monde plus sur, ou le transport aerien devient toujours plus respectueux de l'environnement, plus confortable et plus accessible. implante sur tous les continents, le groupe emploie 100 000 collaborateurs pour un chiffre d'affaires de 27,3 milliards d'euros en 2024, et occupe, seul ou en partenariat, des positions de premier plan mondial ou europeen sur ses marches.   safran est la 2eme entreprise du secteur aeronautique et defense du classement  world's best companies 2024  du magazine time.\n\ndescriptif mission\n\ndescription de l'application digibuy :  digibuy est une solution applicative s2c (source to contract) permettant la collaboration des acteurs de la relation fournisseur avec les fournisseurs de safran.  elle comprend 3 modules: srm (supplier relationship management), sourcing (gestion des appels d'offres), et contracting (gestion des contrats d'achats). elle comprend egalement une fonction  portail fournisseur  permettant aux fournisseurs de collaborer avec les acheteurs safran sur leurs donnees et contacts fournisseurs, leurs documentations, les appels d'offres et les contrats. cette solution digibuy est une application groupe safran sur l'ensemble du perimetre des achats directs et indirects actuellement deploye sur les achats indirects (safran purchasing), les achats  matieres  et sur les achats directs de safran landing systems et de safran ceramics. les deploiements sont en cours sur les achats directs des autres societes du groupe (sae, she, sna, sep, sst, sts, sed, sao)   missions principales :  vous serez charge de l'administration et de la data analyse sur l'application digibuy avec une repartition 50% / 50% sur les 2 missions.  o dans le cadre de l'administration digibuy (50%), vos missions seront : - assurer la creation et la modification des utilisateurs sur le perimetre safran purchasing worldwide et achats matieres (acheteurs, acheteurs delegues du domaine outillages specifiques, juristes et autres acteurs de la relation fournisseur) y compris la gestion des cles de cryptage docaposte necessaires au lancement des signatures electroniques dans le module contracting. le volume actuel d'utilisateurs concernes est de 650.  - assurer la synchronisation des templates juridiques de safran purchasing et des achats matieres entre le module contracting et le sharepoint des juristes y compris a moyen terme la gestion des  balises  dans les templates permettant un pre-remplissage des documents contractuels pour faciliter le travail des acheteurs.  - assurer le monitoring quotidien de l'interface mdm / digibuy.  - d'autres activites pourraient etre integrees a terme comme le monitoring des autres interfaces digibuy (pouey, etq, bi achat, visual compliance, docaposte, ecovadis, s&p)  o dans le cadre du  data analyst digibuy  (50%), vos missions seront : - maintenance evolutive des rapports powerbi digibuy existants - analyse des donnees les plus critiques a commencer par les donnees de la base fournisseurs digibuy vs base fournisseur mdm (supplier master data management)  - d'autres activites ponctuelles de data analyse sur d'autres donnees pourront etre abordes suivant les besoins.  o pilotage : - preparer et animer des comites de pilotage mensuels des activites d'administration et de data analyse digibuy - proposer et ameliorer des kpis (indicateurs) permettant un pilotage efficace pour les garants de l'application.\n\n de formation bac + 4/5 avec idealement une experience sur de l'administration et/ou l'analyse de donnees d'outils digitaux - bonne maitrise de powerbi - connaissance de dataiq serait un plus - sens du reporting et des priorites - pedagogue, ouvert - methodique, rigoureux - sens du service, bon relationnel - francais courant et bonne maitrise de l'anglais",
  "company_name": "aerocontact",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "powerbi",
    "sql",
    "python"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "analysis"
  ],
  "sector": [
    "aerospace"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-scientist-at-logigroup-4219861392",
  "titre": "data scientist",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-01",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "a propos de logigroup :\nlogigroup est une esn, qui evolue dans les domaines de la business transformation, data management, cloud & ia et cybersecurite.\n\n\ndescriptif du poste :\nen tant que data scientist, vous contribuerez activement a la valorisation des donnees au sein de notre entreprise en developpant des modeles predictifs et des analyses avancees. vous collaborerez avec les equipes techniques et metiers pour concevoir des solutions basees sur la donnee, en respectant les meilleures pratiques en data science afin de garantir des livrables pertinents, robustes et exploitables.\n\n\navec nous, vous :\n integrerez une equipe dynamique et motivee\n decouvrirez un panel de missions riches et diversifiees\n aurez de reelles perspectives devolution dans un environnement motivant\n evoluerez en competences\n travaillerez au sein dune entreprise agile qui favorise le travail dune maniere flexible\n beneficierez dun systeme de primes interessant\n\n\nmissions :\n concevoir, developper et deployer des modeles de machine learning, notamment sur des donnees temporelles multivariees\n explorer, analyser et visualiser les donnees a laide de bibliotheques python comme pandas, matplotlib ou seaborn\n participer a lelaboration des pipelines de donnees, de la collecte au pretraitement\n rediger des rapports analytiques et restituer les resultats aux parties prenantes de maniere claire et exploitable\n collaborer etroitement avec les equipes techniques et metiers dans un cadre agile/scrum\n assurer la versionning du code et des modeles via git et github\n veiller a la qualite, la reproductibilite et la performance des solutions deployees\n contribuer aux bonnes pratiques de data science et a la capitalisation des connaissances\n\n\nprofil recherche :\n formation bac +5 en data science, statistiques, informatique ou equivalent\n experience professionnelle de minimum 3 ans sur des projets en data science  ou de machine learning\n maitrise de python 3.x et des bibliotheques courantes en data science (pandas, matplotlib, seaborn)\n tres bonne comprehension des series temporelles et des problematiques associees\n solide competence en sql et manipulation de bases de donnees\n bonne maitrise des outils git/github\n anglais courant (ecrit et parle)\n aisance en travail dequipe, rigueur et esprit danalyse\n\n\nserait un plus :\n connaissance des outils de google cloud platform (gcp), notamment bigquery et vertex ai\n\n\npoints cles :\n debut de la mission : au plus vite\n type de contrat : cdi\n experience demandee : 3 a 5 ans\n fourchette salariale interessante\n teletravail autorise\n evolution de carriere et systeme de primes avantageux\n lieu : casablanca",
  "company_name": "logigroup",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "sql",
    "machine learning"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "analysis"
  ],
  "sector": [
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/stagiaire-data-h-f-at-salafin-bmce-group-4178268527",
  "titre": "stagiaire data (h/f)",
  "via": null,
  "contrat": "other",
  "type_travail": null,
  "publication_date": "2025-03-12",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "dans le cadre de son developpement, salafin recherche des stagiaires en data (h/f) \nbases a casablanca.\nmissions :\nrattache(e) au pole risques de credit, vous aurez pour principales missions :\n collecter, structurer et analyser les donnees relatives aux portefeuilles de credit.\n contribuer a lelaboration et a lautomatisation des rapports de suivi des indicateurs de risques.\n identifier et interpreter les tendances et les anomalies dans les donnees pour detecter les risques potentiels.\n soutenir lequipe dans la mise en place de modeles statistiques et de scoring pour evaluer la qualite du credit.\n collaborer avec les equipes it et les autres departements pour ameliorer la qualite et la precision des donnees.\n participer aux projets damelioration continue en proposant des solutions basees sur lanalyse des donnees.\nprofil recherche :\n\n de formation bac+5, issu dune grande ecole dingenieurs avec une specialisation en mathematiques ou statistique.\n rigueur, esprit analytique et capacite a resoudre des problemes complexes.\n bonnes competences en communication pour vulgariser les resultats des analyses\n maitrise des outils danalyse de donnees (excel, sql, python, r, etc.).\n bonne connaissance des bases de donnees et des techniques de gestion de donnees.\n capacite a interpreter les resultats analytiques et a formuler des recommandations.\n connaissance des modeles de risque de credit (probabilite de defaut, perte en cas de defaut, exposition au defaut, etc.).\n capacite a travailler en equipe et a collaborer avec des parties prenantes internes.\n aisance dans la presentation et la visualisation des donnees (power bi, etc.).\n\nps : les candidatures sans cv ne pourront malheureusement pas etre traitees.",
  "company_name": "salafin bmce group",
  "is_data_profile": true,
  "profile": "unspecified",
  "education_level": 3,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "python",
    "excel"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/manager-data-ia-at-intelcia-4205917234",
  "titre": "manager data & ia",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-10",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "mission\n\nencadre(e) par un manager, vous serez amene a delivrer des projets innovants dans le domaine de la donnee et de lintelligence artificielle et de mettre en uvre des applications permettant a nos clients de tirer le meilleur parti de leurs donnees, doptimiser leurs process et dameliorer leur experience client ainsi que lefficacite des operations crm.\n\n travailler en etroite collaboration avec les clients pour comprendre leurs besoins en matiere de donnees et d'intelligence artificielle\n etre responsable du delivery des projets data/ ia\n participer a lidentification des cas d'usages et aux phases d'exploration pour fixer l'eligibilite du cas d'usage, definir les hypotheses de donnees necessaires, estimer le roi, les impacts macro du deploiement sur les processus et le si et garantir le respect de la protection des donnees personnelles.\n encadrer le consultant junior data & ia dans ces missions \n definir des scenarios d'implementation des solutions retenues dans le contexte client en prenant en compte des dimensions a la fois d'organisation, de processus et de technologie.\n deployer des solutions d'ia, et gerer l'integration avec des systemes existants.\n assurer une veille technologique en vue detre au diapason des nouvelles technologies sur lintelligence artificielle pour sinstruire et pour proposer aux clients des solutions innovantes.\n participer a lacculturation des equipes internes et des clients sur les sujets dia\n\n\nprofil recherche\n\n bac+ 5 dune grande ecole dingenieur ou master avec une specialisation en ia ou en big data, 2 a 4 ans dexperience dans la data\n avoir une bonne maitrise et comprehension de lunivers de lia et de lutilisation de la donnee\n connaissances solides en statistique, data science machine learning, deep learning)\n experience de 2 a 4 ans dans le conseil en data/ia ou en tant que chef de projet data/ia\n maitrise du francais et langlais a lecrit et a loral\n\n\ncompetences\n\n maitrise du langage de programmation python\n connaissance ou initiation dans le project management/ product management\n connaissance souhaitee en power bi et microsoft azure\n capacite de resolution des problemes/problem solving : structuration, identification des problemes, collecte et analyse de donnees, synthese et elaboration de recommandations\n capacite a trouver des solutions creatives pour integrer l'ia dans nos processus et nos livrables\n capacite a rechercher, tester et presenter des solutions dans une demarche projet\n capacite a simplifier et vulgariser le volet technique au grand public.",
  "company_name": "intelcia",
  "is_data_profile": true,
  "profile": "data product manager",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "power bi",
    "machine learning"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-scientist-h-f-at-soci%C3%A9t%C3%A9-g%C3%A9n%C3%A9rale-maroc-4193461137",
  "titre": "data scientist-(h/f)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-03",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "vos missions au quotidien\n\n\n\n\nle data scientist a pour mission la conception, le developpement et l'amelioration de modeles analytiques permettant de creer de la valeur ajoutee pour les metiers et d'aider la banque dans ses prises de decision.\n\n\n\n\nmissions principales :\n\n\n developper des use cases de bout en bout, en collaboration avec la digital factory ainsi que les lignes metiers\n concevoir et developper les modeles de machine learning et de data mining necessaires a la livraison de la solution definie par lequipe projet\n faire evoluer les modelisations et ameliorer l'efficacite des modeles concus tenant compte des retours des metiers ainsi que des resultats terrains obtenus\n recuperer et analyser les donnees pertinentes liees au processus de production de lentreprise, a la vente ou encore liees aux donnees client et ce afin d'apporter une information decisionnelle\n construire des algorithmes permettant dameliorer les resultats de recherches et de ciblage\n elaborer des modeles predictifs afin danticiper levolution des donnees et tendances relatives a lactivite de lentreprise\n modeliser les resultats d'analyse des donnees et les presenter avec des recommandations et des plans d'actions exploitables par les managers metier\n analyser les donnees, mettre en place des reportings, via l'outil 'data vis', qui serviront la prise de decision et formuler des recommandations business\n participer au recrutement dexperts big data pour completer lequipe qui travaille sur le traitement des donnees\n faire de la recherche et developpement relative au traitement de grands volumes de donnees\n automatiser et securiser le traitement data science sur les plateformes dediees\n mener une veille sur les sujets relatifs a son perimetre et etre une force de proposition et d'innovation\n\n\n et si cetait vous ?\n\n\n\n\nprofil recherche :\n\n\n de formation bac +5, diplome d'ingenieur ou diplome en mathematiques, statistiques, econometrie.\n minimum 5 ans d'experience dans le developpement et lapplication de modeles predictifs\n\n\n\n\ncompetences metier :\n\n\n methodologies analytics\n apprentissage automatique (machine learning)\n exploration de donnees\n statistiques\n algorithme / codage / programmation\n\n\n pourquoi nous choisir ?\n\n\n\n\nchez societe generale, nous sommes convaincus que les personnes sont moteurs du changement, et que le monde de demain sera fait de toutes leurs initiatives, des plus petites aux plus ambitieuses.\n\n\n\n\nque vous nous rejoigniez pour quelques mois, quelques annees ou toute votre carriere, ensemble nous avons les moyens davoir un impact positif sur lavenir. creer, oser, innover, entreprendre font partie de notre adn.\n\n\nsi vous aussi vous souhaitez etre dans laction, evoluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et developper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !",
  "company_name": "societe generale maroc",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "machine learning",
    "data mining",
    "python"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/ai-and-data-engineer-at-it-road-consulting-4190263992",
  "titre": "ai and data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-21",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "votre mission :\nen tant que machine learning engineer, vous aurez pour role de :\n concevoir, entrainer et optimiser des modeles de machine learning et deep learning.\n deployer des modeles en production sur des environnements cloud (aws, gcp, azure).\n gerer et automatiser les pipelines de ml grace a mlops (mlflow, kubeflow, airflow).\n traiter et analyser des donnees massives via spark, hadoop, sql et nosql.\n collaborer avec les equipes data et devops pour ameliorer la scalabilite et la performance des modeles.\n\n\nprofil recherche :\n formation : bac+5 en informatique, data science, ou domaine connexe.\n experience : 2 a 5 ans en machine learning, mlops et cloud ai.\n\n competences techniques :\n langages : python (tensorflow, pytorch, scikit-learn), r, julia.\n cloud & devops : aws, gcp, azure, kubernetes, docker.\n big data : spark, hadoop, sql, nosql.\n frameworks ia : tensorflow, pytorch, keras, opencv, hugging face.\n mlops : mlflow, kubeflow, airflow.",
  "company_name": "it road consulting",
  "is_data_profile": true,
  "profile": "machine learning engineer",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "tensorflow",
    "pytorch"
  ],
  "soft_skills": [
    "teamwork",
    "communication",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-engineer-at-oleonis-4224394611",
  "titre": "senior data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "pret(e) a ecrire une nouvelle page de votre parcours dans une equipe qui innove, soutient et evolue chaque jour ?\n\n\noleonis est une agence de conseil en informatique tournee vers l'avenir, specialisee dans les solutions innovantes pour accompagner les entreprises dans leur transformation numerique.\ngrace a notre expertise en cloud computing, en gestion des donnees et en automatisation, nous aidons les organisations a ameliorer leur efficacite, leur evolutivite et leur resilience dans un environnement technologique en constante evolution.\nnous nous distinguons notamment par l'automatisation des flux de travail chronophages a l'aide d'agents d'ia personnalises, permettant ainsi aux equipes de se concentrer sur des missions a forte valeur ajoutee.\n\n\ndescription de la mission :\ndans le cadre de notre developpement, nous recherchons un.e data engineer, base.e au maroc, pour collaborer avec nos equipes sur des projets innovants.\n\n\nvotre mission consistera a concevoir, developper et maintenir des infrastructures de donnees robustes et performantes.\n\n\nresponsabilites principales :\n creer, optimiser et maintenir des pipelines de donnees fiables.\n mettre en uvre des modeles de donnees adaptes aux besoins metiers.\n administrer et faire evoluer des entrepots de donnees pour garantir la qualite, la securite et la disponibilite des informations.\n travailler en etroite collaboration avec nos equipes produit, data et ia.\n\n\nprofil recherche :\n issu d'une formation bac+5 \n vous avez au moins 7 ans d'experience\n vous possedez une comprehension des concepts fondamentaux de l'ingenierie de donnees\n vous etes desireux d'appliquer et de developper vos competences avec divers outils et plateformes, incluant les bases de donnees relationnelles (comme postgresql, mysql) et nosql (comme mongodb).\n competences en data modeling : vous etes capable de comprendre et de contribuer a la structuration et a la modelisation des donnees, en apportant les meilleures pratiques pour optimiser l'organisation et l'acces a l'information.\n competences en etl : capacite a concevoir et implementer des processus etl efficaces.\n competences en data warehousing : bonne maitrise de la creation et de la maintenance de data warehouse.\n competences en data analytics : aptitude a analyser des donnees complexes pour produire des insights exploitables.\n bonne maitrise de python et sql.\n\n\ncompetences additionnelles appreciees :\n connaissance des services cloud (gcp, aws, azure) serait fortement apprecie.\n experience avec des outils de visualisation de donnees (power bi, tableau...).\n\n\ninformations complementaires :\n mode de collaboration : freelance.\n localisation : poste en full remote, base au maroc.\n\n\npourquoi collaborer avec oleonis ?\n missions a fort impact technologique et strategique.\n flexibilite et autonomie dans votre organisation.\n equipe engagee, dynamique et a taille humaine.\n opportunites de collaboration a long terme.\n\n\nsi ce que vous venez de lire vous parle, si vous sentez que vous pouvez apporter votre pierre a ledifice et quon pourrait grandir ensembles.\n\n\nvotre prochain challenge commence ici.\n\n\net parce quon croit profondement que chaque parcours est unique et precieux, ce poste est evidemment ouvert a toutes et a tous, y compris aux personnes en situation de handicap.\n\n\nrejoins-nous.",
  "company_name": "oleonis",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "postgresql"
  ],
  "soft_skills": [
    "teamwork",
    "communication",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-analyst-at-infomineo-4177215374",
  "titre": "senior data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-12",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "about us\ninfomineo is a fast-growing business insights provider, bringing brainshoring to global clients across a range of services: business research, content services, graphic design, and data analytics. our clients include leading consultancies, fortune 500 companies, governments, and ngos. infomineo counts 350+ employees spread across 5 offices covering emea and the americas (casablanca, cairo, dubai, barcelona and mexico city).\n\n\nabout this role\nthis role will give you the opportunity to deliver high added value data & analytics projects and build high quality and innovative solutions for our clients within a growing service company.\n\n\nwhat will you do?\nassist businesses in the decision-making process for data driven projects using the following steps:\n contribute to the design of the technical solution chosen to collect, analyze data, and display the results obtained.\n propose solutions and strategies to tackle business challenges.\n present results in a clear manner\nacquisition & preparation\n clean and prepare the data with the data scientists.\n collect and transform data from the various sources available in big data environments.\nanalysis\n provide data visualization to inform business decisions.\n analyze and interpret data to extract complex relationships and trends.\n optimize data exploration using machine learning techniques.\ndeployment\n adapt and integrate analytics models into the client's is environment.\n assist the it teams in all phases of the production, maintenance and updating of the models developed.\n\n\nwho are you?\neducation & professional experience\n master's degree in a relevant field such as computer science, machine learning, data science, statistics, applied mathematics, data engineering\n full proficiency in english + 1 additional language (french, german, arabic, spanish, italian, portuguese...)\n 4+ years of technical experience in advanced analytics and business intelligence\n\n\ntechnical skills\nacquisition & preparation\n exposure to big data environments and languages such as hadoop, hortonworks, cloudera, spark, scala, pyspark etc. &big data querying tools, such as pig, hive, and impala\n exposure to large data sets both structured and unstructured data: snowflake, sql and relational databases, data warehouse, data lake\n exposure to python programming language coupled with an additional languages experience if possible (e.g. sas, r, javascript)\nanalysis\n good skills in analytical concepts such as data correlation, pareto, market-basket analysis, forecasting, creating complex visuals like sunburst, multi-layered maps, etc.\n experience in bi/data visualization platforms such as power bi, tableau, looker, qlikview...\ndeployment\n exposure to versioning software: git, github, gitlab\n exposure to api integration using python for extracting data from different sources\ninterpersonal skills\n ability to step back, analyze problems, find solutions and the drive to implement these.\n ability to work & collaborate with variety of stakeholders & clients throughout data project life-cycle\n strong interpersonal skills and organisational skills, high motivation, an attention to detail, flexibility, and ability to cope under stress, a focus on identifying the solutions to problems.\n good communication skills & ability to translate complex solutions into business implications and at the same time being able to explain mathematical concepts when required\n\n\nwhat we offer\n a competitive salary\n a great working environment\n a steep learning curve with interesting and diverse topics to work on\n a healthy work-life balance\n health insurance benefits\nequal opportunity employer\ninfomineo is an equal opportunity employer, we prohibit any sort of discrimination (based on color, race, sex, sexual orientation, religion, national origin or any other attributes) in all aspects of employment (recruiting, hiring, wages and salary, promotions, benefits, training and job termination).\nif you believe you match our requirements and values, we would be happy to hear from you. visit our website to know more about us, our services and company culture",
  "company_name": "infomineo",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 4,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "power bi"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/expert-data-engineer-at-intelcia-it-solutions-4188111899",
  "titre": "expert data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-18",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "nous recherchons un data engineer expert en dataiku dss, et starburst (ou bigquery) pour participer a la conception, developpement et optimisation des solutions de gestion et danalyse de donnees sur des plateformes de donnees avancees.\nle data engineer sera responsable de la gestion de flux de donnees, mise en place de pipelines etl, ainsi que loptimisation des performances de traitement de donnees dans lecosysteme dataiku dss et starburst ou similaires.\n\n\nmissions principales\n developper et deployer des pipelines de donnees complexes dans dataiku dss, en utilisant starburst pour le traitement et le stockage des donnees.\n optimiser les performances des requetes et des traitements de donnees.\n integrer des sources de donnees variees et automatiser les processus de collecte et dintegration des donnees.\n travailler en collaboration avec les equipes dataops et cloud pour industrialiser les solutions et garantir leur scalabilite.\n\n\nprofil recherche\n formation : bac + 5 (master ou ecole dingenieur) en systeme dinformation\n experience ; minimum 5 ans dexperience en tant que data engineer\n expertise en dataiku dss, et starburst (ou bigquery)\n competences avancees en sql, python, et gestion de donnees massives.\n experience en optimisation des pipelines de donnees et dans lintegration de solutions big data.\n bonne maitrise des principes de mlops et des solutions cloud (gcp, aws, azure).\n bonne comprehension des defis dintegration des donnees et de la gestion des flux complexes.\n tres bonne communication en francais et en anglais avec toutes les parties prenantes.",
  "company_name": "intelcia it solutions",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "python",
    "dataiku dss"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-quality-fille-at-service-aux-entreprises-4214262550",
  "titre": "data quality (fille)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-26",
  "location": {
    "city": "temara",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "description du poste :  nous recherchons une data quality pour rejoindre notre equipe. dans ce role a temps plein, vous serez charge de surveiller et de maintenir la qualite des donnees traitees. vos taches quotidiennes incluront la verification de l'exactitude des donnees, et la collaboration avec d'autres departements pour resoudre les problemes de qualite des donnees. ce poste est base a temara\n\n\nqualifications : \n personne minutieuse , engagee et motivee pour le traitement des donnees\n competences en data analysis : experience dans l'analyse et l'interpretation des donnees pour garantir leur exactitude et leur qualite.\n competences en analytical skills : capacite a analyser les problemes complexes et a proposer des solutions efficaces.\n d'autres qualifications appreciees incluent une bonne maitrise des outils de qualite des donnees et des langages de programmation comme sql, ainsi que des competences en communication pour travailler efficacement avec diverses equipes.\n profil :\n age de 26 ans et plus\n avoir un bac +2/3 en informatique idealement en traitement des donnees ou developpement informatique\n parfaite maitrise de la langue francaise.\n\n\ncontrat cdi , et salaire motivant",
  "company_name": "service aux entreprises",
  "is_data_profile": true,
  "profile": "data quality analyst",
  "education_level": 2,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "data analysis",
    "analytical skills"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consultants-data-engineers-h-f-at-we-are-beebay-4195935223",
  "titre": "consultants data engineers (h/f)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-28",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "tu es passionne(e) par la data et l'ingenierie des donnees, et tu souhaites rejoindre une equipe dynamique et engagee ?\ncette offre est faite pour toi !\nen tant que data engineer, tu contribueras activement a la conception, au deploiement et a loptimisation de nos infrastructures data. integre(e) a une equipe agile et collaborative, tu auras lopportunite de relever des defis techniques varies et stimulants autour de la gestion et de la valorisation des donnees.\n\n\ntes missions principales incluront :\n collecter, transformer et preparer des donnees multi-sources pour assurer leur qualite et leur coherence.\n concevoir et deployer des pipelines de donnees etl/elt sur databricks et dautres solutions cloud (azure, aws, etc.).\n construire et gerer des data lakes et des entrepots de donnees pour structurer linformation.\n securiser les donnees sensibles via des techniques de data masking et de gouvernance.\n nettoyer, traiter et modeliser les donnees (dimensions & facts tables) pour les rendre exploitables.\n developper des workflows dautomatisation avec azure data factory et power automate.\n optimiser les performances des pipelines de traitement big data pour garantir rapidite et scalabilite.\n concevoir des datasets et rapports analytiques avec power bi pour faciliter la prise de decision.\n\n\ntu es ?\nformation & experience\n bac+5 en informatique\n 3 a 6 ans dexperience en ingenierie des donnees ou roles similaires\n\n\nenvironnement technique\n data processing : databricks, pyspark, sql avance\n cloud data stack : azure data factory, data lake, power bi\n langages : python (pandas, pyspark), sql (optimisation de requetes)\n gestion des donnees : modelisation (dimensions & facts), data masking, gouvernance\n\n\ncompetences cles\n conception et optimisation de pipelines etl/elt (azure data factory, databricks)\n expertise en data lake (architecture, gestion, securisation)\n maitrise de power bi (creation de datasets, rapports analytiques)\n bonnes pratiques en securite et qualite des donnees\n collaboration agile avec les equipes data, devs et metiers\n\n\nce serait un vrai plus si tu as aussi :\n experience avec snowflake (ou autre data warehouse moderne)\n connaissance de microsoft fabric (dataflows, data factory)\n notions en apache spark, kafka (streaming data)\n sensibilite aux methodologies dataops et ci/cd",
  "company_name": "we are beebay",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "pyspark",
    "sql",
    "python"
  ],
  "soft_skills": [
    "teamwork",
    "communication",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-s%C3%A9nior-gcp-at-alten-4213455551",
  "titre": "data engineer senior gcp",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-19",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\nalten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2027. alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\nrejoindre alten maroc cest beneficier :\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers. \n des formations certifiantes et diplomantes. \n des evenements reguliers pour combiner bien etre et performance.\n\n\ndescription du poste\n\nintegre(e) dans les equipes supply, le/la consultant(e) aura pour mission de :\n\n concevoir, developper et maintenir des solutions de traitement de donnees massives en utilisant les technologies big data et les outils gcp. \n mettre en place et optimiser les pipelines de donnees, de lanalyse des performances et de lamelioration continue des solutions existantes\n\n\nqualifications\n\ndiplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique, ou justifiant d'une experience significative equivalente\n\nexperience : de plus de 7 ans en gcp\n\nune experience dans le secteur du commerce de detail ou de la grande distribution serait un plus.\n\ncompetences techniques :\n\n maitriser les technologies cloud de google cloud platform (gcp) pour la gestion des donnees, lorchestration et le deploiement des solutions big data. \n avoir une expertise approfondie de bigquery et bigtable pour le stockage, la manipulation et lanalyse de donnees a grande echelle. \n maitriser les langages de programmation scala ou java pour le developpement de solutions big data, avec une experience significative dans lun des deux. \n avoir une experience pratique avec lecosysteme hadoop et ses outils associes comme spark et apache kafka pour le traitement distribue de donnees. \n etre capable de concevoir et dimplementer des pipelines de donnees complexes en utilisant des outils comme apache kafka et avro pour la gestion des flux de donnees. \n maitriser les concepts de base de kafka pour la conception et la mise en uvre de systemes de messagerie distribues. \n avoir une bonne comprehension des bases de donnees nosql, notamment cassandra et bigtable, pour le stockage et la recuperation de donnees non structurees. \n avoir une experience avec les moteurs de recherche comme elastic search pour la recherche et lanalyse de donnees textuelles. \n maitriser les outils de ci/cd et les pratiques de developpement logiciel pour lautomatisation du deploiement et de lintegration continue. \n avoir une experience pratique avec les outils de deploiement et dorchestration comme jenkins, gitlab, kubernetes, docker et ansible. \n etre capable de travailler avec docker pour la creation et la gestion des conteneurs dapplications.\n\n\ncompetences linguistiques :\n\n avoir une excellente communication ecrite et orale, avec la capacite de produire des livrables et des reportings de haute qualite.\n\n\nsoft skills :\n\n avoir un esprit danalyse et damelioration continue, avec la capacite devaluer le code et ses impacts, ainsi que de remettre en question les solutions existantes pour les ameliorer. \n avoir la capacite de prendre du recul et devaluer les problematiques avec objectivite, en proposant des solutions damelioration. \n avoir un esprit dequipe et la capacite de collaborer efficacement avec les membres de lequipe pour atteindre des objectifs communs. \n maitriser les concepts dagilite (scrum, sprint planning, backlog...).\n\n\ninformations supplementaires\n\nau plaisir de vous lire !",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "gcp",
    "bigquery",
    "scala"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-experimente---df-supply-chain-at-alten-4214535999",
  "titre": "data engineer experimente df supply chain",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "alten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2024. avec plus de 90 recrutements par mois, alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\n\nrejoindre alten maroc c'est beneficier :\n\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers.\n des formations certifiantes et diplomantes.\n des evenements reguliers pour combiner bien etre et performance.\n\n\njob description\n\nla digital factory supply chain concoit et developpe lensemble des assets digitaux permettant doffrir a nos clients et collaborateurs une experience omnicanale parmi les meilleures du marche, au service de l'approvisionnement des magasins. de la commande magasin automatique, aux commandes fournisseurs jusqu'a la preparation en entrepot et au transport vers les points de vente. les technologies de pointe que nous deployons, ainsi que la puissance de nos outils et methodes basees sur la data, le machine learning et l'ia, permettent a nos equipes de focaliser leurs efforts sur la valeur de leurs initiatives.\n\n\nen tant que data scientist/data engineer, vous integrerez la digital factory supply chain ou vous serez amene a appuyer le departement prevision et optimisation particulierement sur des sujets data et danalyse de donnees. au sein d'une equipe composee de data scientists et de data engineers organisee en mode scrum agile, vous travaillerez pour implementer des outils de calcul de prevision (prevision du besoin magasin pour lapprovisionnement entrepot, prevision de charge entrepots etc.)\n\n\n explorer et analyser les donnees du datalake\n\n\n participer au cadrage des nouvelles fonctionnalites\n\n\n developper des modeles de prevision statistiques et de machine learning\n\n\n tester les fonctionnalites developpees\n\n\n\n\nqualifications\n\n vous maitrisez les langages suivants : sql et python\n vous avez un esprit danalyse et la capacite de travailler en equipe et a distance.\n vous etes autonome, rigoureux, fluide dans votre communication orale et ecrite et a l'ecoute des besoins de vos interlocuteurs.\n vous etes reconnu pour vos capacites d'anticipation, votre sens de l'initiative et votre reactivite.\n une connaissance de gcp et de bigquery serait un plus.\n une connaissance meme theorique de la methodologie agile serait un plus.\n une connaissance des commandes git serait un plus.\n excellentes aptitudes a la collaboration et au travail en equipe.\n bonne communication ecrite et orale en francais pour des interactions fluides avec le metier.\n sens critique permettant d'evaluer objectivement differentes solutions.\n capacite a prendre du recul sur les problematiques techniques et fonctionnelles.\n autonomie et proactivite dans l'organisation du travail et la resolution de problemes.\n participation active aux decisions d'equipe avec des contributions constructives.\n capacite a respecter les delais tout en maintenant des standards eleves.\n familier avec les methodes agiles, notamment scrum.\n\n\nadditional information\n\nvous etes rigoureux, creatif, curieux et vous aimez travailler en equipe et monter en competence dans un environnement dynamique, les metiers du service vous animent et vous souhaitez evoluer dans un environnement convivial, rejoignez-nous !\n\n\nau plaisir de vous lire!",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "sql",
    "bigquery"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "adaptability"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-snowflake-senior-at-lumenalta-4214866498",
  "titre": "data engineer - snowflake - senior",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-26",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "experience remote done right. with over 20 years of remote experience, our 500+ team members are 100% remote, and we continue to cultivate vibrant relationships and provide exceptional opportunities for career growth while working with stellar clients on ambitious projects.\n\n\nwhat we're working on:\nenterprise companies turn to us to help them launch innovative digital products that interact with hundreds of millions of customers, transactions, and data points. the challenges we solve daily are real and require creativity, grit, and determination. we are building a culture that challenges norms while fostering experimentation and personal growth. to grasp the scale of the problems we face, ideally, you have some exposure to logistics, fintech, transportation, insurance, media, or other complex multifactor industries.\n\n\nrequirements\n 7+ years experience in a senior developer role using python; ideally, you have delivered business-critical software to large enterprises\n you are comfortable manipulating large data sets and handling raw sql\n experience using technologies such as snowflake, aws, and etl pipelines is essential.\n have extensive experience with data warehousing and working with scalability of large volumes of structured data\n financial services industry experience preferred\n english fluency, verbal and written\n personality traits: professional, problem solver, proactive, passionate, team player.\n\n\n\n\nwhy lumenalta is an amazing place to work at\nat lumenalta, you can expect that you will:\n be 100% dedicated to one project at a time so that you can innovate and grow.\n be a part of a team of talented and friendly senior-level developers.\n work on projects that allow you to use leading tech.\n\n\nthe result? we produce meaningful outcomes for our clients that break barriers in their industries.\n\n\nthe job is 100% remote; please ensure you have a comfortable office set at your desired work location.\n\n\nlumenalta is committed to hiring exceptional talent from a wide variety of diverse backgrounds. if you share our values and enthusiasm for digital transformation, we encourage you to apply\n\n\nwhat's it like to work at lumenalta?",
  "company_name": "lumenalta",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "snowflake"
  ],
  "soft_skills": [
    "problem solving",
    "proactive",
    "teamwork"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/iot-data-engineer-developer-devops-iot-engineer-at-manpowergroup-4173015924",
  "titre": "iot data engineer developer // devops iot engineer",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-03-07",
  "location": {
    "city": "kenitra",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "nous recherchons deux profils talentueux pour notre client base a kenitra : un iot data engineer / developer et un devops iot engineer pour rejoindre des equipes innovantes dans le domaine de l'iot !\n\n\n devops iot engineer\n\n\n principales missions :\n gestion du deploiement de conteneurs docker/kubernetes\n administration des bases de donnees influxdb et mysql\n mise en place de solutions de surveillance (grafana, prometheus)\n developpement et gestion des pipelines ci/cd\n assurer la securite des communications iot\n profil recherche :\n bac+5 en genie informatique\n 3 a 5 ans d'experience en devops ou ingenierie systemes\n expertise sur docker, kubernetes, influxdb, mysql, python/bash\n\n\niot data engineer / developer\n\n\n principales missions :\n creation de tableaux de bord avances avec grafana\n developpement de plugins et de nuds node-red\n integration d'api externes (fastapi)\n automatisation avec python et javascript\n collaboration avec l'ingenieur devops pour optimiser les flux de donnees\n profil recherche :\n bac+5 en genie logiciel ou informatique\n 3 a 5 ans d'experience en developpement iot ou full-stack\n competences en python, javascript, grafana, node-red, influxdb, mysql",
  "company_name": "manpowergroup",
  "is_data_profile": true,
  "profile": "iot data specialist",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "javascript",
    "grafana"
  ],
  "soft_skills": [
    "teamwork",
    "communication",
    "collaboration"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/architecte-cloud-data-big-data-freelance-ld-at-ngbs-4218701202",
  "titre": "architecte cloud data / big data (freelance ld)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-28",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "nous recrutons un(e) architecte cloud data / big data, sur des projets data internationaux, pour assurer les missions suivantes :\n\n\n concevoir des architectures performantes en repondant aux enjeux techniques, organisationnels et operationnels de nos clients\n piloter les projets data & ai avec une vraie vision bout-en-bout\n collaborer avec des equipes internationales (france & a letranger)\n innover en assurant une veille technologique continue et en partageant vos expertises\n\n\nstack et environnement technique :\n cloud gcp expert : gce, gke, app engine, iam, serverless, securite, etc.\n big data & data engineering : spark, databricks, dataflow, kafka, hive, etc.\n infra & devops : terraform, kubernetes, ci/cd, mlops, ansible\n bonus : connaissances aws / azure & experience en migration cloud\n\n\nprofil recherche :\n\n\nbac +5 en informatique, avec min 7 ans d'experience en architecture cloud & data\na laise en communication (francais / anglais)\n\n\nnb: le poste est ouvert pour le freelance (mission longue duree).",
  "company_name": "ngbs",
  "is_data_profile": true,
  "profile": "data architect",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "gcp",
    "spark",
    "databricks"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "innovation"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/dba-senior-data-base-administrator-h-f-at-gentis-4188994123",
  "titre": "dba senior - data base administrator h/f",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-19",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "une multinationale, en pleine croissance et specialisee dans la gestion de donnees et de solutions d'externalisation/delocalisation, situee dans l'axe rabat et casablanca, est a la recherche de son nouvel administrateur de base de donnees a rabat.\n\n\nmission :\nconcoit, gere et administre les systemes de gestion de bases de donnees, il garantit la coherence, la qualite, la securite et laccessibilite permanente des informations.\n\n\nles taches :\n\n\n gestion des changes (nssr - non standard, normal) et probleme (recurrent et/ou avec impact majeur) / capacite / config (rtpa/maj esl ou autre knowledge base)\n participation aux projets (clients et interne)\n assister a des reunions operationnelles internes et externes pour le suivi des cab/tab/ngdm\n proposer des solutions techniques innovantes ou plus adaptees a lenvironnement clients\n assurer lactivite et accompagner les profils juniors / confirme et/ou middle senior\n participer a la preparation des reponses des cahiers de charges\n\n\nprofil : \n bac +3/5 (en informatique de preference).\n\n\nniveau dexperience professionnelle :\n3 a 7 ans d'experience en tant que dba.\n\n\ncompetences :\n must have : oracle ; sql server ; mysql ; ibm db2 ; rac ; dataguard\n nice to have : oracle tuning certification: - oca/ocp/mssql server certif/ mysql\n\n\ncompetences comportementales :\n- esprit dequipe ; esprit danalyse\n\n\nlangues :\n- francais ; anglais\n\n\ncette offre est faite pour toi :\n\n\n un salaire competitif\n un environnement de travail flexible (teletravail)\n une entreprise a taille humaine\n\n\ninteresse(e) ? organisons un meeting !\n\n\nn'hesite pas a me contacter sur :\nmehdi.a@gentis.com",
  "company_name": "gentis",
  "is_data_profile": true,
  "profile": "database administrator",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "oracle",
    "sql server",
    "mysql"
  ],
  "soft_skills": [
    "teamwork",
    "analysis",
    "communication"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-red-tic-4225314665",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "freelance\n casablanca\n publie il y a 6 mois\n\n\nred tic recrute pour lun de ses clients un profil data analyst.\n\nmission\n\n rassembler des donnees a partir de diverses sources, que ce soit a travers des bases de donnees, des fichiers csv ou des outils de collecte.\n traiter les donnees pour eliminer les incoherences, les valeurs manquantes et les doublons, afin de sassurer que les analyses sont precises.\n realiser des analyses descriptives pour comprendre les tendances, les schemas et les relations dans les donnees.\n creer des graphiques, des tableaux et dautres visualisations pour representer les donnees de maniere claire et accessible, facilitant ainsi la comprehension des resultats.\n elaborer des rapports et des presentations pour communiquer les resultats aux parties prenantes, en traduisant les analyses en recommandations concretes.\n\n\nprofil recherche\n\n langages de programmation : sql, python\n outils de visualisation: tableau\n bases de donnees relationnelles : mysql, postgresql, oracle.\n bases de donnees nosql : cassandra\n\n\nrecruitment consulting management training sourcing job jobs offer internship morocco africa java developpement developpement developpeur developpeur informatique application it jee android consultant devops fullstack. dabord. tout dabord. en premier lieu. ensuite, de plus. finalement. en outre. par ailleurs. en dernier lieu. enfin. dabord, en premier lieu, pour commencer, premierement, en conclusions ur conclure, enfn, finalement, en dernier lieu, bien que. il y a aussi il est vrai que... mais. tout en reconnaissant que... on peut supposer que. par exemple . en fait . prenons le cas de. considerons, par exemple. lexemple le plus r. cependant. mais. pourtant. toutefois. neanmoins. contraste. alors que. tandis que. par contre. en revanche analyst recruitment consulting management training sourcing job jobs offer internship morocco africa java developpement developpement developpeur developpeur informatique application it jee android consultant devops fullstack. dabord. tout dabord. en premier lieu. ensuite, de plus. finalement. en outre. par ailleurs. en dernier lieu. enfin. dabord, en premier lieu, pour commencer, premierement, en conclusions ur conclure, enfn, finalement, en dernier lieu, bien que. il y a aussi il est vrai que... mais. tout en reconnaissant que... on peut supposer que. par exemple . en fait . prenons le cas de. considerons, par exemple. lexemple le plus r. cependant. mais. pourtant. toutefois. neanmoins. contraste. alors que. tandis que. par contre. en revanche analyst\n\nnom et prenom\n\nadresse email\n\nmobile\n\nniveau d etude\n\nbac bac +1 bac +2 bac +3 bac +4 bac +5 bac + x\n\nannees dexperience\n\n0 +1 +2 +3 +4 +5 +6 +7 +8 +9 + 10\n\npreavis\n\ndisponible immediatement -1 mois 1 mois 2 mois +2 mois\n\nmessage\n\nupload cv\n\nteleverser votre cv ou tout autre document relatif. taille max: 2 mb.",
  "company_name": "red tic",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": null,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "sql",
    "python",
    "tableau"
  ],
  "soft_skills": [
    "analysis",
    "communication",
    "reporting"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-bi-expert-at-cplnetwork-4209641248",
  "titre": "data engineer - bi expert",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-14",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "nous recrutons : bi expert power bi \n\n\nvous etes passionnee par la data et la visualisation intelligente ? vous avez un il affute pour les dashboards et une solide experience sur power bi ? cette opportunite est pour vous !\n\n\nvos principales missions :\n developper et maintenir des rapports et dashboards power bi.\n deployer des solutions bi dans une logique de reporting factory.\n modeliser, consolider, nettoyer et securiser les donnees.\n collaborer avec des equipes internationales en methode agile.\n mettre en place des processus dautomatisation des flux de donnees.\n travailler dans un environnement technique riche : azure data platform, powershell, sql server, msbi, etc.\n\n\ncompetences techniques recherchees :\n 5+ ans dexperience sur power bi (modelisation, dax, rls, visualisation).\n bonne maitrise de la power platform, de powershell, de lecosysteme azure (data factory, datalake, databricks, microsoft fabric...).\n connaissance de l'active directory, de ms graph api.\n maitrise de la qualite des donnees et de leur cycle de vie.\n\n\nsoft skills :\n aisance a communiquer en anglais, a lecrit comme a loral.\n capacite a comprendre et modeliser des besoins metier.\n experience en environnement agile.\n\n\n interessee ou envie den savoir plus ? envoyez-moi votre cv \n\n\n#powerbi #biexpert #datajobs #hiring #azuredataplatform #businessintelligence #recrutement #microsoftbi #powerplatform",
  "company_name": "cplnetwork",
  "is_data_profile": true,
  "profile": "business intelligence analyst",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "power bi",
    "dax",
    "sql server"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "analysis"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-scientist-h-f-at-societe-generale-maroc-4188322410",
  "titre": "data scientist-(h/f)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-23",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "vos missions au quotidien\n\n\n\n\nle data scientist a pour mission la conception, le developpement et l'amelioration de modeles analytiques permettant de creer de la valeur ajoutee pour les metiers et d'aider la banque dans ses prises de decision.\n\n\n\n\nmissions principales :\n\n\n developper des use cases de bout en bout, en collaboration avec la digital factory ainsi que les lignes metiers\n concevoir et developper les modeles de machine learning et de data mining necessaires a la livraison de la solution definie par lequipe projet\n faire evoluer les modelisations et ameliorer l'efficacite des modeles concus tenant compte des retours des metiers ainsi que des resultats terrains obtenus\n recuperer et analyser les donnees pertinentes liees au processus de production de lentreprise, a la vente ou encore liees aux donnees client et ce afin d'apporter une information decisionnelle\n construire des algorithmes permettant dameliorer les resultats de recherches et de ciblage\n elaborer des modeles predictifs afin danticiper levolution des donnees et tendances relatives a lactivite de lentreprise\n modeliser les resultats d'analyse des donnees et les presenter avec des recommandations et des plans d'actions exploitables par les managers metier\n analyser les donnees, mettre en place des reportings, via l'outil 'data vis', qui serviront la prise de decision et formuler des recommandations business\n participer au recrutement dexperts big data pour completer lequipe qui travaille sur le traitement des donnees\n faire de la recherche et developpement relative au traitement de grands volumes de donnees\n automatiser et securiser le traitement data science sur les plateformes dediees\n mener une veille sur les sujets relatifs a son perimetre et etre une force de proposition et d'innovation\n\n\n et si cetait vous ?\n\n\n\n\nprofil recherche :\n\n\n de formation bac +5, diplome d'ingenieur ou diplome en mathematiques, statistiques, econometrie.\n minimum 5 ans d'experience dans le developpement et lapplication de modeles predictifs\n\n\n\n\ncompetences metier :\n\n\n methodologies analytics\n apprentissage automatique (machine learning)\n exploration de donnees\n statistiques\n algorithme / codage / programmation\n\n\n pourquoi nous choisir ?\n\n\n\n\nchez societe generale, nous sommes convaincus que les personnes sont moteurs du changement, et que le monde de demain sera fait de toutes leurs initiatives, des plus petites aux plus ambitieuses.\n\n\n\n\nque vous nous rejoigniez pour quelques mois, quelques annees ou toute votre carriere, ensemble nous avons les moyens davoir un impact positif sur lavenir. creer, oser, innover, entreprendre font partie de notre adn.\n\n\nsi vous aussi vous souhaitez etre dans laction, evoluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et developper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !",
  "company_name": "societe generale maroc",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "machine learning",
    "data mining",
    "statistical modeling"
  ],
  "soft_skills": [
    "communication",
    "analysis",
    "problem solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consultant-bi-data-tableau-at-brome-consulting-technology-4200181724",
  "titre": "consultant bi-data (tableau)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "pour le compte de notre client bancaire, nous recherchons un consultant bi-data (tableau) :\n\nanalyste data/banque\n\n comprendre le besoin metier et detailler les specifications fonctionnel bi\n elaboration des cahiers des charges techniques a destination des equipes techniques\n suivi des developpements et chalenge des equipes techniques\n test et recette de lensemble de la chaine sop (systeme source) => edd (entrepot de donnees) => datamart (visuellement sur tableau software).\n\n\nskills\n\n formation bac+5 avec minimum de 6 dexperience\n connaissance du domaine bancaire\n manipulation des fichiers de donnees (csv/excel)\n connaissance avancee de loutils tableau software (partie dataviz)\n\n\ndisponibilite : asap",
  "company_name": "brome consulting & technology",
  "is_data_profile": true,
  "profile": "business intelligence analyst",
  "education_level": 3,
  "experience_years": 6,
  "seniority": "senior",
  "hard_skills": [
    "tableau",
    "sql",
    "data visualization"
  ],
  "soft_skills": [
    "communication",
    "analysis",
    "problem solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/gcp-data-engineer-at-cplnetwork-4218721055",
  "titre": "gcp data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-28",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "nous recrutons un consultant data engineer , sur casablanca \n\n\nprofil recherche\n experience en python, sql et environnement cloud (gcp idealement).\n capacite a developper et optimiser des pipelines de donnees.\n bonne capacite dadaptation et esprit dequipe.\n\n\nmissions : \n developper et optimiser des pipelines de donnees en python et sql.\n gerer lintegration et la synchronisation des donnees entre differents systemes en batch et en temps reel.\n travailler avec bigquery et pub/sub sur google cloud platform (gcp).\n assurer la qualite du code via des tests unitaires et dintegration, et participer aux revues de code.\n identifier et resoudre les problemes de performance dans les pipelines.\n\n\nstack technique requise\n cloud : google cloud platform (bigquery, pub/sub, cloud functions, cloud run, gke, cloud sql/postgresql).\n langages et frameworks : python, sql, dbt, fastapi.\n orchestration : apache airflow.\n versioning & ci/cd : gitlab, gitlab runner.\n monitoring : cloud monitoring, looker.",
  "company_name": "cplnetwork",
  "is_data_profile": true,
  "profile": "cloud data engineer",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "sql",
    "bigquery"
  ],
  "soft_skills": [
    "adaptability",
    "teamwork",
    "problem solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-privacy-specialist-12-month-ftc-at-axa-uk-4204362671",
  "titre": "data privacy specialist - 12-month ftc",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-08",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "at axa were committed to driving transformation and innovation. our finance transformation and change delivery programme is at the forefront of this. weve got an exciting opportunity for an experienced data protection professional wholl help ensure privacy compliance as well as guiding axa through significant changes in technology and processes.\n\nyoull provide expert privacy compliance advice to the delivery programme. youll focus on identifying and managing privacy risks associated with strategic change initiatives, both in enhancement of existing technologies and processes, as well as implementation of new ones. this is a 12-month ftc.\n\nat axa we work smart, empowering our people to balance their time between home and the office in a way that works best for them, their team and our customers. you'll work at least 40% of your week away from home, moving to the majority of your working week from september 2025. away from home means either attendance at one of our office locations, visiting clients or attending industry events.\n\nwhat youll be doing:\n\n offer privacy advice to support the finance transformation and change delivery programme.\n identify, assess, and manage privacy risks arising from various strategic change programmes.\n collaborate closely with cross-functional teams including finance, data, it and legal teams across axa group.\n oversee key initiatives delivered in phases over the next 12 months, ensuring compliance with data protection regulations.\n engage with custodians of large-scale multipurpose platforms (data platforms) to evaluate data protection implications.\n work alongside first and second line data protection teams to consider all relevant variables from a data protection perspective.\n work with the data protection manager and manage delivery requirements of the phases.\n\n\n\ndue to the number of applications we expect to receive for this role, we reserve the right to close this advert earlier than the listed closing date to ensure were able to effectively manage interest. therefore, if youre interested in joining us at axa, please dont hesitate to apply.\n\nwhat youll bring:\n\n technical experience in privacy compliance or data protection roles, within a financial services or transformation context  essential.\n strong understanding of data protection regulations and best practices - essential.\n excellent interpersonal skills to engage with diverse stakeholders.\n ability to manage multiple projects and priorities in a dynamic environment.\n proactive and solution-oriented mindset.\n\n\n\ninternal candidates are encouraged to apply for this role as a secondment opportunity through the internal careers site.\n\nas a precondition of employment for this role, you must be eligible and authorised to work in the united kingdom.\n\nwhat we offer:\n\nat axa uk, were appreciative of the people who work for us and our rewards package is reviewed regularly to reflect that. you can expect to receive:\n\n competitive annual salary of up to 70,000 dependent on experience\n discretionary company & performance-based bonus\n contributory pension scheme (up to 12% employer contributions)\n life assurance (up to 10 x annual salary)\n 28 days annual leave plus bank holidays\n opportunity to buy up to 5 extra days leave or sell up to 5 days leave\n axa employee discounts\n gym benefits\n\n\n\nto apply, click on the apply for this job button, youll then need to log in or create a profile to submit your cv. were proud to be an equal opportunities employer and dont discriminate against employees or potential employees based on protected characteristics. if you have a long-term condition or disability and require adjustments during the application or interview process, were proud to offer access to the axa accessibility concierge. for our support, please send an email to adi.stapletonberry@axa-uk.co.uk.\n\nwho we are:\n\naxa uk support functions power axas three customer-facing business units, providing the infrastructure, support and expertise to ensure our customers can always count on us. whether youve got heaps of experience and qualifications behind you, or youre just starting out, well give you the support and opportunities to help you grow and develop with confidence.",
  "company_name": "axa uk",
  "is_data_profile": true,
  "profile": "data privacy officer",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "data protection",
    "privacy compliance",
    "data protection regulations"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "problem-solving"
  ],
  "sector": [
    "finance",
    "technology"
  ],
  "salary_range": {
    "min": null,
    "max": 70000,
    "currency": null,
    "period": "year"
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/global-data-practice-manager-at-opmobility-4221545430",
  "titre": "global data practice manager -",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-06",
  "location": {
    "city": "tangier",
    "region": "tanger-tetouan-al hoceima",
    "country": null,
    "remote": false
  },
  "description": "hungry for challenges? join a group with innovation at its heart and contribute to the automotive revolution!\n\nopmobility is a world-leading provider of innovative solutions for a unique, safer and more sustainable mobility experience. innovation-driven since its creation, the group develops and produces intelligent exterior systems, customized complex modules, lighting systems, clean energy systems and electrification solutions for all mobility companies. with a 11.4 billion economic revenue in 2023, a global network of 152 plants and 40 r&d centers, opmobility relies on its 40,300 employees to meet the challenges of transforming mobility.\n\nour ambition? provide automakers with cutting-edge equipment and solutions to develop tomorrows clean and connected car.\n\nreporting to the group data officer, the global data practice manager is responsible for setting-up and managing the data practice. he/she oversees the delivery of data projects on a global scale. this role involves planning, resource management and quality management, and ensuring the performance of a multidisciplinary team composed of data engineers, business intelligence engineers, and data scientists. she/he plays a key role in defining and executing the company's data strategy, ensuring technical and operational excellence.\n\nmain activities include\n\nteam management and capacity management\n\nrecruit, define training plans, and support data team talents.\n\nestablish an efficient work framework fostering collaboration and innovation.\n\nmanage the teams capacity planning based on business needs and strategic priorities.\n\ndevelop partnerships with universities and academic institutions to attract top talent.\n\ndevelopment of standards and best practices\n\ndefine and ensure adherence to development standards and best practices.\n\nstructure development and integration processes for data solutions (data engineering, bi, data science, etc.).\n\npromote high-quality code, performance optimization, and maintainability across all data solutions.\n\nfunctional operations and data integrity\n\noversees the run of data pipelines to ensure optimal performance.\n\nensure that the data in the platform meets the required quality and reliability standards.\n\nimplement monitoring and alert processes to detect and resolve anomalies.\n\ninnovation and technology watch\n\ndefine and lead the technology roadmap for data solutions (lakehouse, data science, data visualization, etc.).\n\npromote experimentation and innovation in adopting new technologies and approaches.\n\nensure the data practice stays updated on market trends and continuously propose improvements.\n\nrequired profile & experience\n\n masters degree (bac +5) in computer science, data science, statistics, or a related field. \n at least 10 years of experience in the data field, with a minimum of 3 years in team management, including leadership roles in a global context. \n general understanding of it technologies (cloud, network devops,,...) and it frameworks (itil, togaf, iso 27001...) \n functional understanding of key business areas (finance, manufacturing, supply chain, r&d...) \n excellent knowledge of data architectures (lakehouse, data warehouse, data mesh, etc.). \n proficiency with data tools and technologies (azure data factory, azure fabric, databricks, etc.). \n experience in managing data pipelines and ensuring data integrity \n ability to manage project timelines, resources & budgets. experience with agile or other project management methodologies. \n strong experience in managing multidisciplinary data teams. \n ability to structure and lead a technical community\n\n\nkey behavioral skills\n\n excellent interpersonal skills to lead & motivate the team. \n clear communication with stakeholders, including executives and technical staff. \n ability to plan and organize activities efficiently. \n proficient in english, another language is a plus.\n\n\nas a responsible company, opmobility pays particular attention to diversity and equality within its teams and the group commits to treat all job applications equally.",
  "company_name": "opmobility",
  "is_data_profile": true,
  "profile": "data strategist",
  "education_level": 3,
  "experience_years": 10,
  "seniority": "senior",
  "hard_skills": [
    "azure data factory",
    "azure fabric",
    "databricks"
  ],
  "soft_skills": [
    "leadership",
    "communication",
    "planning"
  ],
  "sector": [
    "automotive",
    "technology"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consultant-data-gouvernance-at-gec-global-experts-consulting-4208278220",
  "titre": "consultant data gouvernance",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-04-12",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "gec recrute une consultante data gouvernance  cdi ou freelance\n\nnous recherchons une experte en gouvernance des donnees pour intervenir chez un grand acteur bancaire a casablanca\n\nvotre mission : structurer, securiser et valoriser la donnee a lechelle de lorganisation.\n\nmissions principales :\n\nmise a jour de la politique de gouvernance de donnees\n\ncontribution a la charte de gouvernance et a la definition des roles data\n\nsuivi de l'application des bonnes pratiques en matiere de qualite et darchitecture des donnees\n\naccompagnement a la mise en place de nouvelles solutions si\n\nparticipation a lamelioration continue des processus et outils internes\n\ncompetences techniques :\n\nexcellente maitrise de larchitecture et modelisation data\n\nconnaissance avancee des referentiels et pratiques de gouvernance de donnees\n\nmaitrise des outils data (catalogue, qualite, gestion des metadonnees, etc.)\n\nbonus : data mesh\n\nprofil recherche :\n\nbac+5\n\nsolide experience dans des projets de gouvernance data, idealement en secteur bancaire\n\ncapacite a naviguer entre enjeux techniques et organisationnels",
  "company_name": "gec _ global experts consulting",
  "is_data_profile": true,
  "profile": "data governance analyst",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "data governance",
    "data architecture",
    "data quality"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "problem-solving"
  ],
  "sector": [
    "banking",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/junior-data-engineer-with-ai-focus-at-kenz-up-4214033879",
  "titre": "junior data engineer with ai focus",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-26",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": "morocco",
    "remote": false
  },
  "description": "company overview:\n\nkenzup is a dynamic fintech startup launched in june 2020, funded and backed by a major moroccan corporation. we specialize in financial services and cashback solutions, with our flagship digital cashback application designed to enhance customer retention. kenzup aims to support the national financial inclusion strategy and improve the daily lives of millions of moroccans through a wide range of financial services.\n\nyour role:\n\n assist in the design and implementation of data pipelines that power ai-driven financial solutions\n collaborate with cross-functional teams to collect, process, and transform data to support ai models\n work with large datasets to ensure they are clean, reliable, and optimized for analytical and machine learning purposes\n contribute to the development and maintenance of scalable data infrastructure\n support senior engineers in deploying ai models into production environments\n document data processes, pipelines, and infrastructure to ensure reproducibility and efficiency\n participate actively in team discussions throughout the data lifecycle with a focus on ai applications\n\n\nrequired technical experience:\n\n approximately 3 years of experience in data engineering or a related field\n proficient in python, with experience in data manipulation libraries such as pandas and numpy\n extremely skilled in sql for querying, managing, and transforming large datasets\n experience building data pipelines and etl processes\n familiarity with data warehousing solutions\n understanding of machine learning concepts and ai applications\n exposure to machine learning frameworks such as tensorflow or pytorch is a plus\n experience with cloud services for data and ai, like aws, gcp, or azure\n knowledge of containerization tools such as docker\n experience with version control systems, predominantly git\n comfortable working in agile environments and with continuous integration tools\n strong problem-solving abilities and analytical skills\n effective communication skills in english, both spoken and written\n\n\npowered by jazzhr\n\nqm74iguqcw",
  "company_name": "kenz'up",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 2,
  "experience_years": 3,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "sql",
    "pandas"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "problem-solving"
  ],
  "sector": [
    "fintech"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-science-manager-at-swatx-4225514721",
  "titre": "data science manager",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "swatx is seeking a highly skilled and experienced data science manager to lead our growing data science team. in this strategic role, you will be responsible for overseeing the development and implementation of data-driven solutions to solve complex business challenges. you will mentor and guide a team of data scientists, driving innovation and excellence in analytics and machine learning. if you are a strong leader with a passion for data science and a proven track record of delivering impactful solutions, we invite you to join us.\n\nresponsibilities:\n\n lead and mentor a team of data scientists, providing guidance on best practices in data analysis, machine learning, and statistical modeling\n develop and execute the data science strategy aligned with business objectives, ensuring that data-driven insights are integrated into decision-making processes\n oversee the design and implementation of innovative data science projects that drive value for the organization\n collaborate with cross-functional teams to identify opportunities for leveraging data to improve products, services, and operational efficiency\n build and maintain strong relationships with stakeholders, understanding their data needs and ensuring timely delivery of insights\n monitor and evaluate the performance of data science models and adjust strategies as necessary to achieve desired results\n promote a data-driven culture within the organization by communicating the value of data science initiatives to stakeholders at all levels\n stay updated on the latest trends and developments in data science and analytics, and integrate new methodologies and tools as appropriate\n\n\n\nrequirements\n\n bachelor's or master's degree in data science, computer science, statistics, mathematics, or a related field\n proven experience in a data science role, with at least 5+ years of experience, including 2+ years in a managerial or leadership position\n strong proficiency in programming languages such as python, r, and experience with data manipulation and analysis libraries\n solid understanding of machine learning algorithms, statistical methodologies, and data modeling techniques\n experience with data visualization tools (e.g., tableau, power bi) to communicate findings effectively\n excellent project management skills and ability to prioritize tasks in a fast-paced environment\n strong analytical and problem-solving skills with attention to detail\n exceptional communication skills, both verbal and written, in english and arabic\n proven capability to drive collaboration across teams and influence senior stakeholders\n\n\npreferable certificates:\n\n certified data scientist (cds)\n microsoft certified: azure data scientist associate\n google cloud professional data engineer",
  "company_name": "swatx",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "r",
    "machine learning"
  ],
  "soft_skills": [
    "leadership",
    "communication",
    "collaboration"
  ],
  "sector": [
    "technology"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-anglophone-at-alten-4183887472",
  "titre": "data analyst anglophone",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-13",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\nalten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3300 consultants alteniens en fin 2027. alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\nrejoindre alten maroc cest beneficier :\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers. \n des formations certifiantes et diplomantes. \n des evenements reguliers pour combiner bien etre et performance\n\n\ndescription du poste\n\nen tant que data analyst, vous serez amene a :\n\ngerer le processus de deploiement:\n\n developpement des kpis. \n analyse et difitalisation des processus de deploiement de diverses technologies. \n collection et organisation de donnees issues de differentes sources. \n developpement de rapports power bi. \n collaboration avec les departements fonctionnels et les equipes techniques.\n\n\nqualifications\n\n bac+5 en data. \n ayant min 1 ans dans un poste similaire.\n\n\ncompetences requises:\n\ntechnique:\n\n power bi\n gcp\n sql\n dax\n\n\nlangues :\n\n allemand b2\n anglais courant, assurant lautonomie dans les echanges professionnels et la redaction de documentation technique.\n\n\nsoft skills:\n\n capacite danalyse : aptitude a comprendre des problematiques complexes et a concevoir des solutions adaptees. \n esprit de synthese et redactionnel : clarte dans la presentation des resultats et des recommandations. \n capacite de collaboration : faculte a travailler efficacement avec des equipes interdisciplinaires. \n force de proposition : initiative et creativite dans lidentification d'opportunites d'amelioration et de solutions innovantes. \n reactivite : capacite a gerer les priorites et a sadapter rapidement aux besoins.",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 1,
  "seniority": "junior",
  "hard_skills": [
    "power bi",
    "gcp",
    "sql"
  ],
  "soft_skills": [
    "analysis",
    "communication",
    "collaboration"
  ],
  "sector": [
    "technology",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/crsa-postdoctoral-researcher-in-coastal-ecosystem-monitoring-using-satellite-data-at-um6p-university-mohammed-vi-polytechnic-4209083866",
  "titre": "crsa - postdoctoral researcher in coastal ecosystem monitoring using satellite data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-13",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position title: postdoctoral researcher  coastal ecosystem monitoring and agricultural runoff impacts\n\nduration: 2 years\n\nlocation: mohammed vi polytechnic university (um6p), morocco\n\nabout um6p\n\nlocated at the heart of the future green city of benguerir, mohammed vi polytechnic university (um6p), a higher education institution with international standards, is established to contribute to the development of morocco and the african continent. its vision is honed around research and innovation at the service of education and development. this unique nascent university, with its state-of-the-art campus and infrastructure, has woven a sound academic and research network, and its recruitment process is seeking high-quality academics and professionals in order to boost its quality-oriented research environment in the metropolitan area of marrakech.\n\nabout crsa\n\ncrsa is a transversal structure across several um6p programs. research within the center is organized around several major areas that aim to ensure the challenging food and water security goal in africa, with a special focus on developing methods/tools that use multi-source remotely sensed data. the research aims to improve our understanding of the integrated functioning of continental surfaces and their interaction with climate and humans, with emphasis on sustainable management of natural resources (soil, land, water, agriculture) in the context of climate change. one of the centers goals is to provide a set of services and operational products to users (local, national, and international) that aid in the decision support of water and food systems.\n\nposition overview\n\nthe mohammed vi polytechnic university (um6p) is seeking a highly motivated postdoctoral researcher to work on an interdisciplinary project focused on monitoring the impacts of agricultural runoff on coastal ecosystems along the moroccan coast. the project will utilize advanced satellite remote sensing data (e.g., sentinel-3, landsat, etc.) combined with additional open datasets to assess phytoplankton dynamics, nutrient loading, and harmful algal blooms (habs). the research will contribute to understanding the ecological health of the region.\n\nkey responsibilities\n\n conduct independent research focused on analyzing satellite-derived data (sentinel-3, landsat) to monitor coastal ecosystem changes.\n develop workflows in r, python, or matlab to process and analyze ocean color data, with a focus on chlorophyll-a, suspended particulate matter, and colored dissolved organic matter (cdom).\n assess the impact of agricultural runoff on coastal water quality, particularly nutrient enrichment and its relationship with phytoplankton blooms.\n use remote sensing to detect harmful algal blooms (habs) and assess their spatiotemporal variability along the moroccan coastline.\n investigate links between satellite data and key ecological indicators, including the presence of phytoplankton species indicative of nutrient imbalances.\n collaborate with researchers and institutions (e.g., ocp group) to align the research with sustainable agriculture and environmental monitoring initiatives.\n contribute to scientific publications, project reports, and presentations at international conferences.\n potentially assist in proposal writing to seek additional funding for fieldwork.\n\n\nqualifications\n\n phd in oceanography, environmental sciences, remote sensing, or a related field.\n strong expertise in satellite remote sensing, including atmospheric correction techniques.\n proficiency in r, python, or matlab for data processing, geospatial analysis, and statistical modeling.\n experience with time series analysis, spatial mapping, and oceanographic data interpretation.\n experience in writing scientific papers and presenting research results.\n ability to work independently and collaboratively in an interdisciplinary research environment.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "research scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "remote sensing",
    "python",
    "matlab"
  ],
  "soft_skills": [
    "research",
    "collaboration",
    "communication"
  ],
  "sector": [
    "research",
    "environmental science"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consultant-data-architecte-at-gec-global-experts-consulting-4172860736",
  "titre": "consultant data architecte",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-03-07",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "gec recrute un data architecte !\n\nvous etes passionne par la gestion et larchitecture des donnees ? vous souhaitez evoluer dans un environnement dynamique et strategique ?\n\ngec recherche un data architecte pour accompagner un client dans la conception et loptimisation de son architecture de donnees.\n\nvos missions principales :\n\nconception et optimisation de larchitecture data : definir et mettre en place des modeles de donnees robustes et evolutifs.\n\ngouvernance et securite des donnees : veiller a la qualite, a la securite et a la conformite des donnees avec les normes en vigueur (rgpd, dpo).\n\nmigration et integration des donnees : concevoir des pipelines de donnees efficaces et superviser la migration vers des environnements cloud/hybrides.\n\ncollaboration avec les equipes techniques et metiers : travailler en etroite collaboration avec les equipes it, data science et bi pour aligner larchitecture data avec les objectifs strategiques.\n\nveille technologique et innovation : assurer une veille active sur les nouvelles technologies et proposer des solutions innovantes.\n\nprofil recherche :\n\nformation : bac+5 en informatique, data management, ou ingenierie.\n\nexperience : minimum 5 ans dexperience en architecture de donnees ou en gestion de bases de donnees.\n\ncompetences techniques : maitrise des outils et technologies big data, cloud (aws, azure, gcp), etl, sql, nosql, data lake, data warehouse.\n\nexpertise en gouvernance des donnees et en modelisation de bases de donnees (dimensionnelle, relationnelle).\n\ncapacite a travailler en mode agile et en environnement multi-projets.",
  "company_name": "gec _ global experts consulting",
  "is_data_profile": true,
  "profile": "data architect",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "big data",
    "cloud",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "problem-solving"
  ],
  "sector": [
    "consulting",
    "technology"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-scientist-tech-lead-at-oracle-4181967787",
  "titre": "senior data scientist - tech lead",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-17",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "job description\n\ncreate the future with us\n\nsenior data scientist  madc\n\ncasablanca (onsite)\n\nas an senior data scientist at oracle madc, you will play a pivotal role in shaping the future of oracle offerings. you will be part of an innovative team who works with cutting-edge technologies to bring ai capabilities into oracle products. in this role you will:\n\n design, develop, and maintain ai and ml models (including generative ai), ensuring\n\n\n\nit meets the high standards required by oracle.\n\n perform data processing, cleansing and quality verification (data engineering)\n ensure data curation by implementing proper labeling and classifications.\n leverage nlp techniques to categorize textual inputs while considering different aspects such as nl intent complexities etc.\n conduct rigorous testing and validation processes to ensure the models' accuracy\n\n\n\nand efficiency.\n\n stay updated with the latest advancements in ai and machine learning,applying innovative techniques and methodologies to continually enhance our\n\n\n\nsystems.\n\n engage with stakeholders to translate complex business requirements into\n\n\n\nrobust technical solutions.\n\n participate in the full lifecycle of the project, from conception through deployment and ongoing maintenance, ensuring they align with our strategic objectives and deliver maximum value.\n\n\n\nrequirements\n\n bachelors or masters degree in computer science, artificial intelligence, machine\n\n\n\nlearning, data science or a related field.\n\n a minimum of 2 years of experience developing machine learning algorithms and data science.\n extensive knowledge of large language models and natural language processing\n\n\n\ntechniques.\n\n good knowledge of sql.\n strong proficiency in programming languages such as python, java, or c++.\n excellent problem-solving skills and the ability to work independently on complex\n\n\n\nprojects.\n\n strong communication and collaboration skills, with a proven track record of\n\n\n\nworking effectively in cross-functional teams.\n\n demonstrated ability to deliver high-quality software products within a fast-\n\n\n\npaced, dynamic environment.\n\nwhat we will offer you\n\n a competitive salary with exciting benefits.\n learning and development opportunities to advance your career.\n an employee assistance program to support your mental health.\n employee resource groups that champion our diverse communities\n core benefits such as life insurance, and access to retirement planning\n an inclusive culture that celebrates what makes you unique\n\n\n\nat oracle, we dont just respect differenceswe celebrate them. we believe that innovation starts with inclusion and to create the future we need people with diverse backgrounds, perspectives, and abilities. thats why were committed to creating a workplace where all kinds of people can do their best work. its when everyones\n\nvoice is heard and valued that were inspired to go beyond whats been done before.\n\ncreate the future with us\n\ncareer level - ic3\n\nresponsibilities\n\nas a member of the software engineering division, you will assist in defining and developing software for tasks associated with the developing, debugging or designing of software applications or operating systems. provide technical leadership to other software developers. specify, design and implement modest changes to existing software architecture to meet changing needs.\n\nabout us\n\nas a world leader in cloud solutions, oracle uses tomorrows technology to tackle todays challenges. weve partnered with industry-leaders in almost every sectorand continue to thrive after 40+ years of change by operating with integrity.\n\nwe know that true innovation starts when everyone is empowered to contribute. thats why were committed to growing an inclusive workforce that promotes opportunities for all.\n\noracle careers open the door to global opportunities where work-life balance flourishes. we offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. we also encourage employees to give back to their communities through our volunteer programs.\n\nwere committed to including people with disabilities at all stages of the employment process. if you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the united states.\n\noracle is an equal employment opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans status, or any other characteristic protected by law. oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.",
  "company_name": "oracle",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "sql",
    "machine learning"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "problem-solving"
  ],
  "sector": [
    "technology"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-analyst-at-innovx-4198560506",
  "titre": "senior data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "innovx is an impact business builder with a mission to shape the industries of tomorrow by investing in and developing innovative, high-impact companies and ecosystems.\n\n\noperating in critical sectors such as agriculture & water, social innovation, energy, chemistry, and digital, innovx actively contributes to sustainability and technological leadership in morocco.\n\n\nposition overview:\nas a data analyst at innovx, you will be responsible for managing the collection, processing, and analysis of data, ensuring its quality, deriving actionable insights, and presenting findings in a visually clear and engaging format. you will also maintain data lineage and manage the data dictionary to ensure consistency and clarity across teams.\n\n\nresponsibilities:\n data analysis:\ncollect, process, and analyze large datasets to identify trends, patterns, and correlations that inform business decisions.\n data quality :\nensure data accuracy, consistency, and integrity by implementing data validation techniques and addressing quality issues as they arise.\n data dictionary and lineage:\nmaintain and update the data dictionary to ensure standardized definitions and usage across teams. track data lineage to ensure transparency and traceability of data sources and transformations.\n data insights:\nextract actionable insights from data and communicate findings through clear visualizations and reports that support strategic decision-making.\n\n\nqualifications:\n experience: 3+ years of experience in data analysis, data quality and or data governance, with a significant focus on data and/or ia.\n data-visualisation: proficient with at least one data visualization tools such as power bi, tableau, as well as open-source tools like metabase and superset.\n data governance knowledge : strong understanding of data management and governance challenges, including data quality, security, and compliance.\n data-driven: comfortable analyzing data to derive insights and using those insights to inform product development and strategic decisions.\n data quality : expertise in ensuring data accuracy, consistency, and integrity throughout the data lifecycle. skilled at identifying and resolving data quality issues, implementing validation processes, and maintaining high standards for data governance to support reliable decision-making.\n functional analysis: proven ability to conduct functional analysis and define clear requirements with a focus on data, ensuring that business needs are effectively translated into actionable product features and algorithms.\n customer-centric: strong customer empathy and the ability to translate customer needs into actionable product features and enhancements.\n agile methodology: agile mindset and experience with agile development methodologies and tools.\n communication: excellent communication and interpersonal skills.\n problem solver: strong problem-solving skills and the ability to adapt in a rapidly changing environment.\n education: master's in computer science, statistics, mathematics, or a related field from a top engineering school (emi, ensias, or equivalent) or university.",
  "company_name": "innovx",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "senior",
  "hard_skills": [
    "power bi",
    "data quality",
    "data governance"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "customer-centric"
  ],
  "sector": [
    "business",
    "technology"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-junior-f-h-at-deloitte-4174440463",
  "titre": "data analyst junior f/h",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-04",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "marche : maroc et afrique francophone\n\ntous nos postes sont ouverts au teletravail\n\nrejoindre deloitte, c'est dire oui a une experience qui a du sens, celle ou les rencontres et les missions vous poussent a grandir chaque jour. cest evoluer dans un environnement de travail base sur la confiance, la transmission et lintelligence collective pour construire lavenir de nos clients. un avenir que nous voulons plus responsable, plus durable et respectueux de lenvironnement en prenant des initiatives concretes a notre echelle. nous rejoindre, cest aussi dire oui a une entreprise attachee au bien etre, et a linclusion sans distinction de nos collaborateurs.\n\net vous, prets a dire #isayyes a votre futur chez deloitte?\n\ndeloitte est present sur lensemble du continent africain notamment en afrique francophone, anglophone et lusophone et met son expertise au service de ses clients en afrique.\n\nen afrique francophone deloitte est present en afrique du nord, en afrique de louest et en afrique centrale et dispose de 12 bureaux avec une capacite d'intervention sur 19 pays deloitte mobilise plus de 1 500 collaborateurs dans les activites de consulting, daudit assurance, de conseil juridique et fiscal, de risk advisory, de financial advisory et de business outsourcing.\n\nen tant que firme multidisciplinaire, deloitte offre a ses clients un accompagnement de proximite et sur mesure grace a la maitrise des enjeux locaux afin de repondre aux attentes et aux besoins des acteurs publics et prives (assurances, technologies medias telecoms, sante, consumer business, energie...). deloitte collabore aussi avec les grands bailleurs de fonds internationaux pour fournir une assistance strategique, operationnelle et technique afin de soutenir des projets et des initiatives de developpement dans differentes regions du monde.\n\ndans le cadre du developpement de notre activite en data analytics, nous recherchons pour notre bureau de casablanca, au maroc, un data analyst junior.\n\nen rejoignant notre equipe, vous serez amene(e) a mettre vos competences au service de clients de premier plan dans tous les secteurs dactivites. notre gestion des talents vous permettra de beneficier dun parcours de formation de qualite et de developper vos competences.\n\nquel sera votre role dans la #teamdeloitte ?\n\nvous integrez nos equipes data en tant que data analyst junior pour intervenir sur des missions variees visant a accompagner nos clients dans les projets de transformation data et dans leurs enjeux de gestion des risques. vos missions sont :\n\n audit et control analytics : vous mettez en uvre des techniques avancees d'analyse de donnees en remplacement des diligences traditionnelles d'audit.\n data preparation : vous traitez et transformez des donnees avec python (numpy, pandas).\n data analytics : vous analysez les donnees pour identifier des anomalies et justifier les ecarts.\n data visualisation : vous mettez en uvre des tableaux de bord et des outils d'analyse exploratoire sur les donnees risques de nos clients.\n data modeling : vous concevez des modeles decisionnels capables de repondre aux problematiques business en tenant compte des aspects lies a la gouvernance des donnees.\n data architecture : vous accompagnez a la definition et a la mise en uvre de hub data, et assurez son administration.\n data science : vous realisez des predictions et modelisations sur des sujets reglementaires ou metiers financiers (ex : quantification, risques de credit...), mais egalement sur des missions operationnelles (ex : prevision des ventes, prevision des risques projets...).\n\n\n\net si cetait vous ?\n\n vous etes titulaire dun diplome en data science, ou d'ingenieur/cycle universitaire bac +5 avec une specialisation en data science/business intelligence et informatique ;\n vous beneficiez idealement dune premiere experience (notamment lors des stages) en business intelligence et data analytics dans les domaines de la gestion, l'analyse et l'interpretation des donnees,\n vous avez travaille sur des projets dans les environnements technologiques suivants :\n data preparation : python (pandas, numpy), etl (talend, informatica, ssis...).\n data visualisation : powerbi, tableau, qlik...\n data query: sql (mysql, postgresql, sql server)\n big data : cloudera, spark, hive, pyspark, impala\n data science : dataiku, knime, ibm spss\n vous avez une aisance relationnelle et le sens du collectif,\n vous faites preuve dintelligence emotionnelle et dempathie,\n vous maitrisez le francais et langlais a loral et a lecrit et vous disposez d'un excellent relationnel.",
  "company_name": "deloitte",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "sql",
    "powerbi"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "adaptability"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-at-altados-by-niji-4174456054",
  "titre": "data engineer",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-03-04",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "altados by niji recrute un data engineer avec au moins 5 ans dexperience pour lun de ses clients.\n\n\nmissions :\n concevoir, developper et optimiser les pipelines de donnees\n gerer et structurer des bases de donnees massives\n implementer des solutions de traitement et de transformation des donnees\n assurer la qualite, la gouvernance et la securite des donnees\n collaborer avec les equipes data science et bi\n\n\ncompetences requises :\n experience en etl, ingestion et transformation de donnees\n maitrise de python, sql, spark\n experience avec les plateformes cloud (aws, gcp, azure)\n connaissance des architectures big data, data lakes, data warehouses\n experience avec kafka, airflow, snowflake (un plus)",
  "company_name": "altados by niji",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/quant-analyst-quant-developer-data-scientist-graduate-programme-2025-at-ensimag-alumni-4216343668",
  "titre": "quant analyst / quant developer / data scientist - graduate programme 2025",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-24",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "postee le 24 avr.\n\nlieu : casablanca, morocco\n\n contrat : cdi\n remuneration : competitive \n\n\nsociete : phi partners\n\nphi partners is a boutique technology consulting firm providing services and products to investment banks, hedge funds, and asset management firms. headquartered in london, with a global presence in key financial hubs like new york and paris, phi specialises in fo\n\nand risk technology. our niche focus on these domains has been a differentiator and\n\ngateway into the worlds best-known financial institutions.\n\ndescription du poste\n\nphis 2025 graduate programme starts in september. you will join phi as part of a community of graduates  like-minded, talented young people with whom you will form not just professional but also social bonds that may last a lifetime.\n\nunder our two-year programme, our graduates begin their journey at phi with four to six weeks of intensive classroom-based training, delivered by our business and technical experts. after the intensive training, you will join your first client-facing team as junior consultant, and you will be assigned a learning buddy, a senior colleague who will help you navigate these first steps of your career.\n\nyour training doesnt stop there. you will continue formal training over the two years, and we will make sure time is made available for this. in parallel with the experience that you gain in your client role, we will give you all the support you need to develop the all-round consulting skills necessary for promotion to consultant at the end of the two-year programme.\n\nat phi we pride ourselves that all our employees  including the most senior subject matter experts  are friendly and approachable. with a focus on teamwork and knowledge sharing, we value every employee and their ongoing learning and development.\n\nas one of our delivery consultants, you will be assigned to one of our international project teams, in our delivery centre in casablanca (morocco).\n\nyou will be\n\nworking with a variety of different financial institutions across the whole capital markets sector\n\nhelping our clients run or transform their technology, or shape their technology strategy\n\nplaying an essential and effective role in both the client team and the wider phi family: learning from our experts, supporting your colleagues, and constantly striving for excellence.\n\nyou may also get the opportunity to travel to different locations across europe and beyond, if this is something that you would like to do. as a quant developer, or quant it developer your primary career focus will be in supporting our clients business to implement financial models provided by the clients quant team.\n\nas a quant developer, you will typically work in a trading or risk management environment alongside traders, quants and risk managers. as a quant it developer, you will work within the it department that focusses on one of these business areas.\n\nyou will work to implement maintain and integrate the libraries and systems that support those users day-to-day across multiple asset classes, including structured and exotic products.\n\nyou may have a primary technology focus but each client role will be different, and each project will be different.\n\nyou can expect to work across a range of languages, frameworks and technologies in a variety of business and project contexts.\n\nyour roles could include pricing and risk implementation, quant library design and implementation, quantitative model development and integration, trading desk troubleshooting and support, minor enhancements, bug fixing, data design and management, and integration into distributed compute environments or cloud compute.\n\nlonger term, is it usual that the career path is to become a subject-matter-expert within this area, adding leadership and other skills as you develop.\n\nprofil recherche\n\nwe are looking for talented graduates who have an interest in pursuing a career in capital markets technology, in a consulting context  where each client is different, and each engagement provides a new challenge and a new opportunity for learning.\n\neducation\n\nminimum masters degree in mathematics computer science or finance\n\nother skills and capabilities\n\nfamiliarity with the relevant technical vocabulary\n\ngood knowledge of quantitative methods\n\nobject oriented programming (any of c++/c#/java) at an educational level or from personal projects sql, shell scripts, perl or python, xml/xslts\n\nfamiliarity with design patterns\n\nbasics in devops (automation as part of continuous integration / continuous development)\n\nvoir le fichier joint\n\npour postuler\n\nif you think you have what it takes to become one of our expert consultants and to collaborate with some of the most talented people in their fields, contact us at aleeha.murtaza@phipartners.com\n\nwe receive a high volume of applications, and while we carefully review each one, only shortlisted candidates will be contacted. if you do not hear from us within two weeks, unfortunately, your application has not progressed to the next stage.",
  "company_name": "ensimag alumni",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "python",
    "c++"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consultants-d%C3%A9veloppeurs-confirm%C3%A9s-data-integration-h-f-at-we-are-beebay-4201035456",
  "titre": "consultants developpeurs confirmes data integration h/f",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-04",
  "location": {
    "city": "prefecture of casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "we are beebay est un cabinet it specialise dans le conseil et l'implementation de plateformes d'integration. notre expertise s'articule autour des hip  hybrid integration platforms  et plus particulierement les technologies ipaas et pubsub. nos clients sont principalement bases en europe et au moyen orient.\n\n\npour accompagner notre forte croissance, nous sommes a la recherche de :\n\n\nconsultants developpeurs confirmes data integration h/f\npostes bases a casablanca, maroc\n\n\n ton role\nintegre(e) dans une equipe dynamique et a taille humaine, tu prendras en charge les missions suivantes :\n redaction des contrats dinterface.\n conception des flux de donnees (exposition des apis/ mapping de donnees /...).\n realisation des tests unitaires.\n deploiement/execution des flux d'integration.\n realisation des tests dintegration.\n accompagnement a la mise en production.\n traitement des anomalies et des evolutions.\n participation a des webinars, ...\n\n\nton profil\nde formation bac+5 en informatique, tu as 2 a 3 annees d'experience dont une annee dans le domaine de l'integration (soa, ipaas, etl, etc.)\ntu disposes dune experience significative dans lune des technologies tels que boomi, mulesoft, tibco, talend, informatica, etc...\nfrancais (oral/ecrit) indispensable et langlais est un plus.\ntu as un bon relationnel et un bon team spirit ?\nalors lequipe beebay tattend ! \n\n\n#nos atouts\n rejoignez beebay, entreprise agile au fonctionnement en mode startup\n parcours de formations et certifications sur la solution boomi, solace et gravitee pour tous les nouveaux collaborateurs beebay\n rejoindre une boite en plein developpement au maroc et en france\n projets innovants autour de la data a dimension internationale\n poste challengeant avec un partage de connaissance permanent\n\n\n\n\n \nsi tu souhaites relever des challenges au quotidien et intervenir sur des projets data denvergures, nhesites plus a postuler !",
  "company_name": "we are beebay",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "mid",
  "hard_skills": [
    "sql",
    "boomi",
    "api"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cus-postdoctoral-researcher-in-spatial-data-science-at-um6p-university-mohammed-vi-polytechnic-4211989444",
  "titre": "cus - postdoctoral researcher in spatial data science",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-17",
  "location": {
    "city": null,
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "postdoctoral researcher in spatial data science\n\nposition description\n\nwe are seeking a postdoctoral researcher specializing in urban modeling and cost analysis to develop an innovative model to estimate the direct and indirect costs of urbanization based on urban morphology (compact or sprawling). the candidate will analyze real case studies, integrate variables related to infrastructure, health, and the environment, and simulate scenarios under different climatic and social contexts to provide decision-making tools for sustainable urban planning.\n\nmain tasks and responsibilities\n\n develop a predictive model integrating the direct and indirect costs of urbanization.\n calibrate this model using real data from specific case studies.\n simulate urbanization costs based on various climatic, morphological, and social scenarios.\n formulate innovative methodological approaches.\n produce publications on research in scientific journals.\n participate in teaching activities.\n develop new research proposals.\n\n\nrequired qualifications\n\n ph.d. in data science, urban planning, urban economics, or a related field.\n experience in research projects applied to urban, environmental, or socio-economic issues.\n proficiency in urban modeling tools such as matlab, python (especially libraries like pandas, numpy, scipy, geopandas, etc.), and r.\n advanced skills in predictive modeling and machine learning, particularly for multi-variable simulations.\n knowledge of complex systems modeling applied to urban dynamics.\n publications in scientific journals.\n\n\npersonal and organizational qualifications\n\n ability to develop innovative methods.\n ambition for research excellence.\n interest in african issues.\n entrepreneurial mindset, dynamism, and organizational skills.\n fluency in both french and english (oral and written) is required.\n\n\nwe offer\n\n excellent working conditions and competitive salary on an international scale.\n an opportunity to contribute to the development of research excellence in africa.\n a highly stimulating multicultural working environment and a great team atmosphere.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "geospatial data scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "matlab",
    "r"
  ],
  "soft_skills": [
    "communication",
    "research",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consultant-data-viz-bi-h-f-at-devoteam-4176286825",
  "titre": "consultant data viz / bi (h/f)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-06",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\nchez devoteam, nous sommes des  digital transformakers . le respect, la franchise et la passion animent chaque jour notre tribu.\n\nensemble, nous aidons nos clients a remporter la bataille du digital : du conseil a la mise en uvre de technologies innovantes, jusqua ladoption des usages.\n\ncloud, cybersecurity, data, devops, fullstack dev, low code, rpa nont plus aucun secret pour notre tribu !\n\nnos 10 000+ collaborateurs sont certifies, formes et accompagnes au quotidien pour relever de nouveaux challenges innovants.\n\nleader du cloud, de la cybersecurite et de la data en emea, le groupe devoteam a realise en 2022 un chiffre daffaires de 1,036 milliard deuros et se donne pour ambition de le doubler dans les 5 annees a venir.\n\ndevoteam maroc, acteur de reference dans les expertises it depuis plus de 30 ans  (350+ consultants) accelere sa croissance en developpant ses activites dexpertise en nearshore pour repondre aux besoins de nos clients francais, europeens et moyen orientaux.\n\nes-tu pret(e) a nous rejoindre et relever ensemble ce defi ?\n\n\ndescription du poste\n\nen tant que consultant data viz / bi, vous serez responsable de la conception, de la mise en place et de loptimisation de tableaux de bord interactifs sur tableau. vous travaillerez en etroite collaboration avec les equipes metiers et techniques afin de transformer les donnees en informations strategiques exploitables.\n\nmissions principales\n analyse des besoins metiers et comprehension des enjeux strategiques lies aux donnees.\n conception et developpement de tableaux de bord interactifs sur tableau en integrant les meilleures pratiques en matiere de data visualization.\n optimisation et maintenance des solutions existantes pour garantir leur performance et leur ergonomie.\n extraction, transformation et modelisation des donnees a partir de diverses sources (sql, data warehouses, fichiers plats, apis, etc.).\n assurer la qualite des donnees et la coherence des indicateurs en collaboration avec les equipes data et bi.\n accompagner et former les utilisateurs sur lexploitation des dashboards et la prise en main de tableau.\n veille technologique et amelioration continue des outils et methodologies bi.\n\n\n\n\nqualifications\n\ncompetences techniques\n maitrise de tableau (creation de dashboards, calculs avances, gestion des permissions, deploiement sur tableau server/online).\n solides competences en sql pour lextraction et la manipulation des donnees.\n bonne connaissance des concepts de modelisation des donnees et des architectures bi.\n experience avec d'autres outils bi (power bi, qlik sense) est un plus.\n connaissance des bases de donnees relationnelles (postgresql, mysql, sql server...).\n experience avec etl (alteryx, talend, informatica) est un atout.\n\n\n\ncompetences fonctionnelles\n diplome bac+5 en informatique, statistiques, data science ou domaine equivalent.\n minimum 4 ans dexperience en bi et data visualization, avec une expertise averee sur tableau.\n capacite a analyser et comprendre les besoins metiers.\n bonne maitrise de la data visualisation et storytelling pour creer des dashboards impactants.\n esprit critique et capacite a transformer des donnees brutes en insights strategiques.\n excellente capacite de communication et pedagogie pour accompagner les utilisateurs.\n\n\n\ntype de contrat\n cdi \n 100% presentiel a casablanca\n\n\n\n\ninformations supplementaires\n\n  https://www.linkedin.com/company/devoteam\n https://twitter.com/devoteam\n https://www.facebook.com/devoteam",
  "company_name": "devoteam",
  "is_data_profile": true,
  "profile": "data visualization specialist",
  "education_level": 3,
  "experience_years": 4,
  "seniority": "senior",
  "hard_skills": [
    "tableau",
    "sql",
    "powerbi"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-manpowergroup-4207336710",
  "titre": "data analyst",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "manpowergroup recrute : data analyst (h/f)\n\n\ntu es passionne(e) par les donnees, rigoureux(se), et tu aimes donner du sens aux chiffres pour accompagner la prise de decision ? rejoins notre equipe en tant que data analyst !\n\n\ntes missions principales :\n nettoyage, fiabilisation et structuration des donnees\n analyse, exploration et interpretation des donnees pour identifier des tendances cles\n elaboration et mise en place de tableaux de bord & kpis permettant de piloter l'activite et ameliorer la performance (prestation france travail / cep)\n creation doutils sur mesure a destination des equipes operationnelles\n presentation des analyses aux responsables de region, de site et fonctions support\n redaction de la documentation technique\n reporting et actualisation hebdomadaire des dashboards\n\n\nenvironnement technique :\n python, excel\n power bi pour la datavisualisation\n\n\nce poste est fait pour toi si tu es a laise avec les outils de data, que tu sais rendre les chiffres parlants et que tu veux avoir un impact concret sur le pilotage de lactivite.\n\n\n poste base a casablanca, \n disponibilite : immediate",
  "company_name": "manpowergroup",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "excel",
    "powerbi"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-at-red-tic-4185847416",
  "titre": "data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-15",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "freelance\n rabat\n publie il y a 3 mois\n\n\ndescription\n\nthe data engineer is responsible for designing, developing, and maintaining the infrastructure and systems required for data storage, processing, and analysis. they play a crucial role in building and managing the data pipelines that enable efficient and reliable data integration, transformation, and delivery for all data users across the enterprise.\n\nexperience\n\njob requirements\n\nsenior data engineer\n\n minimum of  8 years of experience in data engineering, with at least 4 years of hands-on experience with databricks. \n at least 8 years of work experience in data management disciplines, including data integration, modeling, optimization and data quality, or other areas directly relevant to data engineering responsibilities and tasks.\n\n\nmedium data engineer\n\n minimum of 5 years of experience in data engineering, with at least 2 years of hands-on experience with databricks. \n at least 5 years of work experience in data management disciplines, including data integration, modeling, optimization and data quality, or other areas directly relevant to data engineering responsibilities and tasks.\n\n\nresponsibilities\n\n designs, develops, and maintains robust data pipelines using databricks and apache spark, that extract data from various sources, transform it into the desired format, and load it into the appropriate data storage systems. \n implement and manage advanced data products in our medallion architecture. \n implement and manage advanced data models, including dimensional, relational, and data vault modeling techniques. \n integrates data from different sources, including databases, data warehouses, apis, and external systems. \n ensures data consistency and integrity during the integration process, performing data validation and cleaning as needed. \n transforms raw data into a usable format by applying data cleansing, aggregation, filtering, and enrichment techniques. \n optimizes data pipelines and data processing workflows for performance, scalability, and efficiency. \n monitors and tunes data systems, identifies and resolves performance bottlenecks, and implements caching and indexing strategies to enhance query performance. implements data quality checks and validations within data pipelines to ensure the accuracy, consistency, and completeness of data. \n manage databricks unity catalog including administrative activities (policies, security, access control, cost control). \n optimize and administer databricks environments to ensure high performance and reliability. \n cluster configuration and policy management in databricks. \n build and maintain ci/cd pipelines (devops) in github or azure devops. \n collaborate with cross-functional teams to deliver comprehensive data solutions. \n ensure data quality, security, and governance across all data processes. \n communicate effectively with stakeholders to understand requirements and deliver actionable insights. \n operate within agile teams, contributing to continuous improvement in data engineering practices and processes.\n\n\nskills\n\n databricks certifications (associate, professional, administration). \n proficiency in modern data modeling techniques and data administration. \n strong knowledge of sql, python, pyspark. \n experience with cloud platforms such as aws and azure. also, very familiar with aws iam and azure ad security mechanisms.\n expert problem-solving skills, including debugging skills, allowing the determination of sources of issues in unfamiliar code or systems, and the ability to recognize and solve repetitive problems. \n strong communication skills and a proactive,  getting things done  mindset. \n experience working in agile teams and familiarity with agile methodologies. \n ability to design, build, and deploy data solutions that capture, explore, transform, and utilize data to support ai, ml, and bi. \n proficiency in the design and implementation of modern data architectures and concepts such as cloud services (aws, azure, gcp) and modern data warehouse tools (snowflake, databricks). \n experience with database technologies such as sql, nosql, oracle, hadoop, or teradata. \n ability to collaborate within and across teams of different technical knowledge to support delivery and educate end users on data products. \n excellent business acumen and interpersonal skills; able to work across business lines at a senior level to influence and effect change to achieve common goals. \n ability to describe business use cases/outcomes, data sources and management concepts, and analytical approaches/options. \n ability to translate among the languages used by executive, business, it, and quant stakeholders.\n\n\nrecruitment consulting management training sourcing job jobs offer internship morocco africa java developpement developpement developpeur developpeur informatique application it jee android consultant devops fullstack. dabord. tout dabord. en premier lieu. ensuite, de plus. finalement. en outre. par ailleurs. en dernier lieu. enfin. dabord, en premier lieu, pour commencer, premierement, en conclusions ur conclure, enfn, finalement, en dernier lieu, bien que. il y a aussi il est vrai que... mais. tout en reconnaissant que... on peut supposer que. par exemple . en fait . prenons le cas de. considerons, par exemple. lexemple le plus r. cependant. mais. pourtant. toutefois. neanmoins. contraste. alors que. tandis que. par contre. en revanche engineer\n\nnom et prenom\n\nadresse email\n\nmobile\n\nniveau d etude\n\nbac bac +1 bac +2 bac +3 bac +4 bac +5 bac + x\n\nannees dexperience\n\n0 +1 +2 +3 +4 +5 +6 +7 +8 +9 + 10\n\npreavis\n\ndisponible immediatement -1 mois 1 mois 2 mois +2 mois\n\nmessage\n\nupload cv\n\nteleverser votre cv ou tout autre document relatif. taille max: 2 mb.",
  "company_name": "red tic",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "python",
    "pyspark"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-attijariwafa-bank-4181774821",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-11",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "attijariwafa bank est le premier groupe bancaire et financier du maghreb et un acteur financier de reference en afrique. en plus de lactivite bancaire, le groupe opere, a travers des filiales specialisees, dans tous les metiers financiers : assurance, credit immobilier, credit a la consommation, leasing, gestion dactifs, intermediation boursiere, conseil, location longue duree, factoring... attijariwafa bank est basee au maroc et opere dans 25 pays. avec 20 602 collaborateurs, le groupe attijariwafa bank compte 10,2 millions de clients. il dispose du reseau de distribution le plus large au maroc et le plus dense en afrique avec 5 265 agences.\n\nnotre banque, leader dans le secteur financier national, est a la recherche d'un data analyst senior pour rejoindre notre equipe gouvernance de donnees au sein du data office. en tant que membre cle de notre equipe, vous participerez activement a la mise en application de la strategie data management en termes d'amelioration de la qualite de donnees et de la bonne gestion des metadata et des donnees de reference (master data management) de la banque et de ses filiales conformement aux orientations strategiques du groupe.\n\nvos missions :\n\n veiller au respect des politiques et processus data liees a la qualite de la donnee, metadata et mdm.\n expertise en matiere d'analyse et profiling de donnees, developpement des datajobs, et remediation des donnees.\n expertise en matiere de conception, design et developpement de solutions de dashbording.\n pilotage et suivi de l'activite data quality, metadata & mdm.\n accompagnement des metiers et des acteurs de l'organisation data dans leurs besoins d'amelioration de la qualite de donnees, gestion des referentiels et dictionnaires de donnees.\n administration et evolution de la plateforme data management.\n conduite de projets et initiatives data tout en respectant les delais, budgets et la qualite des livrables.\n developpement des modeles predictifs et des algorithmes complexes pour ameliorer la qualite el la remediation des donnees.\n\n\nprofil recherche :\n\n diplome dingenieur en informatique/statistiques ou equivalent.\n experience professionnelle pertinente (5ans et plus) en tant que data analyst, consultant business intelligence, data scientist, de preference dans le secteur financier.\n capacite demontree a travailler avec de grands ensembles de donnees et a tirer des insights significatifs.\n bonnes capacites danalyse, de synthese et dorganisation.\n management dequipe et leadership.\n excellentes competences en communication et capacite a travailler en equipe.\n maitrise des langages de programmation/requetage tels que python, sql, sas.\n maitrise dau moins un outil de dashboarding (sas visual analytics, qlikview, bo, qliksense, tableau, power bi, ...)\n capacites decoute et orientation client.",
  "company_name": "attijariwafa bank",
  "is_data_profile": true,
  "profile": "data governance analyst",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "sas"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "leadership"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-scientist-for-seo-at-white-light-digital-marketing-4226135229",
  "titre": "data scientist for seo",
  "via": null,
  "contrat": "part-time",
  "type_travail": null,
  "publication_date": "2025-05-08",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "data scientist \n\ncan you turn messy seo data into clear, actionable growth wins?\n\nwere looking for a data scientist who can take large, unstructured seo datasets and extract insights that drive rankings, traffic, and revenue. youll work closely with our seo strategists to identify opportunities, test hypotheses, and measure what actually moves the needle.\n\nwe're a strategy-first digital agency trusted by private equity firms and 8-figure ecom brands. we hire smart, self-managing people who want freedom, not babysitting. youll own your outcomes, go deep into data, and help shape seo strategy at a high level.\n\ncompensation & next steps\n\n (contract, based on experience)\n part-time trial period (paid), then full-time contract\n fully remote, async teamwork from anywhere\n\n\nthe role\n\nwhat youll own\n\n building data models that forecast seo impact and roi\n automating the analysis of rankings, traffic, and content performance\n identifying patterns across serp behavior, competitors, and user intent\n creating dashboards that guide strategic seo decisions\n running statistical tests to validate seo experiments\n\n\nideal profile\n\nwho you are\n\n 2+ years working with seo or digital marketing datasets\n advanced skills in python, sql, and data visualization (looker, power bi, or similar)\n experience with web scraping, apis (google search console, ga4), and nlp\n comfortable presenting technical findings to non-technical stakeholders\n bonus: familiarity with content clustering, internal linking, and topical authority\n\n\nwhat's on offer?\n\n work alongside & learn from best in class talent\n excellent career development opportunities\n attractive salary & benefits",
  "company_name": "white light digital marketing",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "sql",
    "data visualization"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "adaptability"
  ],
  "sector": [
    "marketing",
    "digital marketing"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/head-of-data-at-sobrus-4189011070",
  "titre": "head of data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-19",
  "location": {
    "city": "skhirat-temara",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "a propos de sobrus\n\nsobrus est sobrus est une startup marocaine en pleine croissance, specialisee dans l'edition de solutions de gestion 100% cloud dediees au domaine de la sante. nous developpons des applications web et mobiles, qui ont un impact positif sur la sante des patients. nos services sont disponibles dans 14 pays a travers le monde, couvrant l'afrique et l'europe . toute lequipe de sobrus est animee par sa passion et est entierement obsedee par la satisfaction client.\n\na propos de poste\n\na propos du poste\n\nen tant que head of data, vous aurez pour mission de structurer et piloter la strategie data de l'entreprise, en accompagnant les equipes internes a exploiter la donnee de maniere agile et en developpant des solutions avancees (analyses predictives, intelligence artificielle, etc.) afin de creer de la valeur pour le marche.\n\na ce titre, vos missions principales seront les suivantes :\n\n definir et mettre en uvre une strategie data alignee avec la vision et les objectifs de lentreprise.\n assurer la gouvernance des donnees : qualite, accessibilite, conformite reglementaire (rgpd, loi 09-08 au maroc, etc.).\n mettre en place les meilleures pratiques en matiere de gestion, de stockage et de securisation des donnees.\n accompagner les equipes (product, tech, marketing, sales, customer success, finance) dans l'utilisation de la donnee pour orienter chaque decision.\n mettre en place des outils de visualisation et d'analyse de donnees accessibles aux equipes.\n developper des kpis et dashboards pertinents pour le suivi des performances.\n favoriser une culture de la data-driven decision-making au sein de lentreprise.\n concevoir et implementer des modeles danalyses avancees et predictives pour optimiser les operations et ameliorer lexperience client.\n developper des solutions basees sur lintelligence artificielle et le machine learning pour le marche.\n collaborer avec les equipes produit et tech pour integrer des fonctionnalites data-driven dans les solutions sobrus.\n recruter et encadrer une equipe data (data analysts, data engineers, data scientists).\n mettre en place des processus agiles pour assurer une execution efficace des projets data.\n former les equipes internes et diffuser les bonnes pratiques data aupres des collaborateurs.\n suivre les evolutions technologiques et les tendances en matiere de data science et dia.\n identifier et tester des technologies innovantes pouvant apporter un avantage competitif a lentreprise.\n\n\nles avantages que sobrus vous offre\n\n primes sur objectif.\n formations continues.\n formations metiers.\n incentives et challenges.\n team building.\n une journee off pour feter votre anniversaire.\n une assurance maladie complementaire.\n\n\nprofil recherche\n\n bac +5 / master en data science, informatique, statistiques, mathematiques appliquees ou equivalent.\n minimum 5 a 7 ans dexperience dans le domaine de la data, avec une premiere experience reussie en management dequipe.une experience dans un environnement saas, sante, retail, fintech ou assurance est un plus.\n\n\ncompetences requises\n\n expertise en gestion et gouvernance des donnees.\n excellentes connaissances en data science, machine learning et intelligence artificielle.\n maitrise des outils danalyse et de visualisation de donnees (sql, power bi, tableau, looker, etc.).\n experience en cloud computing et big data (gcp, aws, azure, snowflake, etc.).\n bonne maitrise des langages de programmation orientes data (python, r, sql).\n leadership et capacite a structurer une equipe.\n excellent communicant, capable de vulgariser la data aupres des equipes metier.\n fort esprit analytique et oriente resolution de problemes.\n capacite a travailler en mode agile et collaboratif avec des equipes pluridisciplinaires.\n esprit entrepreneurial, force de proposition et vision strategique.",
  "company_name": "sobrus",
  "is_data_profile": true,
  "profile": "data strategist",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "python",
    "machine learning"
  ],
  "soft_skills": [
    "leadership",
    "communication",
    "problem-solving"
  ],
  "sector": [
    "healthcare",
    "technology"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-experimente-df-supply-chain-at-alten-4225740960",
  "titre": "data engineer experimente df supply chain",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-11",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "company description\n\nalten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2024. avec plus de 90 recrutements par mois, alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\nrejoindre alten maroc c'est beneficier :\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers. \n des formations certifiantes et diplomantes. \n des evenements reguliers pour combiner bien etre et performance.\n\n\njob description\n\nla digital factory supply chain concoit et developpe lensemble des assets digitaux permettant doffrir a nos clients et collaborateurs une experience omnicanale parmi les meilleures du marche, au service de l'approvisionnement des magasins. de la commande magasin automatique, aux commandes fournisseurs jusqu'a la preparation en entrepot et au transport vers les points de vente. les technologies de pointe que nous deployons, ainsi que la puissance de nos outils et methodes basees sur la data, le machine learning et l'ia, permettent a nos equipes de focaliser leurs efforts sur la valeur de leurs initiatives.\n\nen tant que data scientist/data engineer, vous integrerez la digital factory supply chain ou vous serez amene a appuyer le departement prevision et optimisation particulierement sur des sujets data et danalyse de donnees. au sein d'une equipe composee de data scientists et de data engineers organisee en mode scrum agile, vous travaillerez pour implementer des outils de calcul de prevision (prevision du besoin magasin pour lapprovisionnement entrepot, prevision de charge entrepots etc.)\n\n explorer et analyser les donnees du datalake\n participer au cadrage des nouvelles fonctionnalites\n developper des modeles de prevision statistiques et de machine learning\n tester les fonctionnalites developpees\n\n\nqualifications\n\n vous maitrisez les langages suivants : sql et python\n vous avez un esprit danalyse et la capacite de travailler en equipe et a distance. \n vous etes autonome, rigoureux, fluide dans votre communication orale et ecrite et a l'ecoute des besoins de vos interlocuteurs. \n vous etes reconnu pour vos capacites d'anticipation, votre sens de l'initiative et votre reactivite. \n une connaissance de gcp et de bigquery serait un plus. \n une connaissance meme theorique de la methodologie agile serait un plus. \n une connaissance des commandes git serait un plus. \n excellentes aptitudes a la collaboration et au travail en equipe. \n bonne communication ecrite et orale en francais pour des interactions fluides avec le metier. \n sens critique permettant d'evaluer objectivement differentes solutions. \n capacite a prendre du recul sur les problematiques techniques et fonctionnelles. \n autonomie et proactivite dans l'organisation du travail et la resolution de problemes. \n participation active aux decisions d'equipe avec des contributions constructives. \n capacite a respecter les delais tout en maintenant des standards eleves. \n familier avec les methodes agiles, notamment scrum.\n\n\nadditional information\n\nvous etes rigoureux, creatif, curieux et vous aimez travailler en equipe et monter en competence dans un environnement dynamique, les metiers du service vous animent et vous souhaitez evoluer dans un environnement convivial, rejoignez-nous !\n\nau plaisir de vous lire!",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "sql",
    "python",
    "machine learning"
  ],
  "soft_skills": [
    "teamwork",
    "communication",
    "problem-solving"
  ],
  "sector": [
    "it",
    "supply chain"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/stagiaire-data-hf-at-salafin-bmce-group-4174427841",
  "titre": "stagiaire data (h/f)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-04",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "pour postuler, merci de joindre imperativement votre cv.\n\ndans le cadre de son developpement, salafin recherche des stagiaires en data (h/f) bases a casablanca.\n\nmissions\n\nrattache(e) au pole risques de credit, vous aurez pour principales missions :\n\n collecter, structurer et analyser les donnees relatives aux portefeuilles de credit.\n contribuer a lelaboration et a lautomatisation des rapports de suivi des indicateurs de risques.\n identifier et interpreter les tendances et les anomalies dans les donnees pour detecter les risques potentiels.\n soutenir lequipe dans la mise en place de modeles statistiques et de scoring pour evaluer la qualite du credit.\n collaborer avec les equipes it et les autres departements pour ameliorer la qualite et la precision des donnees.\n participer aux projets damelioration continue en proposant des solutions basees sur lanalyse des donnees.\n\n\nprofil recherche\n\n de formation bac+5, issu dune grande ecole dingenieurs avec une specialisation en mathematiques ou statistique.\n rigueur, esprit analytique et capacite a resoudre des problemes complexes.\n bonnes competences en communication pour vulgariser les resultats des analyses\n maitrise des outils danalyse de donnees (excel, sql, python, r, etc.).\n bonne connaissance des bases de donnees et des techniques de gestion de donnees.\n capacite a interpreter les resultats analytiques et a formuler des recommandations.\n connaissance des modeles de risque de credit (probabilite de defaut, perte en cas de defaut, exposition au defaut, etc.).\n capacite a travailler en equipe et a collaborer avec des parties prenantes internes.\n aisance dans la presentation et la visualisation des donnees (power bi, etc.).\n\n\nps : les candidatures sans cv ne pourront malheureusement pas etre traitees.",
  "company_name": "salafin bmce group",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "sql",
    "python",
    "excel"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [
    "finance",
    "banking"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-engineer-at-cplnetwork-4227013204",
  "titre": "senior data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-09",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "nous recrutons : senior data engineer\n\n\nnous recherchons un data engineer experimente pour integrer une equipe technique engagee autour de projets data a fort enjeu.\n\n\n missions :\n- conception et optimisation de pipelines de donnees sur azure data factory\n- traitement des donnees a grande echelle via azure databricks\n- industrialisation des flux etl (batch & temps reel)\n- participation aux choix darchitecture data sur lenvironnement azure\n- collaboration etroite avec les equipes bi, data science et it\n\n\n profil recherche :\n- solide experience en developpement de pipelines etl\n- maitrise des environnements cloud azure\n- esprit analytique, rigoureux et autonome",
  "company_name": "cplnetwork",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "azure data factory",
    "azure databricks",
    "etl"
  ],
  "soft_skills": [
    "teamwork",
    "problem-solving",
    "communication"
  ],
  "sector": [
    "it",
    "data engineering"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-databricks-mid-level-at-lumenalta-4214847384",
  "titre": "data engineer - databricks - mid level",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-26",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "experience remote done right. with over 20 years of remote experience, all 500+ staff are 100% remote, and we still grow vibrant relationships and provide exceptional opportunities for career growth while working with stellar clients on ambitious projects.\n\n\nwhat we're working on:\nenterprise companies turn to us to help them launch innovative digital products that interact with hundreds of millions of customers, transactions and data points. the problems we solve daily are real and require creativity, grit and determination. we are building a culture that challenges norms while fostering experimentation and personal growth. to grasp the scale of problems we face, ideally, you have some exposure to logistics, fintech, transportation, insurance, media or other complex multifactor industries.\n\n\nrequirements\n 3+ years experience in a data engineering role using python; ideally, you have delivered business-critical software to large enterprises\n you are comfortable manipulating large data sets and handling raw sql\n experience using technologies such as pyspark/aws/databricks is essential\n experience creating etl pipeline from scratch\n e-commerce and financial services industry experience preferred\n english fluency, verbal and written\n personality traits: professional, problem solver, proactive, passionate, team player.\n\n\nwhy lumenalta is an amazing place to work at\nat lumenalta, you can expect that you will:\n be 100% dedicated to one project at a time so that you can innovate and grow.\n be a part of a team of talented and friendly senior-level developers.\n work on projects that allow you to use leading tech.\n\n\nthe result? we produce meaningful outcomes for our clients that break barriers in their industries.\n\n\nthe job is 100% remote; please ensure you have a comfortable office set at your desired work location.\n\n\nlumenalta is committed to hiring exceptional talent from a wide variety of diverse backgrounds. if you share our values and enthusiasm for digital transformation, we encourage you to apply\n\n\nwhat's it like to work at lumenalta?",
  "company_name": "lumenalta",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "sql",
    "databricks"
  ],
  "soft_skills": [
    "teamwork",
    "problem-solving",
    "proactive"
  ],
  "sector": [
    "it",
    "data engineering"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-infrastructure-flux-cft-at-alten-4187999074",
  "titre": "data infrastructure flux cft",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-23",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "alten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2200 consultants et vise un centre dexcellence de 3300 consultants alteniens en fin 2027. avec plus de 90 recrutements par mois, alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\n\nrejoindre alten maroc c'est beneficier :\n\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers.\n des formations certifiantes et diplomantes.\n des evenements reguliers pour combiner bien etre et performance.\n\n\njob description\n\nnotre  futur collaborateur aura pour mission de participer a la prestation suivante :\n\n\n garantir larchitecture technico fonctionnelle du si scope, en coordination avec les equipes en interne.\n administration du datawarehouse\n gerer les traitements (job , et echange de donnees via sftp, cft) autour du datawarehouse\n administrer linfrastructure de lecosysteme scope (serveurs windows et linux, serveur de partage)\n collaborer avec les chefs de projets it en lien avec les autres sujets (data, build ...)\n echanger avec des prestataires externes\nplus en detail votre role consiste a :\n\n\n gerer les infrastructures informatiques du client administration bdd (oracle), systeme (serveur windows et linux), et outils it\n sassurer du respect des nomenclatures (nommage des objets, les emplacements,)\n choisir les infrastructures adequates pour les projets (dimensionnements, articulations des tables,)\n gerer les droits dacces\n sassurer de la continuite de service au niveau des bases (espace libre, accessibilite)\n accompagner les dba dans les montees de versions et installation de patch (astreinte possible)\n gerer les demandes de machines supplementaires, allocation despace aupres des dba\n\n inverventions build et run sur les flux flux de transfert de fichier cft ou sftp\n gestion de letl apache hop\n coordination avec les partenaires externes pour certains flux developpes\n\n sur la migration des traitements sur job scheduler migration des anciens traitement susr les nouveaux serveurs\n administration systeme avec infrastructure windows et linux\n installation des outils de transfert de fichier\n\n\n inverventions build et run mise en place dapi vers des partenaires exterieurs\n traitement des generations de fichier (multi format)\n intervention sur ls traitements de dedoublonnage de la bdd\n\n\n\n\n\n\nqualifications\n\ndiplome(e) dun bac+5 en informatique ou equivalent.\n\n\n+8ans d'experience\n\n\ncompetences requises:\n\n\n langage : powershell,sql- pl/sql\n bases : oracle (niveau admin bdd)\n outils: office 365, teams, jira, confluence, gitlab, jenkins, elasticsearch, sftp, systeme de transfert de fichier (cft), ordonnanceur (jobscheduler).\n administration : bonne connaissance des types de reseaux, serveurs, gestion des droits dacces, administration des applications web ( serveur iis , apache ...)\n savoir utiliser un etl (apache hop\nsoft skills :\n\n\n avoir un bon relationnel et une bonne communication\n rigueur / organisation \n capacite dadaptation et de reactivite pour gerer le build et le run de la mission\n\n\nadditional information\n\nvous etes rigoureux, creatif, curieux et vous aimez travailler en equipe et monter en competence dans un environnement dynamique, les metiers du service vous animent et vous souhaitez evoluer dans un environnement convivial, rejoignez-nous !\n\n\nau plaisir de vous lire!",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 8,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "powershell",
    "oracle"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "adaptability"
  ],
  "sector": [
    "it",
    "data engineering"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cus-postdoctoral-researcher-in-spatial-data-science-at-um6p-university-mohammed-vi-polytechnic-4209474515",
  "titre": "cus - postdoctoral researcher in spatial data science",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-14",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "postdoctoral researcher in spatial data science\n\nposition description\n\nwe are seeking a postdoctoral researcher specializing in urban modeling and cost analysis to develop an innovative model to estimate the direct and indirect costs of urbanization based on urban morphology (compact or sprawling). the candidate will analyze real case studies, integrate variables related to infrastructure, health, and the environment, and simulate scenarios under different climatic and social contexts to provide decision-making tools for sustainable urban planning.\n\nmain tasks and responsibilities\n\n develop a predictive model integrating the direct and indirect costs of urbanization.\n calibrate this model using real data from specific case studies.\n simulate urbanization costs based on various climatic, morphological, and social scenarios.\n formulate innovative methodological approaches.\n produce publications on research in scientific journals.\n participate in teaching activities.\n develop new research proposals.\n\n\nrequired qualifications\n\n ph.d. in data science, urban planning, urban economics, or a related field.\n experience in research projects applied to urban, environmental, or socio-economic issues.\n proficiency in urban modeling tools such as matlab, python (especially libraries like pandas, numpy, scipy, geopandas, etc.), and r.\n advanced skills in predictive modeling and machine learning, particularly for multi-variable simulations.\n knowledge of complex systems modeling applied to urban dynamics.\n publications in scientific journals.\n\n\npersonal and organizational qualifications\n\n ability to develop innovative methods.\n ambition for research excellence.\n interest in african issues.\n entrepreneurial mindset, dynamism, and organizational skills.\n fluency in both french and english (oral and written) is required.\n\n\nwe offer\n\n excellent working conditions and competitive salary on an international scale.\n an opportunity to contribute to the development of research excellence in africa.\n a highly stimulating multicultural working environment and a great team atmosphere.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "geospatial data scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "matlab",
    "machine learning"
  ],
  "soft_skills": [
    "research",
    "innovation",
    "communication"
  ],
  "sector": [
    "research",
    "academia"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/manager-data-ia-at-intelcia-4223612428",
  "titre": "manager data & ia",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "mission\n\nencadre(e) par un manager, vous serez amene a delivrer des projets innovants dans le domaine de la donnee et de lintelligence artificielle et de mettre en uvre des applications permettant a nos clients de tirer le meilleur parti de leurs donnees, doptimiser leurs process et dameliorer leur experience client ainsi que lefficacite des operations crm.\n\n travailler en etroite collaboration avec les clients pour comprendre leurs besoins en matiere de donnees et d'intelligence artificielle\n etre responsable du delivery des projets data/ ia\n participer a lidentification des cas d'usages et aux phases d'exploration pour fixer l'eligibilite du cas d'usage, definir les hypotheses de donnees necessaires, estimer le roi, les impacts macro du deploiement sur les processus et le si et garantir le respect de la protection des donnees personnelles.\n encadrer le consultant junior data & ia dans ces missions \n definir des scenarios d'implementation des solutions retenues dans le contexte client en prenant en compte des dimensions a la fois d'organisation, de processus et de technologie.\n deployer des solutions d'ia, et gerer l'integration avec des systemes existants.\n assurer une veille technologique en vue detre au diapason des nouvelles technologies sur lintelligence artificielle pour sinstruire et pour proposer aux clients des solutions innovantes.\n participer a lacculturation des equipes internes et des clients sur les sujets dia\n\n\nprofil recherche\n\n bac+ 5 dune grande ecole dingenieur ou master avec une specialisation en ia ou en big data, 2 a 4 ans dexperience dans la data\n avoir une bonne maitrise et comprehension de lunivers de lia et de lutilisation de la donnee\n connaissances solides en statistique, data science machine learning, deep learning)\n experience de 2 a 4 ans dans le conseil en data/ia ou en tant que chef de projet data/ia\n maitrise du francais et langlais a lecrit et a loral\n\n\ncompetences\n\n maitrise du langage de programmation python\n connaissance ou initiation dans le project management/ product management\n connaissance souhaitee en power bi et microsoft azure\n capacite de resolution des problemes/problem solving : structuration, identification des problemes, collecte et analyse de donnees, synthese et elaboration de recommandations\n capacite a trouver des solutions creatives pour integrer l'ia dans nos processus et nos livrables\n capacite a rechercher, tester et presenter des solutions dans une demarche projet\n capacite a simplifier et vulgariser le volet technique au grand public.",
  "company_name": "intelcia",
  "is_data_profile": true,
  "profile": "data strategist",
  "education_level": 3,
  "experience_years": 4,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "machine learning",
    "power bi"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "leadership"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-engineer-freelance-at-proorga-consulting-4228418974",
  "titre": "senior data engineer (freelance)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-12",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "secteur : distribution\n disponibilite : asap\n localisation : casablanca / mode hybride possible\n\n\n description du besoin\ndans le cadre du renforcement de sa data platform, notre client recherche un senior data engineer pour assurer la collecte, le traitement et le stockage des donnees sur microsoft azure. il jouera un role cle dans la mise en place de pipelines de donnees performants et leur exposition selon les besoins metiers.\nle consultant collaborera etroitement avec les equipes metiers et les equipes techniques (cto/dsi) pour concevoir des solutions robustes, securisees et evolutives.\n\n\n missions principales\n-developpement de pipelines de donnees (elt) performants et maintenables.\n-conception et administration de bases de donnees et entrepots de donnees.\n-implementation darchitectures et de modeles de donnees adaptes.\n-automatisation des workflows et optimisation des performances.\n-mise en place de mesures de securite pour la protection des donnees sensibles.\n-collaboration avec les metiers, data scientists, data analysts, developpeurs, etc.\n-maintenance evolutive et corrective des pipelines existants.\n-documentation des processus et normes.\n-veille technologique continue sur les outils et bonnes pratiques en data engineering.\n\n\n competences techniques requises\n-excellente maitrise de python et sql.\n-expertise sur azure data factory et azure databricks.\n-bonne connaissance des bases de donnees relationnelles et nosql.\n-competences solides en modelisation de donnees et gestion de schemas.\n-capacite a optimiser les performances des processus de traitement de donnees.\n\n\n profil recherche\n-formation : bac+5 dune ecole dingenieur ou universite avec specialisation data.\n-langues : maitrise du francais et de larabe.\n-seniorite : confirme / senior.\n-experience : minimum 5 ans en data engineering, idealement dans un environnement azure.",
  "company_name": "proorga consulting",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "azure data factory"
  ],
  "soft_skills": [
    "teamwork",
    "communication",
    "problem-solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consulting-data-manager-at-vivadata-4195709926",
  "titre": "consulting data manager",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-03",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "qui sommes-nous?\n\nartefact est une nouvelle generation de cabinet de conseil specialisee en data dont plus de 1200 collaborateurs repartis sur 19 pays ont pour mission daccompagner la transformation chez nos clients.\n\nnous offrons une large gamme de solutions data-driven, que nous adaptons aux besoins specifiques de nos clients, que ce soit des projets ia pour l'automatisation des process internes a chaque etape de leur chaine de valeur, la creation d'experiences consommateurs innovantes et personnalisees, le conseil en strategie data et marketing digital jusqu'a la gestion du mix-media et plus encore !\n\nla performance de nos services data repose sur une reelle expertise technologique en intelligence artificielle et des competences metiers acquises aupres de plus de 1000 clients dans le monde, tels que accorhotels, orange, carrefour, engie, emirates, deutsche telekom, monoprix...\n\nla force d'artefact repose sur un mix unique d'atouts: une connaissance des technologies de pointe en data, des methodes agiles permettant de delivrer tres rapidement les projets et des equipes composees des meilleurs experts dans leurs domaines (business consultants, data analysts, data scientists, ingenieurs data...).\n\npour accompagner cette croissance, notre departement conseil recherche un(e) manager data consultant.\n\nresponsabilites principales\n\ndelivery et management de projets\n\n piloter et faire grandir des equipes pluridisciplinaires (consultants, data scientists, data/software engineers, data analysts) en :\n organisant des projets en sous chantier (avec pour chacun des objectifs, livrables clairs, des deadlines,....).\n definissant les roles et responsabilites au sein de l'equipe.\n fixant des objectifs aux membres de l'equipe.\n etant garant de la qualite des livrables et de la satisfaction client.\n\nimpact business\n\n comprendre les besoins de nos clients et leur apporter des solutions data adaptees.\n renforcer nos relations avec les clients actuels, identifier les opportunites commerciales et proposer des solutions pertinentes. \n accompagner louverture de nouveaux territoires commerciaux pour artefact.\n avoir une bonne capacite dadaptation a l'environnement de travail en passant facilement dun contexte a un autre (industrie, client, entites metiers au sein d'un meme client, ...)\n\n\nimpact interne\n\n devenir referent sur une ou plusieurs expertises et les developper (strategie, data gouvernance, data marketing,... ) : construction de nouvelles offres, formation des consultants, actions marketing, developpement de partenariats, pitchs clients.... \n participer a des evenements externes et a la creation de contenu marketing faisant la promotion dartefact.\n developper / enrichir l'offre d'artefact afin de repondre aux besoins de nos clients. \n le consulting manager agit egalement en tant que leader des operations, prenant la tete de sujets strategiques tels que les rh, les entretiens de recrutement, l'innovation, le management agile ou l'industrialisation.\n\n\nprofil\n\n vous disposez dune experience de 4 ans dans un cabinet de conseil.\n vous avez une experience en gestion du personnel et une capacite averee a developper de jeunes talents\n vous savez comment identifier les opportunites commerciales et vous aimez les interactions.\n vous etes curieux et passionne par les sujets lies a la data et a levolution technologique.\n vous avez un etat d'esprit analytique et aimez la resolution de problemes.\n vous faites preuve de rigueur et proactivite\n vous maitrisez : suite google/ pack office.. \n une excellente communication (ecrite / orale) en francais et en anglais est obligatoire.\n\n\npourquoi nous rejoindre\n\n un melange unique de talents (data consultants, data analyst, data scientist, data engineer), et une hyper croissance continue offrant de nombreuses opportunites de carrieres rapides. \n un endroit ideal pour apprendre : vous maitriserez les competences cles du monde de l'entreprise de demain : vous recevez des formations regulieres sur la technologie (offre artefact, technologies de la donnee,...), votre travail en equipes hybrides, vous apprenez les facons de travailler specifiques a la tech (product mindset, agilite...). a la fin de votre experience artefact, vous etes un leader technologique experimente.\n la culture : innovation, collaboration et action sont nos valeurs, pour faire simple, nous sommes des faiseurs qui travaillent ensemble afin de creer des solutions innovantes.\n\n\nchez artefact, nous recrutons nos collaborateurs uniquement en fonction de nos besoins et des qualites propres de chaque candidat. nous assurons le developpement de leurs competences professionnelles et de leurs responsabilites sans discrimination daucune sorte, notamment de croyances, de genre, dage, de situation d'handicap, dorigine ethnique, dorientation sexuelle, dappartenance a une organisation politique, religieuse, syndicale ou a une minorite.\n\napply now\n\napply for this jobapply for this job\n\nshare this offer\n\nsimilar jobs\n\ndata analytics\n\nview more\n\ndata engineering\n\nview more\n\ndata science\n\nview more\n\nteamwork makes the dream works.\n\nartefacts teams are made up of the best experts in their fields, and its our biggest responsibility to ensure their professional development and personal wellbeing.\n\nlearn more",
  "company_name": "vivadata",
  "is_data_profile": true,
  "profile": "data consultant",
  "education_level": 3,
  "experience_years": 4,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "google suite",
    "project management"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "adaptability"
  ],
  "sector": [
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-confirme-3-a-7-ans-dexperience-at-free-work-4197599443",
  "titre": "data engineer confirme (3 a 7 ans dexperience)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-04",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "dans le cadre dun programme de transformation data au sein dun acteur majeur du secteur de la distribution, nous recherchons un(e) data engineer experimente(e) pour renforcer les equipes dune plateforme data structuree autour dune architecture  data-centric . cette plateforme vise a decloisonner les silos dinformation et a fournir des donnees en temps reel via api a lensemble de lecosysteme metier et si, dans une logique de convergence entre decisionnel et operationnel.\n\nvos responsabilites\n\nintegre(e) a lequipe data, vous serez charge(e) de concevoir, developper et maintenir des pipelines de traitement de donnees a grande echelle, en environnement cloud. vous interviendrez a la croisee des enjeux techniques et metiers, dans un environnement resolument agile et oriente performance.\n\nmissions principales\n\ndevelopper et maintenir des flux de donnees batch et temps reel (bigquery, bigtable, apache kafka, apache spark)\n\nconcevoir des pipelines evolutifs et robustes en lien etroit avec les equipes techniques\n\noptimiser les processus dacquisition, de transformation et de stockage des donnees\n\nassurer la haute disponibilite et les performances en production dans une demarche devops\n\ncontribuer a la definition de larchitecture microservices et a lamelioration continue\n\nrediger et maintenir les tests unitaires et dintegration\n\nproduire des livrables de qualite et assurer un reporting clair et regulier\n\nproposer des pistes damelioration (refactoring, simplification, industrialisation)\n\ncompetences techniques requises\n\nlangages : tres bonne maitrise de java ; la connaissance de scala est un atout apprecie, mais non bloquant\n\ntraitement de flux et big data : bonne experience avec apache kafka et apache spark\n\ncloud : experience sur gcp (bigquery, dataproc, kubernetes...) ou environnement cloud equivalent\n\nci/cd : pratique de git et des outils dintegration/deploiement continus (gitlab ci/cd ou similaire)\n\narchitecture & devops : bonne culture des microservices et des pratiques devops\n\nqualite logicielle : rigueur dans lecriture de tests et dans le maintien de la qualite du code\n\nsoft skills attendus\n\nesprit dequipe et capacite a collaborer dans un environnement distribue\n\ncommunication fluide, ecrite comme orale\n\nsens de lanalyse et capacite a challenger lexistant avec bienveillance\n\nautonomie et proactivite dans la resolution de problemes\n\nprofil candidat:\n\ndiplome(e) dune ecole dingenieur, dun master universitaire ou equivalent par lexperience\n\n3 a 7 ans dexperience sur un poste similaire, avec une solide expertise java (et idealement scala)\n\nune connaissance du secteur retail est un plus, sans etre indispensable",
  "company_name": "free-work",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "mid",
  "hard_skills": [
    "java",
    "apache kafka",
    "apache spark"
  ],
  "soft_skills": [
    "teamwork",
    "communication",
    "problem-solving"
  ],
  "sector": [
    "distribution"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/lead-data-integration-api-etl-talend-boomi-pentaho-informatica-maroc-at-adapt1solution-4225539221",
  "titre": "lead data integration api, etl, talend, boomi, pentaho, informatica maroc",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "notre mission\n\nl'optimisation du cycle d'elaboration budgetaire, le pilotage de la performance financiere et la planification sont au cur de notre metier. nous accompagnons nos clients dans la mise en place d'un processus contributif et collaboratif et identifions les indicateurs pertinents afin d'elaborer des tableaux de bord efficaces pour nos clients.\n\nadoptez les meilleurs solutions - a tous les niveaux de votre entreprise\n\nnous recherchons notre lead data integration base(e) au maroc qui sera responsable de la conception, du developpement et de la mise en uvre des solutions de gestion et d'integration des donnees pour nos clients. le/la titulaire du poste devra gerer et coordonner une equipe de developpeurs de donnees et travailler en etroite collaboration avec nos equipes et celles de nos clients pour assurer l'integration et la qualite des donnees.\n\nresponsabilites:\n\n concevoir, developper et maintenir les solutions de gestion et d'integration des donnees de l'entreprise\n coordonner et superviser une equipe de developpeurs de donnees\n travailler en etroite collaboration avec les equipes interne et clients pour comprendre leurs besoins en matiere de donnees et s'assurer que les solutions repondent a ces besoins\n evaluer les outils et les technologies pour l'integration et la gestion des donnees et recommander les meilleurs choix\n developper et mettre en uvre des politiques et des procedures pour assurer la qualite et la securite des donnees\n travailler avec les equipes informatique clients pour assurer l'integration des donnees dans les systemes existants\n evaluer les performances de l'ensemble du systeme de gestion des donnees et apporter des ameliorations en consequence\n fournir des rapports sur l'etat du systeme de gestion des donnees et des recommandations pour des ameliorations futures\n\n\n\nrequirements\n\ncompetences:\n\n experience confirmee en developpement et de programmation de solutions de gestion et d'integration de donnees\n connaissance approfondie de la conception de bases de donnees relationnelles et non relationnelles\n capacite a travailler avec des outils de gestion de donnees tels que etl (extract, transform, load), la virtualisation de donnees, l'integration de donnees en temps reel, etc\n competences en leadership et en gestion d'equipe\n bonne capacite de communication et de collaboration avec les autres equipes de l'entreprise\n connaissance des langages de programmation tels que sql, python, java, etc\n connaissance des normes de securite et de confidentialite des donnees\n competences en resolution de problemes et en prise de decision\n\n\n\noutils:\n\n outils etl tels que talend, informatica, boomi, mulesoft etc\n outils de virtualisation de donnees tels que denodo, etc\n outils de gestion de bases de donnees relationnelles et non relationnelles tels que mysql, microsoft sql, oracle, mongodb, cassandra, etc\n outils de business intelligence tels que tableau, power bi, etc\n outils de collaboration tels que teams, slack, jira, etc\n\n\n\nbenefits\n\nvenez rejoindre une equipe jeune et dynamique en pleine croissance travaillant en mode hybride sur de superbes projets internationaux.",
  "company_name": "adapt1solution",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "sql",
    "etl",
    "talend"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "leadership"
  ],
  "sector": [
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-at-red-tic-4225322081",
  "titre": "data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "freelance\n casablanca\n publie il y a 6 mois\n\n\nred tic recrute pour lun de ses clients un profil data engineer.\n\nmission\n\n conception de pipelines de donnees en integrant des sources de donnees variees (bases de donnees relationnelles, systemes de fichiers, api, etc.).\n developper des processus etl/elt talend pour lextraction, la transformation et le chargement des donnees en respectant les regles metier.\n ameliorer les performances des pipelines pour garantir la rapidite et lefficacite du traitement des donnees.\n gestion des infrastructures de donnees et selection des technologies appropriees (bases de donnees nosol, datalake data warehouses, etc.)\n definir une architecture de donnees evolutive*\n gerer linfrastructure dans des environnements cloud (aws, azure, google cloud) ou sur site, en tenant compte des, besoins de scalabilite et de securite.\n securite des donnees: mettre en uvre des politiques de securite (chiffrement, anonymisation, gestion des acces) pour garantir la confidentialite des donnees.\n automatisation et monitoring des processus\n\n\nprofil recherche\n\n maitrise des langages: python, scala, sql.\n outils et frameworks : hadoop, spark, kafka.\n bases de donnees : mysql, postgresql, cassandra, redshift, bigquery.\n gestion de version: git.\n orchestration : airflow.\n connaissances en devops : docker, kubernetes.\n\n\nrecruitment consulting management training sourcing job jobs offer internship morocco africa java developpement developpement developpeur developpeur informatique application it jee android consultant devops fullstack. dabord. tout dabord. en premier lieu. ensuite, de plus. finalement. en outre. par ailleurs. en dernier lieu. enfin. dabord, en premier lieu, pour commencer, premierement, en conclusions ur conclure, enfn, finalement, en dernier lieu, bien que. il y a aussi il est vrai que... mais. tout en reconnaissant que... on peut supposer que. par exemple . en fait . prenons le cas de. considerons, par exemple. lexemple le plus r. cependant. mais. pourtant. toutefois. neanmoins. contraste. alors que. tandis que. par contre. en revanche\n\nnom et prenom\n\nadresse email\n\nmobile\n\nniveau d etude\n\nbac bac +1 bac +2 bac +3 bac +4 bac +5 bac + x\n\nannees dexperience\n\n0 +1 +2 +3 +4 +5 +6 +7 +8 +9 + 10\n\npreavis\n\ndisponible immediatement -1 mois 1 mois 2 mois +2 mois\n\nmessage\n\nupload cv\n\nteleverser votre cv ou tout autre document relatif. taille max: 2 mb.",
  "company_name": "red tic",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "scala",
    "sql"
  ],
  "soft_skills": [
    "problem-solving",
    "communication",
    "teamwork"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-ii-xm-project-at-pizza-hut-digital-technology-4190574817",
  "titre": "data analyst ii - xm project",
  "via": null,
  "contrat": "other",
  "type_travail": null,
  "publication_date": "2025-03-27",
  "location": {
    "city": "tan-tan province",
    "region": "guelmim-oued noun",
    "country": null,
    "remote": false
  },
  "description": "at pizza hut global, we want to build the winning recipe for our customers and team to connect people through the joy of pizza. taking a fact based, data driven approach is fundamental to us focusing on the right areas. pizza hut global has a vast amount of operational data to surface insights for our team and key markets to improve the customer experience, execution of standards and to increase sales.\n\nwere looking for someone with a proven track record to be our data analyst for the cx team who is passionate about leveraging data to solve business problems and make data driven strategic decisions. they should have the ability to dive deep into the data sets, set up user friendly dashboards, present data back in a clear concise format utilizing dashboards, excel & ppt and plan a calendar of analysis to manage the intake.\n\nreporting to the insights manager and supporting the cx team, you would work closely with the hutbot data team in vietnam to ensure that we are sharing learnings across teams.\n\njob functions\n\n data analysis & reporting: collect, clean, and analyze data from multiple sources to produce key business insights. design and deliver actionable reports and dashboards in reporting platforms.\n ad-hoc analysis: provide on-demand analysis to address specific business queries and support initiatives.\n business insights & strategy: collaborate with business leaders to deliver business insights to support decision-making across various departments, shaping strategy and creating understanding.\n data visualization & dashboards: develop dynamic, visually compelling dashboards that allow teams to monitor key metrics, track performance, and identify opportunities for improvement.\n data modeling: use historical data to create predictive models and correlation outcomes, helping to plan for kpi performance and make proactive decisions.\n data integration: work closely with data teams to ensure seamless integration of data sources, ensuring that data flows accurately and efficiently between systems.\n data quality & integrity: maintain data accuracy, consistency, and integrity in data systems, identify discrepancies, and work to resolve any data issues promptly.\n presentation: create and present back analysis in excel / dashboard / ppt format to clearly represent the data\n\n\nknowledge and skill required\n\n2+ years experience in a similar role, with strong expertise in data processing and bi-based reporting. experience in restaurant industry is a plus.\n\ntechnical skills\n\n strong proficiency in database platforms e.g. snowflake, bigquery for data warehousing and querying.\n expertise in domo or other bi tools (power bi, tableau,...) for reporting, app-based dashboards, and data visualization.\n proficiency in sql, and strong experience with data modeling, etl processes, and cloud-based data platforms and data analysis tools.\n strong understanding of statistical analysis techniques.\n experience working in a cross functional team.\n ability to take data, turn it into insights and report back in clear concise format with recommendations for action\n strong organization and documentation skills.\n relationship-building skills  and ability to gain influence with key stakeholders in order to drive decisions.\n strong english written and verbal communication skills.\n highly proactive and self motivated.\n experience using content square or other user experience analysis tool is advantageous.\n\n\nattractive benefits\n\nwhy you'll love working here:\n\n 100% salary during the probation period.\n annual leave: 18 days/year.\n five recharge days  extra days, in addition to company holidays.\n 1 day off paid leave for your birthday.\n half-day fridays.\n full salary insurance.\n 13th-month bonus.\n advanced health insurance (generali).\n regular team and engagement activities.\n linkedin learning & training courses, based on company policy.\n macbook and monitors.\n\n\nworking location: waseco building, 10 pho quang street, ward 2, tan binh district, hcmc.\n\nworking hour: 9am-6pm, monday to friday.",
  "company_name": "pizza hut digital & technology",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 2,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "domo",
    "snowflake"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "organization"
  ],
  "sector": [
    "restaurant"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-x-delivery-at-boston-consulting-group-bcg-4205214414",
  "titre": "data analyst - x delivery",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "who we are\n\nboston consulting group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. bcg was the pioneer in business strategy when it was founded in 1963. today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\n\nto succeed, organizations must blend digital and human capabilities. our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. bcg delivers solutions through leading-edge management consulting along with technology and design, corporate and digital venturesand business purpose. we work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\n\nwhat you'll do\n\nas a part of bcg x team you will work closely with consulting teams on a diverse range of advanced analytics topics. you will have the opportunity to leverage analytical methodologies, subject matter expertise, and accelerated execution to deliver value to bcg's consulting (case) teams and practice areas (domain). you will collaborate with case teams to gather requirements, specify, design, develop, deliver, and support analytics solutions serving client needs. you will provide technical support through deeper understanding of relevant data analytics tools and processes to build high quality and efficient solutions.\n\nwhat you'll bring\n\nworking with case (and proposal) team\n\n delivering original analysis and insights to case teams, typically owning all or part of an analytics module\n establishing credibility by thought partnering with case teams on analytics topics; drawing conclusions on a range of external and internal issues related to your module\n executing analytical approaches and creating defined outcomes; contributing to approach selection focussing on problem solving and client value aspects\n applying analytical, statistical and programming skills, building models, creating algorithms and using appropriate tools to discover knowledge from a variety of large and versatile data sources\n wrapping the outcomes of analysis into ready-to-use software modules / minimal viable products / dashboards\n training the project and client teams on advanced analytics approaches in general as well as on the use of tools and methodologies to increase the impact of their work\n communicating analytical insights through sophisticated synthesis and packaging of results (including ppt slides and charts)\n developing broad expertise in at least one analytics topic or platformthinking analytically:\n you should be strong in analytical solutioning with hands on experience in advanced delivery, through the entire life cycle of analytics. strong technical and statistical skills with the ability to develop and codify knowledge and provide analytical advice where required.\n\n\ntechnical skills (must have)\n\n overall fluency in either of python or r: ability to read, create, debug and package code, being comfortable using either of pycharm, r-studio, visual studio or any other ide\n sql scripting, ability to collect data from relational databases, e.g. postgresql, mysql, mssql etc.)\n data wrangling with python (pandas) or r\n hands on statistical inference using python, r as well as ms excel extensions\n experience in data visualization and presentation using either of tableau, powerbi, qlikview, dash, ...\n self-learning and quick ramping in previously unfamiliar technological stack if needed\n\n\ntechnical skills (good to have)\n\n experience in building scalable production ready dashboards and web applications using python or js frameworks e.g. either of django, flask, react, vue, angular etc.\n experience with proprietary low-code data wrangling, predictive analytics and modelling tools (either of alteryx, knime, dataiku, sas, spss etc.)\n experience with customer analytics, pricing optimization, predictive maintenance, supply chain optimization, network optimization, workforce allocation, smart manufacturing and related topics in a global organization or professional services is preferred\n experience in geoanalytics using python or specialized solutions is a plus\n first experience in simulation modelling and optimization approaches (operations research / linear programming / mixed integer programming)\n knowledge of dedicated optimization and simulation tools (aimms, llamasoft, gurobi, anylogic) is a plus\n programming and/or scripting experience a plus: sql, c#, perl, spark, vba\n experience with big data environments a plus: amazon redshift, hadoop/hive, teradata\n experience with collaboration tools & ticketing systems (e.g. jira, confluence, github) is preferred\n\n\nyou bring (experience & qualifications)\n\n bachelor's / master's degree related to computer science, data engineering, data science, statistics, mathematics, or economics is required\n previous experience in the domain of advanced analytics (internships included)\n analytical expertise, including the ability to synthesize complex data, understand system capabilities and constraints, apply specific analytics methodologies, and deliver impactful solutions\n consulting experience will be considered a plus\n fluent written and spoken english (other languages desirable)\n\n\nwho you'll work with\n\nour business management and operations team members work to ensure that bcg is running smoothly, efficiently, and productively. we are made up of executive and administrative (or case team) assistants, visual service artists, receptionists, facilities staff, and the team leaders and office coordinators who manage these operations and business management jobs.\n\nboston consulting group is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\n\nbcg is an e - verify employer. click here  for more information on e-verify.",
  "company_name": "boston consulting group (bcg)",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "sql",
    "tableau"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cus-postdoctoral-researcher-in-spatial-data-science-at-um6p-university-mohammed-vi-polytechnic-4218448400",
  "titre": "cus - postdoctoral researcher in spatial data science",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-27",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position description\n\nwe are seeking a postdoctoral researcher specializing in urban modeling and cost analysis to develop an innovative model to estimate the direct and indirect costs of urbanization based on urban morphology (compact or sprawling). the candidate will analyze real case studies, integrate variables related to infrastructure, health, and the environment, and simulate scenarios under different climatic and social contexts to provide decision-making tools for sustainable urban planning.\n\nmain tasks and responsibilities\n\n develop a predictive model integrating the direct and indirect costs of urbanization.\n calibrate this model using real data from specific case studies.\n simulate urbanization costs based on various climatic, morphological, and social scenarios.\n formulate innovative methodological approaches.\n produce publications on research in scientific journals.\n participate in teaching activities.\n develop new research proposals.\n\n\nrequired qualifications\n\n ph.d. in data science, urban planning, urban economics, or a related field.\n experience in research projects applied to urban, environmental, or socio-economic issues.\n proficiency in urban modeling tools such as matlab, python (especially libraries like pandas, numpy, scipy, geopandas, etc.), and r.\n advanced skills in predictive modeling and machine learning, particularly for multi-variable simulations.\n knowledge of complex systems modeling applied to urban dynamics.\n publications in scientific journals.\n\n\npersonal and organizational qualifications\n\n ability to develop innovative methods.\n ambition for research excellence.\n interest in african issues.\n entrepreneurial mindset, dynamism, and organizational skills.\n fluency in both french and english (oral and written) is required.\n\n\nwe offer\n\n excellent working conditions and competitive salary on an international scale.\n an opportunity to contribute to the development of research excellence in africa.\n a highly stimulating multicultural working environment and a great team atmosphere.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "geospatial data scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "matlab",
    "machine learning"
  ],
  "soft_skills": [
    "problem-solving",
    "communication",
    "research"
  ],
  "sector": [
    "research",
    "academia"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-anglophone-at-alten-4183888637",
  "titre": "data analyst anglophone",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-13",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\nalten delivery center maroc, subsidiary of the world leader in engineering and technology consulting created in 2008 and present in fez, rabat, tetouan and casablanca, today has more than 2,300 consultants and is aiming for a center of excellence of 3,100 consultants alteniens at the end of 2024. with more than 90 recruitments per month, alten maroc is now a major player in the professional integration of engineers. we support our clients, industry leaders, in their development strategies in the fields of automotive, rail, it, r&d and telecoms & media.\n\njoining alten maroc means benefiting from :\n\n diversified professional paths with career opportunities, internal, sectoral, geographic and professional mobility. \n certification and diploma training courses. \n regular events to combine well-being and performance.\n\n\ndescription du poste\n\nthe consultant will be responsible for the following tasks :\n\n collaborate with cross-functional teams (including data scientists, analysts, developers) to define data requirements, pipeline design, and solutions. \n design, implement, and maintain scalable etl pipelines using aws glue (spark), python, and pyspark. \n manage complex data workflows and dependencies, including with aws lambda, using airflow (or similar orchestration tools). \n build and maintain cloud-native, scalable, and cost-effective data infrastructure on aws, ensuring performance optimization. \n integrate and optimize data flows across various aws services like s3 (glue catalog, athena), aurora postgres, redshift, and iceberg tables. \n ensure data quality, governance, and compliance standards are met across all data processes. \n take ownership of the end-to-end lifecycle of data pipelines, from design to deployment and monitoring. \n collaborate closely with data science teams to operationalize models, leveraging aws sagemaker where applicable. \n ensure strong documentation practices and follow best practices for scalability, maintainability, and cost management.\n\n\nqualifications\n\n masters degree in data\n 5 years of experience in a similar role\n\n\nmandatory hard skills :\n\npython & spark\n\n proficiency in python (including pandas) for data transformations using tdd approach. \n hands-on experience with apache spark, ideally via aws glue.\n\n\ncloud services (aws)\n\n experience with aws services such as s3, glue, athena, redshift, aurora, lambda, iam, and eventbridge. \n comfortable with cloud-based architecture, serverless design, and deployment strategies.\n\n\ndata workflow orchestration\n\n experience in building and managing dags in airflow (or similar tools). \n familiarity with lambda-based event-driven architectures.\n\n\nsoftware engineering practices\n\n proficiency with git (branching, pull requests, code reviews) and ci/cd pipelines. \n understanding of release management and automated testing in a multienvironment setup.\n\n\nbig data ecosystems\n\n hands-on experience with distributed processing frameworks (like spark) and large-scale data lake solutions, including iceberg tables. \n familiarity with data lake architectures, partitioning strategies, and best practices.\n\n\nhard skills that would be a real plus :\n\n experience with dimensional modelling, partitioning strategies, or other best practices. \n sql knowledge for properly designing and maintaining data schemas for efficient querying and reporting\n infrastructure as a code: familiarity with tools like terraform or cloudformation for automated aws provisioning. \n event-driven architectures: experience with event-driven architectures and working with aws eventbridge / lambda / sqs / sns\n\n\nsoft skills :\n\n effective communication skills for scrum team collaboration\n ownership & accountability: drive projects independently and take full responsibility for deliverables. \n effective communication: ability to explain technical details to both technical and non-technical stakeholders. \n strong problem-solving: ability to dissect complex issues, propose scalable solutions, and optimize workflows. \n team collaboration: comfortable working with cross-functional teams (data scientists, developers, analysts, etc.). \n adaptability & continuous learning: eagerness to explore emerging technologies and refine existing processe",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "spark",
    "aws"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cbs-postdoctoral-position-artificial-intelligence-applied-to-multi-omics-data-integration-at-um6p-university-mohammed-vi-polytechnic-4218446646",
  "titre": "cbs - postdoctoral position: artificial intelligence applied to multi-omics data integration",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-27",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position overview\n\nwe are seeking an outstanding postdoctoral researcher in artificial intelligence (ai) and data science with expertise in multi-omics data integration for health and precision medicine. the successful candidate will join a multidisciplinary team developing ai-driven approaches to integrate and analyze genomics, transcriptomics, proteomics, metabolomics, and microbiome datasets to uncover biomarkers, therapeutic targets, and mechanistic insights into complex diseases.\n\nthe project addresses critical challenges in personalized medicine, disease stratification, and multi-modal data fusion, enabling next-generation solutions in precision health and biomedical research.\n\nscientific challenges addressed in the position\n\n heterogeneity and high dimensionality of multi-omics data requiring advanced ai/ml methods for robust analysis and integration.\n data sparsity, batch effects, and missing values across different omics layers and platforms.\n cross-omics data fusion and representation learning for comprehensive systems biology modeling.\n identification of causal relationships and biomarker discovery through integrative approaches.\n time-series and longitudinal multi-omics data analysis for disease progression modeling.\n explainability and interpretability of ai models to support clinical decision-making and regulatory compliance in healthcare settings.\n scalability and computational efficiency in processing and integrating massive multi-omics datasets from clinical cohorts.\n\n\nkey responsibilities\n\n design and implement ai/ml pipelines for multi-omics data integration, including supervised and unsupervised learning methods.\n develop deep learning architectures (e.g., variational autoencoders, graph neural networks, transformers) for cross-omics data representation and feature extraction.\n apply multi-view learning, transfer learning, and data fusion techniques to integrate heterogeneous omics datasets and clinical metadata.\n conduct network-based analysis (gene regulatory networks, protein-protein interaction networks, metabolic networks) to identify key disease drivers and biomarkers.\n build predictive models for disease classification, patient stratification, and treatment response prediction.\n collaborate with biologists, clinicians, and bioinformaticians for data interpretation and validation of computational findings in clinical or experimental settings.\n disseminate research outcomes through publications in high-impact journals, conference presentations, and workshops.\n mentor and support the training of graduate students and early-career researchers in ai and multi-omics integration.\n\n\nrequired qualifications\n\n ph.d. in bioinformatics, computational biology, data science, artificial intelligence, or a related field.\n proven experience in multi-omics data integration, omics data analysis (genomics, transcriptomics, proteomics, metabolomics, microbiome).\n strong expertise in machine learning, deep learning, and advanced ai frameworks (tensorflow, pytorch, scikit-learn). experience with bioinformatics tools and databases (e.g., bioconductor, galaxy, kegg, reactome, string).\n proficiency in python, r, and unix/linux-based environments for high-performance data analysis. knowledge of biological network inference, causal modeling, and graph-based ai approaches.\n experience in multi-modal data fusion, representation learning, and heterogeneous data integration.\n strong publication record in relevant peer-reviewed journals.\n excellent communication skills and ability to work in a multidisciplinary environment.\n familiarity with cloud-based computing platforms (aws, azure, google cloud) and high-performance computing (hpc) environments.\n understanding of data privacy, security, and ethical considerations in handling clinical data.\n\n\napplication process\n\ninterested candidates should submit the following documents in a single pdf:\n\n a cover letter outlining their research interests, motivation, and relevant experience.\n a detailed curriculum vitae (cv) with a list of publications.\n contact details of two academic referees.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "bioinformatics data scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "r",
    "deep learning"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "research"
  ],
  "sector": [
    "research",
    "academia"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/3-senior-data-engineers-at-africawork-4179600517",
  "titre": "3 senior data engineers",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-12",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "nous recrutons pour notre client des ingenieurs de donnees seniors capable de diriger une equipe et de contribuer activement a la conception et a l'implementation de solutions techniques dans un environnement data-driven.\n\n\nlieu: casablanca ou rabat\n\n\nresponsabilites :\n diriger une equipe de developpeurs dans la mise en uvre de solutions techniques.\n fournir et executer des conceptions techniques pour les composants de la plateforme de donnees.\n etablir des normes, des modeles et des pratiques exemplaires pour les equipes.\n superviser et diriger la livraison de fonctionnalites ou d'epopees completes.\n encadrer et accompagner les membres plus juniors de l'equipe.\n communiquer efficacement avec les parties prenantes externes et internes.\n garantir le respect des pratiques de securite, d'automatisation, et de gestion des couts sur azure.\ncompetences requises :\n 5 ans d'experience en ingenierie des donnees, notamment dans le traitement de grandes quantites de donnees, les processus etl/elt, les lacs de donnees, et les entrepots de donnees.\n experience obligatoire en plateforme azure data, incluant :\nazure data lake gen2, azure data factory, azure sql, azure databricks, key vault, cosmosdb, app services, azure analysis services, docker/kubernetes, azure stream analytics.\n expertise en sql et maitrise avancee de python ou c#.\n experience des technologies danalyse et de veille strategique, y compris les services microsoft azure analytics, adl, adf, pyspark, sql-dw-synapse, hive.\n familiarite avec azure devops.\n excellentes competences en communication ecrite et presentation.\n competences en reflexion creative, resolution de problemes, gestion du temps, gestion de projet, et organisation pour equilibrer et prioriser les taches.\nexperience souhaitee :\n solide comprehension des services de donnees et technologies danalyse, avec une experience averee dans des projets complexes.",
  "company_name": "africawork",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "azure data lake gen2",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/network-data-center-engineer-5-days-onsite-at-lakarya-4199853572",
  "titre": "network /data center engineer (5 days onsite)",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-04-02",
  "location": {
    "city": "tangier",
    "region": "tanger-tetouan-al hoceima",
    "country": null,
    "remote": false
  },
  "description": "job title: network /data center engineer\nlocation: medport tangier ,port de tanger med, vf67+q5 ksar es seghir, morocco.\nemployment type: onsite - 3 month contract with possible extension.\nrole overview:\nwe are seeking a skilled network engineer to provide highly experienced data center technician with 5+ years of expertise in managing data center operations, racking, stacking, and cabling. skilled in optimizing data center infrastructure, ensuring uptime, and maintaining organized, efficient server rooms. proven track record of managing equipment installations, troubleshooting issues, and working with cross-functional teams to support business-critical systems. strong attention to detail with hands-on experience in maintaining hardware, network systems, and power supplies.\n\n\n8+ years, 5+ years in datacenter management, racking, stacking and cabling\n\n\nkey responsibilities:\n perform racking, stacking, and cabling of servers, switches, routers, and storage devices following industry standards.\n troubleshoot and resolve network and connectivity issues with various cabling systems (fiber optics, cat5/6).\n maintain physical infrastructure, including cable management, air flow, power distribution, and environmental monitoring systems.\n implement data center infrastructure management (dcim) tools to track assets, power usage, and environmental metrics.\n develop and maintain thorough documentation of equipment, layouts, and cabling to ensure smooth operations and future scalability.\n perform the deployment and installation of servers, networking equipment, and storage solutions.\n assist with server decommissioning, moving old hardware, and securely recycling obsolete devices.\n\n\nskills & qualifications:\n data center management\n server racking & stacking\n network cabling (fiber & copper)\n hardware installation & maintenance\n power and cooling systems management\n network troubleshooting & issue resolution\n data center infrastructure optimization\n equipment inventory & documentation\n knowledge of dcim (data center infrastructure management) tools",
  "company_name": "lakarya",
  "is_data_profile": true,
  "profile": "unspecified",
  "education_level": 3,
  "experience_years": 8,
  "seniority": "senior",
  "hard_skills": [
    "data center management",
    "server racking & stacking",
    "network cabling",
    "hardware installation & maintenance",
    "power and cooling systems management"
  ],
  "soft_skills": [
    "teamwork",
    "problem-solving",
    "attention to detail"
  ],
  "sector": [
    "it",
    "technology"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/safety-data-analyst-at-royal-air-maroc-4210655580",
  "titre": "safety data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-15",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "au sein du departement systemes de gestion de la securite, direction qualite surete et securite, vous aurez comme principales missions de :\n\n\n assurer la production et la mise a jour des indicateurs de securite de toutes les entites dexploitation.\n assurer lanalyse et la prediction statistiques des indicateurs de securite.\n accompagner les managers operationnels ainsi que tous les correspondants qualite/securite des entites operationnelles dans lanalyse des tendances des indicateurs de performance de securite a travers la fourniture des donnees necessaires.\n assurer la transmission des rapports de securite exigibles dans le cadre des programmes data protection auxquels la compagnie a souscrit et assurer une retroaction au personnel concerne des etudes elaborees dans le cadre de ces programmes.\n assurer l'analyse comparative avec les autres compagnies pour chaque categorie dincidents des differents domaines operationnels en vue d'affiner et daligner les objectifs de securite de la compagnie par rapport aux performances de lindustrie.\n\n\nprofil recherche :\n de formation superieure en ecole d'ingenierie specialise en data et en programmation informatique.\n vous etes fraichement diplome et justifiez de stage dans les domaines de la data analyse.\n vous etes rigoureu(se)x ,engage(e), et avez une grande capacite d'apprentissage.\n une bonne maitrise du francais et de l'anglais a l'ecrit et a l'oral est exigee pour la tenue du poste.",
  "company_name": "royal air maroc",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "data analysis",
    "statistical analysis",
    "data visualization"
  ],
  "soft_skills": [
    "rigor",
    "communication",
    "learning"
  ],
  "sector": [
    "aviation",
    "data analysis"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/full-stack-data-developer-at-allianz-technology-4182033862",
  "titre": "full stack data developer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-17",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "67286 | it & tech engineering | entry level | non-executive | allianz technology | full-time | permanent\n\nwe are looking for a junior full stack data developer with experience in python, azure, angular, and postgresql. you will develop and maintain data-driven applications while ensuring scalability, security, and efficiency.\n\nkey responsibilities\n\n develop full-stack applications using python, angular, and postgresql.\n work with azure cloud services.\n implement oauth authentication and security best practices.\n write and optimize bash/sh scripts.\n use ci/cd pipelines (github actions, azure devops, etc.).\n collaborate using jira, confluence, and servicenow.\n debug and troubleshoot frontend (angular, javascript) and backend (python, postgresql).\n participate in code reviews and documentation.\n\n\npreferred qualifications\n\n proficiency in python.\n experience with azure cloud.\n strong knowledge of angular.\n familiarity with postgresql.\n understanding of oauth authentication.\n experience with bash/sh scripting.\n hands-on experience with ci/cd tools (github, github actions, etc.).\n knowledge of jira, confluence, and servicenow.\n basic understanding of devops and cloud security.\n\n\nif you are passionate about full-stack development and eager to grow, wed love to hear from you!\n\nallianz group is one of the most trusted insurance and asset management companies in the world. caring for our employees, their ambitions, dreams and challenges, is what makes us a unique employer. together we can build an environment where everyone feels empowered and has the confidence to explore, to grow and to shape a better future for our customers and the world around us.\n\nwe at allianz believe in a diverse and inclusive workforce and are proud to be an equal opportunity employer. we encourage you to bring your whole self to work, no matter where you are from, what you look like, who you love or what you believe in.\n\nwe therefore welcome applications regardless of ethnicity or cultural background, age, gender, nationality, religion, disability or sexual orientation.\n\njoin us. let's care for tomorrow.",
  "company_name": "allianz technology",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 2,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "azure",
    "angular",
    "postgresql",
    "bash/sh scripting"
  ],
  "soft_skills": [
    "collaboration",
    "problem-solving",
    "communication"
  ],
  "sector": [
    "it",
    "technology",
    "insurance"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-senior-gcp-at-alten-4182303153",
  "titre": "data engineer senior gcp",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-12",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\nalten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2027. alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\nrejoindre alten maroc cest beneficier :\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers. \n des formations certifiantes et diplomantes. \n des evenements reguliers pour combiner bien etre et performance.\n\n\ndescription du poste\n\nintegre(e) dans les equipes supply, le/la consultant(e) aura pour mission de :\n\n concevoir, developper et maintenir des solutions de traitement de donnees massives en utilisant les technologies big data et les outils gcp. \n mettre en place et optimiser les pipelines de donnees, de lanalyse des performances et de lamelioration continue des solutions existantes\n\n\nqualifications\n\ndiplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique, ou justifiant d'une experience significative equivalente\n\nexperience : de plus de 7 ans en gcp\n\nune experience dans le secteur du commerce de detail ou de la grande distribution serait un plus.\n\ncompetences techniques :\n\n maitriser les technologies cloud de google cloud platform (gcp) pour la gestion des donnees, lorchestration et le deploiement des solutions big data. \n avoir une expertise approfondie de bigquery et bigtable pour le stockage, la manipulation et lanalyse de donnees a grande echelle. \n maitriser les langages de programmation scala ou java pour le developpement de solutions big data, avec une experience significative dans lun des deux. \n avoir une experience pratique avec lecosysteme hadoop et ses outils associes comme spark et apache kafka pour le traitement distribue de donnees. \n etre capable de concevoir et dimplementer des pipelines de donnees complexes en utilisant des outils comme apache kafka et avro pour la gestion des flux de donnees. \n maitriser les concepts de base de kafka pour la conception et la mise en uvre de systemes de messagerie distribues. \n avoir une bonne comprehension des bases de donnees nosql, notamment cassandra et bigtable, pour le stockage et la recuperation de donnees non structurees. \n avoir une experience avec les moteurs de recherche comme elastic search pour la recherche et lanalyse de donnees textuelles. \n maitriser les outils de ci/cd et les pratiques de developpement logiciel pour lautomatisation du deploiement et de lintegration continue. \n avoir une experience pratique avec les outils de deploiement et dorchestration comme jenkins, gitlab, kubernetes, docker et ansible. \n etre capable de travailler avec docker pour la creation et la gestion des conteneurs dapplications.\n\n\ncompetences linguistiques :\n\n avoir une excellente communication ecrite et orale, avec la capacite de produire des livrables et des reportings de haute qualite.\n\n\nsoft skills :\n\n avoir un esprit danalyse et damelioration continue, avec la capacite devaluer le code et ses impacts, ainsi que de remettre en question les solutions existantes pour les ameliorer. \n avoir la capacite de prendre du recul et devaluer les problematiques avec objectivite, en proposant des solutions damelioration. \n avoir un esprit dequipe et la capacite de collaborer efficacement avec les membres de lequipe pour atteindre des objectifs communs. \n maitriser les concepts dagilite (scrum, sprint planning, backlog...).\n\n\ninformations supplementaires\n\nau plaisir de vous lire !",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "gcp",
    "bigquery",
    "bigtable",
    "scala",
    "java",
    "hadoop",
    "spark",
    "apache kafka",
    "cassandra"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-plateforme-lead-azure-hadoop-spark-kafka-min-5-ans-exp-secteur-distribution-freelance-pr%C3%A9sentiel-mission-longue-dur%C3%A9e-casablanca-at-confidentiel-4225310643",
  "titre": "data plateforme lead azure(hadoop,spark,kafka) min 5 ans exp secteur distribution  freelance presentiel mission longue duree casablanca",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "bonjour,nous recherchons pour un client \n\n\ndata plateforme lead azure(hadoop,spark,kafka) min 5 ans exp secteur distribution freelance presentiel mission longue duree casablanca\n\n\n il assure l'efficacite de la collecte, du traitement et du stockage des donnees.\n il collabore avec les equipes metiers et cto/dsi pour repondre aux besoins et mettre en place l'infrastructure.\n il dirige les data engineers pour implementer des pipelines optimaux et exposer les donnees necessaires.\n\n\nresponsabilites:\n\n\n concevoir des frameworks et developper des pipelines pour la collecte, le traitement, et le stockage des donnees sur la plateforme data cloud azure.\n animer et diriger une equipe de data engineers.\n coordonner les projets et repartir les taches au sein de l'equipe.\n developper les competences des membres de l'equipe et assurer leur mentorat.\n etablir des normes et des processus pour la collecte, le stockage, la transformation, et la securisation des donnees.\n garantir la qualite et la fiabilite des donnees en mettant en place des mecanismes de controle et de surveillance.\n collaborer avec les parties prenantes (metiers, data scientists, data analysts, developpeurs...) pour comprendre leurs besoins, fournir des solutions de donnees efficaces et soutenir les initiatives liees aux donnees.\n participer a la veille technologique pour rester informe des avancees dans le domaine du big data et de l'ingenierie des donnees.\n\n\nprofil recherche:\n\n\n diplome bac+5 d'une ecole d'ingenierie avec au moins 5 ans d'experience en data engineering ou dans un poste similaire, ou vous avez developpe des competences techniques liees aux technologies suivantes :\n maitrise des technologies data sur azure.\n maitrise des langages de programmation python et sql.\n expertise dans la conception et le developpement de pipelines de donnees (elt) et la manipulation des donnees.\n connaissance approfondie des outils et des frameworks de big data tels que hadoop, spark, kafka.\n competences en modelisation de donnees et en gestion de schemas.\n maitrise des principes d'optimisation des performances et des techniques de resolution de problemes lies aux bases de donnees.\n\n\nduree preavis: disponible asap\nsi vous etes interesse veuiller envoyer votre candidature",
  "company_name": "confidentiel",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "azure",
    "python",
    "sql",
    "hadoop",
    "spark",
    "kafka"
  ],
  "soft_skills": [
    "leadership",
    "collaboration",
    "problem-solving"
  ],
  "sector": [
    "it",
    "distribution"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-scientist-%E2%80%93-tech-lead-at-red-tic-4173160818",
  "titre": "senior data scientist  tech lead",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-07",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "cdi\n casablanca\n publie il y a 2 mois\n\n\nred tic is recruiting a skilled senior data scie to join our team.\n\njob description\n\nwe are looking for a senior data scientist with expertise in ai and machine learning to join our team. in this role, you will be responsible for designing, developing, and optimizing ai & ml models while ensuring high performance and reliability.\n\nkey responsibilities\n\n develop and maintain ai and ml models, including generative ai, ensuring high-quality standards.\n perform data processing, cleansing, and quality verification (data engineering).\n implement data curation techniques, ensuring proper labeling and classification.\n utilize nlp techniques to categorize textual inputs based on different complexities.\n conduct rigorous testing and validation to enhance model accuracy and efficiency.\n stay up to date with advancements in ai and ml, applying innovative methodologies.\n collaborate with stakeholders to translate business requirements into technical solutions.\n participate in the full project lifecycle, from conception to deployment and maintenance.\n\n\nrequired profile\n\n bachelors or masters degree in computer science, ai, machine learning, data science, or a related field.\n at least two years of experience in developing machine learning algorithms and data science.\n extensive knowledge of large language models and nlp techniques.\n proficiency in sql.\n strong programming skills in python, java, or c++.\n excellent problem-solving abilities and the capability to work independently on complex projects.\n strong communication and collaboration skills, with experience working in cross-functional teams.\n ability to deliver high-quality solutions in a fast-paced environment.\n\n\nrecruitment consulting management training sourcing job jobs offer internship morocco africa java developpement developpement developpeur developpeur informatique application it jee android consultant devops fullstack. dabord. tout dabord. en premier lieu. ensuite, de plus. finalement. en outre. par ailleurs. en dernier lieu. enfin. dabord, en premier lieu, pour commencer, premierement, en conclusions ur conclure, enfn, finalement, en dernier lieu, bien que. il y a aussi il est vrai que... mais. tout en reconnaissant que... on peut supposer que. par exemple . en fait . prenons le cas de. considerons, par exemple. lexemple le plus r. cependant. mais. pourtant. toutefois. neanmoins. contraste. alors que. tandis que. par contre. en revanche data scie\n\nnom et prenom\n\nadresse email\n\nmobile\n\nniveau d etude\n\nbac bac +1 bac +2 bac +3 bac +4 bac +5 bac + x\n\nannees dexperience\n\n0 +1 +2 +3 +4 +5 +6 +7 +8 +9 + 10\n\npreavis\n\ndisponible immediatement -1 mois 1 mois 2 mois +2 mois\n\nmessage\n\nupload cv\n\nteleverser votre cv ou tout autre document relatif. taille max: 2 mb.",
  "company_name": "red tic",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "senior",
  "hard_skills": [
    "machine learning",
    "nlp",
    "sql",
    "python"
  ],
  "soft_skills": [
    "problem-solving",
    "communication",
    "collaboration"
  ],
  "sector": [
    "it",
    "technology"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/kpi-manager-data-analyst-at-cnexia-4223339573",
  "titre": "kpi manager/data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "joining cnexia is choosing to be part of an ambitious project that values innovation, promotes continuous learning and enables all tech champions to fulfill their creative dreams.\n\n\nat cnexia, we do more than support the clients of our world-class network and services. we develop innovative solutions and create original multiplatform media content. in fact, were revolutionizing how canadians communicate on the web, interact with mobile apps or benefit from an ai-enhanced experience.\n\n\nproud of our status as a fully owned moroccan subsidiary of the largest canadian telecom company, we have been ceaselessly growing our team since 2021. with over 1100 employees, mainly based in fez, we have expanded in the northern region of the kingdom with our brand-new state of the art site in technopolis rabat.\n\n\nif you are ready for this challenge, we invite you to join a community that values bold ideas and professional growth all in an engaging multi-cultural world-class environment.\n\n\nas a kpi manager/data analyst, your main responsibilities will be as follows:\n\n\n collect data from multiple sources of data\n provide frequent updates for multiple key performance indicators\n analyse the data with management team for updates in the data collection/analysis\n keep all the kpis up to date with the weekly/monthly/quartely requirements\n\n\n\n\nprofile main requirements (must have qualifications) :\n\n\n university or college degree in engineering, computer sciences, physic, mathematics or relevant experience in equivalent domain\n excellent communication skills in french and english\n minimum of +3 years experience as a data analyst, data extraction and presentation\n strong experience with excel, powerpoint\n worked with jira, confluence\n familiarity with agile environment \n\n\nnice to have:\n\n\n safe certification (safe for teams)",
  "company_name": "cnexia",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "excel",
    "powerpoint",
    "data analysis",
    "kpi management"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "analysis"
  ],
  "sector": [
    "telecommunications",
    "data analysis"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-steward-h-f-at-petit-forestier-group-4183873669",
  "titre": "data steward h/f",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-17",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "entite:\nau sein du groupe, petit forestier digital solutions est le centre de services nearshore du groupe petit forestier.\ncree en 2017, pfds accompagne le groupe dans sa transformation digitale en offrant un catalogue de services complet (support applicatif et infrastructure multi-niveaux, developpement, administration et maintenance des systemes d'informations groupe, test et qualite logicielle, bi et data quality, cyber securite, business process outsourcing).\n\n\ncontexte :\nle groupe petit forestier est en forte croissance, a la fois organique et externe avec des acquisitions a linternational. dans ce contexte, le groupe a lance un programme ambitieux de transformation (tom). il integre un volet systeme dinformation majeur avec limplementation de la solution sap pour remplacer le cur du systeme dinformation existant.\n\n\nrole :\nvotre responsabilite premiere est de coordonner la collecte, la maintenance et l'administration des donnees de base client dans les principaux systemes d'entreprise. vous travaillez avec les business analystes et les departements internes pour resoudre les problemes de donnees, et effectuez les mises a jour du systeme de donnees en masse quand cela est necessaire, conformement aux standards en place.\n\n\nmissions a prevoir pour le poste :\n etre le garant de la coherence globale des donnees entre les differents si en procedant a des analyses pertinentes des differentes bases de donnees\n gerer le flux de donnees provenant de diverses sources\n analyser les rejets de 1er niveau, les traiter ou les faire traiter par le niveau 2\n veiller a la qualite des donnees de l'ensemble des systemes d'information par des jeux de requetes\n identifier les causes des anomalies et determiner les actions correctrices\n sensibilisation des utilisateurs du systeme d'informations sur la qualite des donnes et le respect des consignes de la qualite de saisie des donnees\n\n\nprofil attendu (competences, experience, formation requise) :\n de formation bac+5 en informatique.\n vous justifiez dune experience de 2 ans sur un poste similaire\n vous parlez francais et anglais couramment.\n vous possedez de solides capacites d'analyse et une connaissance significative de l'environnement informatique.\n vous avez dexcellentes competences analytiques / de resolution de problemes et une connaissance dans l'amelioration de la qualite des donnees.",
  "company_name": "petit forestier group",
  "is_data_profile": true,
  "profile": "data governance analyst",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "data analysis",
    "sql",
    "data quality"
  ],
  "soft_skills": [
    "analysis",
    "problem-solving",
    "communication"
  ],
  "sector": [
    "it",
    "data governance"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/head-of-data-officer-at-batenborch-international-maroc-4223957327",
  "titre": "head of data officer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-05",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "nous recrutons pour le compte dun leader dans son secteur dactivite, un head of data officer :\nresponsabilites principales :\n definir et piloter la strategie data et la feuille de route associee\n mettre en place une gouvernance data robuste et efficiente\n suivre la performance des projets et des initiatives data via des kpis clairs\n federer les parties prenantes autour des enjeux data a tous les niveaux de lorganisation\n encadrer et developper une equipe multidisciplinaire\n accompagner la transformation data-driven de l'organisation\n identifier les opportunites de valorisation de la donnee pour generer de la valeur business\n\n\nqualifications requises :\n bac+5 en informatique, en data science ou en ingenierie telecom\n experience professionnelle reussie de 8 a 10 ans en gestion et gouvernance des donnees\n excellente maitrise des principes de gouvernance des donnees, architecture data, modelisation et qualite des donnees\n excellentes competences en communication\n leadership confirme dans la gestion dequipes pluridisciplinaires et de projets complexes\n anglais courant\n\n\ncomment postuler :\nenvoyez votre cv a s.laarid@batenborchinternational.ma",
  "company_name": "batenborch international maroc",
  "is_data_profile": true,
  "profile": "data strategist",
  "education_level": 3,
  "experience_years": 10,
  "seniority": "senior",
  "hard_skills": [
    "data governance",
    "data architecture",
    "data modeling",
    "data quality"
  ],
  "soft_skills": [
    "leadership",
    "communication",
    "project management"
  ],
  "sector": [
    "management",
    "data strategy"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analytics-senior-data-analyst-casablanca-at-infomineo-4225527596",
  "titre": "data analytics - senior data analyst - casablanca",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "about us\n\ninfomineo is a fast-growing business insights provider, bringing brainshoring to global clients across a range of services: business research, content services, graphic design, and data analytics. our clients include leading consultancies, fortune 500 companies, governments, and ngos. infomineo counts 350+ employees spread across 5 offices covering emea and the americas (casablanca, cairo, dubai, barcelona and mexico city).\n\nabout this role\n\nthis role will give you the opportunity to deliver high added value data & analytics projects and build high quality and innovative solutions for our clients within a growing service company.\n\nwhat will you do?\n\nassist businesses in the decision-making process for data driven projects using the following steps:\n\n contribute to the design of the technical solution chosen to collect, analyze data, and display the results obtained\n propose solutions and strategies to tackle business challenges\n present results in a clear manner\n\n\n\nacquisition & preparation\n\n clean and prepare the data with the data scientists\n collect and transform data from the various sources available in big data environments\n\n\n\nanalysis\n\n provide data visualization to inform business decisions\n analyze and interpret data to extract complex relationships and trends\n optimize data exploration using machine learning techniques\n\n\n\ndeployment\n\n adapt and integrate analytics models into the client's is environment\n assist the it teams in all phases of the production, maintenance and updating of the models developed\n\n\n\nrequirements\n\nwho are you?\n\neducation & professional experience\n\n master's degree in a relevant field such as computer science, machine learning, data science, statistics, applied mathematics, data engineering\n full proficiency in english + 1 additional language (french, german, arabic, spanish, italian, portuguese...)\n 4+ years of technical experience in advanced analytics and business intelligence\n\n\n\ntechnical skills\n\nacquisition & preparation\n\n exposure to big data environments and languages such as hadoop, hortonworks, cloudera, spark, scala, pyspark etc. &big data querying tools, such as pig, hive, and impala\n exposure to large data sets both structured and unstructured data: snowflake, sql and relational databases, data warehouse, data lake\n exposure to python programming language coupled with an additional languages experience if possible (e.g. sas, r, javascript)\n\n\n\nanalysis\n\n good skills in analytical concepts such as data correlation, pareto, market-basket analysis, forecasting, creating complex visuals like sunburst, multi-layered maps, etc\n experience in bi/data visualization platforms such as power bi, tableau, looker, qlikview..\n\n\n\ndeployment\n\n exposure to versioning software: git, github, gitlab\n exposure to api integration using python for extracting data from different sources\n\n\n\ninterpersonal skills\n\n ability to step back, analyze problems, find solutions and the drive to implement these\n ability to work & collaborate with variety of stakeholders & clients throughout data project life-cycle\n strong interpersonal skills and organisational skills, high motivation, an attention to detail, flexibility, and ability to cope under stress, a focus on identifying the solutions to problems\n good communication skills & ability to translate complex solutions into business implications and at the same time being able to explain mathematical concepts when required\n\n\n\nbenefits\n\nwhat we offer\n\n a competitive salary\n a great working environment\n a steep learning curve with interesting and diverse topics to work on\n a healthy work-life balance\n health insurance benefits\n\n\n\nequal opportunity employer\n\ninfomineo is an equal opportunity employer, we prohibit any sort of discrimination (based on color, race, sex, sexual orientation, religion, national origin or any other attributes) in all aspects of employment (recruiting, hiring, wages and salary, promotions, benefits, training and job termination).\n\nif you believe you match our requirements and values, we would be happy to hear from you. visit our website to know more about us, our services and company culture",
  "company_name": "infomineo",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 4,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "data visualization",
    "hadoop",
    "spark"
  ],
  "soft_skills": [
    "problem-solving",
    "collaboration",
    "communication"
  ],
  "sector": [
    "business intelligence",
    "data analysis"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/quant-analyst-quant-developer-data-scientist-graduate-programme-2025-at-phi-partners-4180620268",
  "titre": "quant analyst / quant developer / data scientist: graduate programme 2025",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-17",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "about phis graduate programme\n\nphis 2025 graduate programme starts in september. you will join phi as part of a community of graduates  like-minded, talented young people with whom you will form not just professional but also social bonds that may last a lifetime.\n\nunder our two-year programme, our graduates begin their journey at phi with four to six weeks of intensive classroom-based training, delivered by our business and technical experts. after the intensive training, you will join your first client-facing team as junior consultant, and you will be assigned a learning buddy, a senior colleague who will help you navigate these first steps of your career.\n\nyour training doesnt stop there. you will continue formal training over the two years, and we will make sure time is made available for this. in parallel with the experience that you gain in your client role, we will give you all the support you need to develop the all-round consulting skills necessary for promotion to consultant at the end of the two-year programme.\n\nat phi we pride ourselves that all our employees  including the most senior subject matter experts  are friendly and approachable. with a focus on teamwork and knowledge sharing, we value every employee and their ongoing learning and development.\n\nabout the role\n\nas one of our delivery consultants, you will be assigned to one of our international project teams, in one of our current delivery centres in bucharest (romania) or casablanca (morocco).\n\nyou will be:\n\n working with a variety of different financial institutions across the whole capital markets sector\n helping our clients run or transform their technology, or shape their technology strategy\n playing an essential and effective role in both the client team and the wider phi family: learning from our experts, supporting your colleagues, and constantly striving for excellence.\n\n\n\nyou may also get the opportunity to travel to different locations across europe and beyond, if this is something that you would like to do. as a quant developer, or quant it developer your primary career focus will be in supporting our clients business to implement financial models provided by the clients quant team.\n\nas a quant developer, you will typically work in a trading or risk management environment alongside traders, quants and risk managers. as a quant it developer, you will work within the it department that focusses on one of these business areas.\n\nyou will work to implement maintain and integrate the libraries and systems that support those users day-to-day across multiple asset classes, including structured and exotic products.\n\nyou may have a primary technology focus but each client role will be different, and each project will be different.\n\nyou can expect to work across a range of languages, frameworks and technologies in a variety of business and project contexts.\n\nyour roles could include pricing and risk implementation, quant library design and implementation, quantitative model development and integration, trading desk troubleshooting and support, minor enhancements, bug fixing, data design and management, and integration into distributed compute environments or cloud compute.\n\nlonger term, is it usual that the career path is to become a subject-matter-expert within this area, adding leadership and other skills as you develop.\n\nabout you\n\nwe are looking for talented graduates who have an interest in pursuing a career in capital markets technology, in a consulting context  where each client is different, and each engagement provides a new challenge and a new opportunity for learning.\n\neducation\n\n minimum masters degree in mathematics computer science or finance\n\n\n\nother skills and capabilities\n\n familiarity with the relevant technical vocabulary\n good knowledge of quantitative methods\n object oriented programming (any of c++/c#/java) at an educational level or from personal projects sql, shell scripts, perl or python, xml/xslts\n familiarity with design patterns\n basics in devops (automation as part of continuous integration / continuous development)\n\n\n\nwhat we expect from our junior consultants\n\nquality & timeliness of delivery\n\n is highly self-motivated with a strong will to deliver outstanding work results on time\n respects and adheres to own and team schedules; complies to working hours, meetings and agreed delivery dates\n\n\n\nteamwork\n\n is a team player that works well with other people\n is able to transform constructive feedback into learning progress instead of conflicts\n is reliable & responsible\n is engaged and actively supports achieving teams goals\n\n\n\nproblem solving\n\n has strong analytical skills\n can identify most occurring problems uses creativity to find innovative solutions.\n can filter complex information into simple terms\n provides input in evaluating options using best judgement\n helps implement solution\n\n\n\nflexible thinking\n\n is naturally curious and understands the importance of continuous innovation and creativity as these skills are key for a successful career at phi\n is resilient and learn how to tackle challenges whilst having a positive attitude in overcoming obstacles\n constantly learns and develops, can grasp new ideas and concepts quickly and applies this learning to ensure the best possible outcomes for our clients\n\n\n\ncommunication & relationship building\n\n is a friendly and sociable colleague, keen to help people, with a strong service orientation\n is a strong communicator with the ability to summarise complex topics in simple terms\n inspires confidence and build trust in others\n is solution oriented in a no-blame culture, expressing ideas assertively\n\n\n\nabout our offer\n\n competitive package in an international it consultancy\n accelerated career progression with 2-years training and development plan\n working with market leaders and best people from the industry\n work on client sites all over europe or locally from bucharest/casablanca\n gym-membership\n health insurance\n mobile phone\n\n\n\nnext steps\n\nif you think you have what it takes to become one of our expert consultants and to collaborate with some of the most talented people in their fields, contact us at careers@phipartners.com\n\nwe receive a high volume of applications, and while we carefully review each one, only shortlisted candidates will be contacted. if you do not hear from us within two weeks, unfortunately, your application has not progressed to the next stage.",
  "company_name": "phi partners",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "python",
    "c++"
  ],
  "soft_skills": [
    "teamwork",
    "communication",
    "problem solving"
  ],
  "sector": [
    "finance",
    "technology"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-engineer-gcp-at-oleonis-4228276016",
  "titre": "senior data engineer gcp",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-12",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "pret(e) a ecrire une nouvelle page de votre parcours dans une equipe qui innove, soutient et evolue chaque jour ?\n\n\noleonis est une agence de conseil en informatique tournee vers l'avenir, specialisee dans les solutions innovantes pour accompagner les entreprises dans leur transformation numerique.\ngrace a notre expertise en cloud computing, en gestion des donnees et en automatisation, nous aidons les organisations a ameliorer leur efficacite, leur evolutivite et leur resilience dans un environnement technologique en constante evolution.\nnous nous distinguons notamment par l'automatisation des flux de travail chronophages a l'aide d'agents d'ia personnalises, permettant ainsi aux equipes de se concentrer sur des missions a forte valeur ajoutee.\n\n\ndescription de la mission :\ndans le cadre de notre developpement, nous recherchons un.e data engineer, base.e au maroc, pour collaborer avec nos equipes sur des projets innovants.\nvotre mission consistera a concevoir, developper et maintenir des infrastructures de donnees robustes et performantes.\n\n\nresponsabilites principales :\n creer, optimiser et maintenir des pipelines de donnees fiables.\n mettre en uvre des modeles de donnees adaptes aux besoins metiers.\n administrer et faire evoluer des entrepots de donnees pour garantir la qualite, la securite et la disponibilite des informations.\n travailler en etroite collaboration avec nos equipes produit, data et ia.\n\n\nprofil recherche :\n issu d'une formation bac+5\n vous avez au moins 7 ans d'experience\n vous possedez une comprehension des concepts fondamentaux de l'ingenierie de donnees\n vous avez une experience significative sur les outils gcp ( bigquery; cloud workflows; cloud functions; ...)  et sur les outils iac comme terraform \n competences en data modeling : vous etes capable de comprendre et de contribuer a la structuration et a la modelisation des donnees, en apportant les meilleures pratiques pour optimiser l'organisation et l'acces a l'information.\n competences en etl : capacite a concevoir et implementer des processus etl efficaces.\n competences en data analytics : aptitude a analyser des donnees complexes pour produire des insights exploitables.\n bonne maitrise de python et sql.\n\n\ncompetences additionnelles appreciees :\n experience avec des outils de visualisation de donnees (power bi, tableau...).\n\n\ninformations complementaires :\n mode de collaboration : freelance.\n localisation : poste en full remote, base au maroc.\n\n\npourquoi collaborer avec oleonis ?\n missions a fort impact technologique et strategique.\n flexibilite et autonomie dans votre organisation.\n equipe engagee, dynamique et a taille humaine.\n opportunites de collaboration a long terme.\n\n\n\n\nsi ce que vous venez de lire vous parle, si vous sentez que vous pouvez apporter votre pierre a ledifice et quon pourrait grandir ensemble.\nvotre prochain challenge commence ici.\n\n\net parce quon croit profondement que chaque parcours est unique et precieux, ce poste est evidemment ouvert a toutes et a tous, y compris aux personnes en situation de handicap.\n\n\nrejoins-nous.",
  "company_name": "oleonis",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 5,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "gcp"
  ],
  "soft_skills": [
    "teamwork",
    "communication",
    "problem solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cus-postdoctoral-researcher-in-spatial-data-science-at-um6p-university-mohammed-vi-polytechnic-4211222399",
  "titre": "cus - postdoctoral researcher in spatial data science",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-16",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "postdoctoral researcher in spatial data science\n\nposition description\n\nwe are seeking a postdoctoral researcher specializing in urban modeling and cost analysis to develop an innovative model to estimate the direct and indirect costs of urbanization based on urban morphology (compact or sprawling). the candidate will analyze real case studies, integrate variables related to infrastructure, health, and the environment, and simulate scenarios under different climatic and social contexts to provide decision-making tools for sustainable urban planning.\n\nmain tasks and responsibilities\n\n develop a predictive model integrating the direct and indirect costs of urbanization.\n calibrate this model using real data from specific case studies.\n simulate urbanization costs based on various climatic, morphological, and social scenarios.\n formulate innovative methodological approaches.\n produce publications on research in scientific journals.\n participate in teaching activities.\n develop new research proposals.\n\n\nrequired qualifications\n\n ph.d. in data science, urban planning, urban economics, or a related field.\n experience in research projects applied to urban, environmental, or socio-economic issues.\n proficiency in urban modeling tools such as matlab, python (especially libraries like pandas, numpy, scipy, geopandas, etc.), and r.\n advanced skills in predictive modeling and machine learning, particularly for multi-variable simulations.\n knowledge of complex systems modeling applied to urban dynamics.\n publications in scientific journals.\n\n\npersonal and organizational qualifications\n\n ability to develop innovative methods.\n ambition for research excellence.\n interest in african issues.\n entrepreneurial mindset, dynamism, and organizational skills.\n fluency in both french and english (oral and written) is required.\n\n\nwe offer\n\n excellent working conditions and competitive salary on an international scale.\n an opportunity to contribute to the development of research excellence in africa.\n a highly stimulating multicultural working environment and a great team atmosphere.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "geospatial data scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "matlab",
    "r"
  ],
  "soft_skills": [
    "communication",
    "problem solving",
    "research"
  ],
  "sector": [
    "research",
    "academia"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-exp%C3%A9riment%C3%A9-dbt-sql-bigquery-at-alten-4227088553",
  "titre": "data engineer experimente dbt / sql / bigquery",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-05-09",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\nalten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2200 consultants et vise un centre dexcellence de 3300 consultants alteniens en fin 2027. alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\nrejoindre alten maroc cest beneficier :\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers. \n des formations certifiantes et diplomantes. \n des evenements reguliers pour combiner bien etre et performance\n\n\ndescription du poste\n\nintegre(e) dans les equipes plateforme data le/la consultant(e) aura pour mission de contribuer a des projets data en apportant son expertise sur les taches suivantes : montee en competence sur l'etl bigl, participation a la realisation de projets metier dans le cadre de la solution offline elt in-house bigloader et bdi/dbt, prise en charge des demandes de corrections provenant d'incidents ou d'anomalies, participation a l'auto-formation et a la montee en competences de l'equipe de developpement, application des bonnes pratiques et des normes de developpement, mise en pratique des methodes  devops , contribution aux chiffrages des usages et a la constitution des releases, contribution a l'automatisation du delivery, developpement et documentation du code, travail au sein d'une equipe clients scrum\n\nqualifications\n\n diplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique, ou justifiant d'une experience significative equivalente\n experience de 3 ans a 7 ans en dbt, sql, bigquery\n une experience dans le secteur du commerce de detail ou de la grande distribution serait un plus. \n experience significative dans le domaine de la data et du cloud, notamment sur google cloud platform (gcp). \n tres bonne maitrise de bigquery et du sql avance, avec une experience sur des traitements de gros volumes de donnees. \n maitrise de sql pour la manipulation, lanalyse et la valorisation de donnees. \n connaissance approfondie de dbt (data build tool) pour la gestion et lorchestration de pipelines de donnees. \n experience avec pubsub pour la gestion de flux de donnees en temps reel. \n maitrise des outils de ci/cd, en particulier via gitlab ci/cd et docker compose, pour lautomatisation des workflows data. \n bonne connaissance de lenvironnement linux et des outils de ligne de commande. \n experience solide avec les systemes de gestion de version (git). \n travail en methodologie agile (scrum), avec une capacite a collaborer efficacement dans des equipes pluridisciplinaires. \n excellente communication ecrite et orale : bonne communication ecrite et orale en francais pour des interactions fluides avec le metier. \n esprit d'analyse et d'amelioration continue : capacite a evaluer le code et ses impacts, ainsi qu'a remettre en question les solutions existantes pour les ameliorer. \n capacite de prise de recul : aptitude a evaluer les problematiques avec objectivite et a proposer des solutions d'amelioration. \n capacite a respecter les delais tout en maintenant des standards eleves. \n esprit d'equipe : capacite a collaborer efficacement avec les membres de l'equipe pour atteindre des objectifs communs.\n\n\ninformations supplementaires\n\nlooking forward to hearing from you !",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 2,
  "experience_years": 5,
  "seniority": "mid",
  "hard_skills": [
    "sql",
    "bigquery",
    "dbt"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/tech-lead-data-at-axa-global-business-services-axa-gbs-4205528355",
  "titre": "tech lead data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "the reporting factory team is responsible for :\n\n\n operational maintenance of the different existing reports for workplace and network (more than 30)\n managing requests for these reports (new releases, changes, access)\n maintaining the operation of the dedicated bi platform\n creation of new reports (ad-hoc requests)\n\n\nposition & missions \n\n\nthe tech lead data is responsible:\n managing the monthly steering committee reporting factory for workplace and network (prepare and present contents to update top management on the rf activities)\n keep track of recurring activities realized by the 04 experts power bi \n manage new release requests \n manage report creation projects\n update communication on sharepoint \n\n\ntechnicals skills:\n good experience in it (more than 5 years)\n project management experience, preferably in it (mandatory)\n good knowledge of agile project management and azure devops\n good knowledge on power bi / power bi training\n excellent skills on power point presentation for executive level (mandatory)\n good knowledge and usage of m365 productivity tools\n fluent english & french \n\n\nsoft skills:\n analysis and synthesis skills to gather technical and organizational information \n ability to anticipate issues and propose solutions with a problem solver attitude \n rigorous and organized work method with capacity to adapt to demanding and fast paced projects\n sense of teamwork and interpersonal skills to manage relationships with internal and external stakeholders \n ability to listen and have good communication skills to promote our solutions within the company",
  "company_name": "axa global business services (axa gbs)",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 2,
  "experience_years": 5,
  "seniority": "mid",
  "hard_skills": [
    "power bi",
    "azure devops",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem solving"
  ],
  "sector": [
    "insurance",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-societe-generale-4217915808",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-26",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "reference 250009tj\n\n vos missions au quotidien\n\nmissions\n\nau sein du departement business transformation oversight (bto) a casablanca, vous serez dans lequipe\n\nbusiness intelligence unit (biu) qui a la charge de mettre en uvre des outils data pour couvrir les enjeux business\n\net technologiques en etroite collaboration avec les acteurs de la salle des marches a linternational (paris & londres).\n\nconcretement, vous serez amene a :\n\n comprendre les besoins des clients institutionnels en termes de besoins  data \n rassembler des donnees, les consolider dans des bases de donnees et fournir des outils automatises dintegration et de restitution.\n valider la qualite et la coherence des donnees collectees et mener les actions correctives lorsque cela est necessaire.\n exploiter les donnees via des outils et des capacites d'ia/ machine learning.\n analyser les differentes tendances du marche et flux traites en interne et en externe.\n mettre en place de modeles quantitatifs daide a la decision.\n preparer les elements de synthese et les rapports danalyses.\n developper des services web et outils interactifs pour analyser les donnees de marche et synthetiser les informations necessaires a la decision, a destination du trading, vente et top management.\n assurer le bon fonctionnement, la robustesse et levolution des differents outils.\n proposer et partager des idees de rationalisation et d'automatisation des processus.\n\n\n et si cetait vous ?\n\nprofil\n\nde formation superieure de type master ou ecole dingenieur en informatique, vous disposez dune grande curiosite pour la finance de marche et dun esprit pratique, avec un minimum de trois ans d'experiences professionnelles\n\nvous disposez des connaissances et competences suivantes :\n\n langages de programmation : python, java, javascript\n maitrise les technologies sql, nosql, spark, azure\n l'architecture de base de donnees et les architectures big data / datalake\n outils et techniques danalyses des donnees et des methodologies statistiques\n outils de traitement de la donnee (etl , ...)\n modeles machine learning & intelligence artificielle\n\n\navoir une connaissance en finance de marche est un plus.\n\nvous possedez par ailleurs un bon niveau de francais et danglais, tant a lecrit qua loral.\n\nvotre rigueur, implication professionnelle, sens de l'analyse et esprit critique, gout du travail en equipe, ainsi que vos qualites relationnelles a prendre des initiatives dans une orientation service et resultat seront des atouts majeurs pour reussir a ce poste.\n\n pourquoi nous choisir ?\n\ncreee en 2014, sg ats est une filiale du groupe societe generale qui fournit des solutions agiles et efficaces aux salles des marches sg en europe (principalement a paris et londres) afin de les aider a se developper et a repondre aux exigences de plus en plus fortes imposees par les differentes legislations bancaires internationales.\n\nforte de son succes, sg ats fournit aujourd'hui des prestations a forte valeur ajoutee a differentes lignes de metiers du groupe (en europe principalement mais egalement aux etats-unis et en asie) sur des activites de marches, mais egalement a plusieurs directions du groupe societe generale.\n\nsacree  meilleur employeur 2023  maroc  sg ats est une structure jeune, dynamique qui positionne le capital humain au centre de son developpement. sg ats souhaite donc sentourer de talents qui participeront activement a la reussite de lentreprise tout en evoluant dans un environnement international propice au developpement de competences a forte valeur ajoutee.\n\n les informations recueillies sur ce site font lobjet dun traitement destine a repondre aux besoins de recrutement de la societe sg ats. ces donnees sont traitees par les services internes de la societe. conformement a la loi n 09-08 promulguee par le dahir 1-09-15 du 18 fevrier 2009, relative a la protection des personnes physiques a legard du traitement des donnees a caractere personnel, vous beneficiez dun droit dacces et de rectification aux informations qui vous concernent, que vous pouvez exercer en vous adressant a donnees-personnelles.sgats@sgcib.com. vous pouvez egalement, pour des motifs legitimes, vous opposer a ce que les donnees qui vous concernent fassent lobjet dun traitement. ces donnees peuvent faire lobjet dun transfert a letranger. ces traitements ont ete notifies et autorises par la cndp sous les numeros a-rh-354/2016 et t-rh-129/2016.\n\n diversite et inclusion\n\nnous sommes un employeur garantissant l'egalite des chances et nous sommes fiers de faire de la diversite une force pour notre entreprise. le groupe sengage a reconnaitre et a promouvoir tous les talents, quels que soient leurs croyances, age, handicap, origine ethnique, nationalite, appartenance a une organisation politique, religieuse, syndicale ou a une minorite, ou toute autre caracteristique qui pourrait faire lobjet dune discrimination.",
  "company_name": "societe generale",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "sql",
    "azure"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem solving"
  ],
  "sector": [
    "finance",
    "banking"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/crsa-postdoctoral-researcher-in-coastal-ecosystem-monitoring-using-satellite-data-at-um6p-university-mohammed-vi-polytechnic-4185150464",
  "titre": "crsa - postdoctoral researcher in coastal ecosystem monitoring using satellite data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-15",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position title: postdoctoral researcher  coastal ecosystem monitoring and agricultural runoff impacts\n\nduration: 2 years\n\nlocation: mohammed vi polytechnic university (um6p), morocco\n\nabout um6p\n\nlocated at the heart of the future green city of benguerir, mohammed vi polytechnic university (um6p), a higher education institution with international standards, is established to contribute to the development of morocco and the african continent. its vision is honed around research and innovation at the service of education and development. this unique nascent university, with its state-of-the-art campus and infrastructure, has woven a sound academic and research network, and its recruitment process is seeking high-quality academics and professionals in order to boost its quality-oriented research environment in the metropolitan area of marrakech.\n\nabout crsa\n\ncrsa is a transversal structure across several um6p programs. research within the center is organized around several major areas that aim to ensure the challenging food and water security goal in africa, with a special focus on developing methods/tools that use multi-source remotely sensed data. the research aims to improve our understanding of the integrated functioning of continental surfaces and their interaction with climate and humans, with emphasis on sustainable management of natural resources (soil, land, water, agriculture) in the context of climate change. one of the centers goals is to provide a set of services and operational products to users (local, national, and international) that aid in the decision support of water and food systems.\n\nposition overview\n\nthe mohammed vi polytechnic university (um6p) is seeking a highly motivated postdoctoral researcher to work on an interdisciplinary project focused on monitoring the impacts of agricultural runoff on coastal ecosystems along the moroccan coast. the project will utilize advanced satellite remote sensing data (e.g., sentinel-3, landsat, etc.) combined with additional open datasets to assess phytoplankton dynamics, nutrient loading, and harmful algal blooms (habs). the research will contribute to understanding the ecological health of the region.\n\nkey responsibilities\n\n conduct independent research focused on analyzing satellite-derived data (sentinel-3, landsat) to monitor coastal ecosystem changes.\n develop workflows in r, python, or matlab to process and analyze ocean color data, with a focus on chlorophyll-a, suspended particulate matter, and colored dissolved organic matter (cdom).\n assess the impact of agricultural runoff on coastal water quality, particularly nutrient enrichment and its relationship with phytoplankton blooms.\n use remote sensing to detect harmful algal blooms (habs) and assess their spatiotemporal variability along the moroccan coastline.\n investigate links between satellite data and key ecological indicators, including the presence of phytoplankton species indicative of nutrient imbalances.\n collaborate with researchers and institutions (e.g., ocp group) to align the research with sustainable agriculture and environmental monitoring initiatives.\n contribute to scientific publications, project reports, and presentations at international conferences.\n potentially assist in proposal writing to seek additional funding for fieldwork.\n\n\nqualifications\n\n phd in oceanography, environmental sciences, remote sensing, or a related field.\n strong expertise in satellite remote sensing, including atmospheric correction techniques.\n proficiency in r, python, or matlab for data processing, geospatial analysis, and statistical modeling.\n experience with time series analysis, spatial mapping, and oceanographic data interpretation.\n experience in writing scientific papers and presenting research results.\n ability to work independently and collaboratively in an interdisciplinary research environment.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "unspecified",
  "education_level": 4,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "r",
    "matlab"
  ],
  "soft_skills": [
    "communication",
    "research",
    "collaboration"
  ],
  "sector": [
    "research",
    "environmental science"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-alten-4204622028",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "alten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2024. avec plus de 90 recrutements par mois, alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\n\nrejoindre alten maroc c'est beneficier :\n\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers.\n des formations certifiantes et diplomantes.\n des evenements reguliers pour combiner bien etre et performance.\n\n\ndescription du poste\n\nles differentes activites confiees a lequipe  data & analytics - palantir foundry :\n\n\n -developper des tableaux de bord et des vues analytiques dans palantir foundry (incluant workshop, contour, etc.).\n -concevoir et optimiser des pipelines de donnees pour garantir une alimentation continue et precise des modeles analytiques.\n -collaborer avec les equipes metiers pour traduire les processus et les exigences en produits de donnees robustes et adaptes.\n -nettoyer, transformer et organiser les donnees brutes en formats exploitables pour l'analyse.\n -developper des scripts et des solutions sur mesure en utilisant pyspark, java et typescript.\n -integrer et gerer des bases de donnees relationnelles (snowflake, sql) tout en developpant des requetes performantes.\n -concevoir et maintenir des tableaux de bord interactifs sur power bi, avec transformation des donnees via power query.\n -appliquer des methodes statistiques et utiliser des outils comme python (pandas, numpy) pour des analyses avancees.\n -participer a des projets danalyse predictive en utilisant des algorithmes de machine learning de base, si necessaire...\n\n\nqualifications\n\nprofil recherche :\n\n\n bac +5 en data ou equivalent ;\n experience souhaitee : un an et plus ;\n bon niveau de communication : francais/ anglais...\ncompetences requises :\n\n\noutils de developpement et danalyse : palantir foundry :\n\n\n-modules : workshop, contour\n\n\n-creation de pipelines de donnees, tableaux de bord, et produits analytiques.\n\n\nlangages de programmation :\n\n\n-pyspark\n\n\n-java\n\n\n-typescript\n\n\nbases de donnees et requetes :\n\n\n-snowflake : gestion des bases de donnees relationnelles.\n\n\n-sql : redaction de requetes performantes pour lintegration et lanalyse des donnees.\n\n\noutils de visualisation et transformation :\n\n\npower bi :\n\n\n-creation de tableaux de bord interactifs.\n\n\n-analyse et exploration de donnees visuelles.\n\n\npower query :\n\n\n-transformations avancees des donnees pour les rapports et analyses.\n\n\noutils et bibliotheques statistiques : python :\n\n\n-bibliotheques principales : pandas, numpy.\n\n\n-analyse statistique et manipulation des donnees\n\n\n\n\ninformations supplementaires\n\nvous etes rigoureux, creatif, curieux et vous aimez travailler en equipe et monter en competence dans un environnement dynamique, les metiers du service vous animent et vous souhaitez evoluer dans un environnement convivial, rejoignez-nous !\n\n\nau plaisir de vous lire !",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 2,
  "experience_years": 1,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "sql",
    "power bi"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-databricks-senior-at-lumenalta-4214844766",
  "titre": "data engineer - databricks - senior",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-26",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "experience remote done right. with over 20 years of remote experience, all 500+ staff are 100% remote, and we still grow vibrant relationships and provide exceptional opportunities for career growth while working with stellar clients on ambitious projects.\n\n\nwhat we're working on:\nenterprise companies turn to us to help them launch innovative digital products that interact with hundreds of millions of customers, transactions and data points. the problems we solve daily are real and require creativity, grit and determination. we are building a culture that challenges norms while fostering experimentation and personal growth. to grasp the scale of problems we face, ideally, you have some exposure to logistics, fintech, transportation, insurance, media or other complex multifactor industries.\n\n\nrequirements\n 7+ years experience in a senior developer role using python; ideally, you have delivered business-critical software to large enterprises\n you are comfortable manipulating large data sets and handling raw sql\n experience using technologies such as pyspark/aws/databricks is essential\n experience creating etl pipeline from scratch\n e-commerce and financial services industry experience preferred\n english fluency, verbal and written\n personality traits: professional, problem solver, proactive, passionate, team player.\n\n\nwhy lumenalta is an amazing place to work at\nat lumenalta, you can expect that you will:\n be 100% dedicated to one project at a time so that you can innovate and grow.\n be a part of a team of talented and friendly senior-level developers.\n work on projects that allow you to use leading tech.\n\n\nthe result? we produce meaningful outcomes for our clients that break barriers in their industries.\n\n\nthe job is 100% remote; please ensure you have a comfortable office set at your desired work location.\n\n\nlumenalta is committed to hiring exceptional talent from a wide variety of diverse backgrounds. if you share our values and enthusiasm for digital transformation, we encourage you to apply\n\n\nwhat's it like to work at lumenalta?",
  "company_name": "lumenalta",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "databricks"
  ],
  "soft_skills": [
    "teamwork",
    "problem solving",
    "communication"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-at-datafuze-4194202784",
  "titre": "data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-26",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "about us:\njoin our dynamic team where your work will directly contribute to delivering secure, scalable, and efficient data solutions. we value curiosity, collaboration, and continuous growth.\n\n\nthe role:\nwe are looking for a passionate data engineer to join us in designing, building, and maintaining a cutting-edge, high-quality data platform on azure. you will collaborate with business and it partners to deliver secure, flexible, and cost-efficient solutions and work alongside talented cloud engineers, data engineers, and analysts. a key part of your role will be enabling seamless ci/cd pipelines to deploy platforms and data pipelines with precision and scalability.\n\n\nwhat you will do:\n design, build, and maintain our azure data platform.\n collaborate with business and it partners on solution delivery.\n work within a team of cloud engineers, data engineers, and analysts.\n enable and utilize ci/cd pipelines for deployment.\n\n\nwhat you will bring (required skills):\n proven experience in data engineering\n strong experience with data platforms.\n proficiency in python.\n experience with infrastructure-as-code tools, specifically terraform.\n experience with azure ci/cd tooling.\n scripting skills in bash.\n knowledge of containerization technologies like docker.\n familiarity with monitoring tools such as grafana and prometheus.\n experience with git (e.g., github/bitbucket).\n core competencies: analytical thinking, collaborating, conceptual thinking, data-driven, it security awareness, problem-solving, process-driven, result-driven, tactical & strategic planning.\n soft skills: exceptional french/english communication (oral and written), a growth mindset with initiative, determination, and curiosity to learn, humility, and the ability to teach and collaborate effectively.\n\n\nwhat would make you stand out (optional skills):\n experience with dbt.\n experience with kubernetes for container orchestration.\n familiarity with ci/cd tools like azure devops.\n experience with automation workflows using github actions.\n\n\nwhy join us?\nbe part of an innovative team building the future of data solutions. we offer an environment that fosters curiosity, collaboration, and continuous growth.",
  "company_name": "datafuze",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 2,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "terraform",
    "azure"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem solving"
  ],
  "sector": [
    "it",
    "data"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cbs-postdoctoral-position-artificial-intelligence-applied-to-multi-omics-data-integration-at-um6p-university-mohammed-vi-polytechnic-4225921759",
  "titre": "cbs - postdoctoral position: artificial intelligence applied to multi-omics data integration",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-08",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position overview\n\nwe are seeking an outstanding postdoctoral researcher in artificial intelligence (ai) and data science with expertise in multi-omics data integration for health and precision medicine. the successful candidate will join a multidisciplinary team developing ai-driven approaches to integrate and analyze genomics, transcriptomics, proteomics, metabolomics, and microbiome datasets to uncover biomarkers, therapeutic targets, and mechanistic insights into complex diseases.\n\nthe project addresses critical challenges in personalized medicine, disease stratification, and multi-modal data fusion, enabling next-generation solutions in precision health and biomedical research.\n\nscientific challenges addressed in the position\n\n heterogeneity and high dimensionality of multi-omics data requiring advanced ai/ml methods for robust analysis and integration.\n data sparsity, batch effects, and missing values across different omics layers and platforms.\n cross-omics data fusion and representation learning for comprehensive systems biology modeling.\n identification of causal relationships and biomarker discovery through integrative approaches.\n time-series and longitudinal multi-omics data analysis for disease progression modeling.\n explainability and interpretability of ai models to support clinical decision-making and regulatory compliance in healthcare settings.\n scalability and computational efficiency in processing and integrating massive multi-omics datasets from clinical cohorts.\n\n\nkey responsibilities\n\n design and implement ai/ml pipelines for multi-omics data integration, including supervised and unsupervised learning methods.\n develop deep learning architectures (e.g., variational autoencoders, graph neural networks, transformers) for cross-omics data representation and feature extraction.\n apply multi-view learning, transfer learning, and data fusion techniques to integrate heterogeneous omics datasets and clinical metadata.\n conduct network-based analysis (gene regulatory networks, protein-protein interaction networks, metabolic networks) to identify key disease drivers and biomarkers.\n build predictive models for disease classification, patient stratification, and treatment response prediction.\n collaborate with biologists, clinicians, and bioinformaticians for data interpretation and validation of computational findings in clinical or experimental settings.\n disseminate research outcomes through publications in high-impact journals, conference presentations, and workshops.\n mentor and support the training of graduate students and early-career researchers in ai and multi-omics integration.\n\n\nrequired qualifications\n\n ph.d. in bioinformatics, computational biology, data science, artificial intelligence, or a related field.\n proven experience in multi-omics data integration, omics data analysis (genomics, transcriptomics, proteomics, metabolomics, microbiome).\n strong expertise in machine learning, deep learning, and advanced ai frameworks (tensorflow, pytorch, scikit-learn). experience with bioinformatics tools and databases (e.g., bioconductor, galaxy, kegg, reactome, string).\n proficiency in python, r, and unix/linux-based environments for high-performance data analysis. knowledge of biological network inference, causal modeling, and graph-based ai approaches.\n experience in multi-modal data fusion, representation learning, and heterogeneous data integration.\n strong publication record in relevant peer-reviewed journals.\n excellent communication skills and ability to work in a multidisciplinary environment.\n familiarity with cloud-based computing platforms (aws, azure, google cloud) and high-performance computing (hpc) environments.\n understanding of data privacy, security, and ethical considerations in handling clinical data.\n\n\napplication process\n\ninterested candidates should submit the following documents in a single pdf:\n\n a cover letter outlining their research interests, motivation, and relevant experience.\n a detailed curriculum vitae (cv) with a list of publications.\n contact details of two academic referees.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "research scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "machine learning",
    "deep learning"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "mentoring"
  ],
  "sector": [
    "research",
    "academia"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-wama-invest-4188804764",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-19",
  "location": {
    "city": "casablanca",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "offre d'emploi : data analyst\nlieu :casablanca\nexperience requise : 5 ans \ndescription du poste :\nnous recherchons un data analyst talentueux et rigoureux pour rejoindre notre equipe. le candidat ideal aura une excellente maitrise de la gestion des donnees, de l'analyse statistique et des outils de visualisation. son role principal sera d'exploiter les donnees issues de differentes sources afin de fournir des analyses pertinentes pour optimiser les prises de decision strategiques.\nmissions principales :\n recuperer, structurer et organiser les donnees issues de differentes sources pour assurer leur qualite et coherence.\n effectuer des analyses descriptives pour identifier les tendances et les anomalies.\n utiliser des statistiques et des modeles analytiques pour repondre aux problematiques metier.\n concevoir des tableaux de bord interactifs et des rapports pour presenter les resultats (power bi, tableau, excel, python, etc.).\n suivre les performances a laide dindicateurs cles (kpi).\n realiser des tableaux de bord en concertation avec le chef de projet data.\n mettre a jour la documentation associee au workflow ou la creer si besoin.\n alimenter regulierement le data catalogue avec tout kpi calcule.\n implementer, assainir et optimiser les kpis demandes par le metier.\n concevoir des datamarts adequats respectant la modelisation mise en place par la charte de gouvernance.\n identifier et remonter les dysfonctionnements et les ameliorations a apporter a la gestion quotidienne de son activite (processus, procedures, outils, interface...).\n proposer des solutions d'ameliorations operationnelles et contribuer le cas echeant au deploiement de ces solutions.\ncompetences requises :\n maitrise des langages de programmation : python.\n competences solides en sql et manipulation de bases de donnees.\n experience avec les outils de visualisation de donnees : tableau, power bi.\n bonne maitrise de la visualisation de donnees et de la modelisation de datamarts.\n experience dans l'optimisation et l'assainissement des kpis.\n connaissance des systemes dexploitation : windows, rhel.\n la connaissance de dremio serait un plus.\nprofil recherche :\n bac +5 en informatique, statistiques, data science, mathematiques appliquees ou domaine connexe.\n experience significative en analyse de donnees, bi et reporting.\n capacite a manipuler des donnees complexes et a en extraire des insights pertinents.\n esprit analytique, rigueur et attention aux details.\n bonne capacite de communication pour presenter des analyses a des interlocuteurs varies.",
  "company_name": "wama invest",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "power bi"
  ],
  "soft_skills": [
    "communication",
    "analytical skills",
    "attention to detail"
  ],
  "sector": [
    "finance",
    "investment"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-azure-senior-at-confidentiel-4226710961",
  "titre": "data engineer azure senior",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-09",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "dans le cadre de notre croissance, nous recherchons un data engineer azure senior pour rejoindre nos equipes techniques et intervenir sur des projets a forte valeur ajoutee\nvos missions principales\nen tant que data engineer senior, vous serez un acteur cle dans la structuration et la mise en uvre des solutions data sur le cloud azure :\n concevoir, developper et maintenir des pipelines de donnees sur azure data factory (adf) et azure synapse analytics\n participer activement aux projets de migration de donnees vers le cloud azure\n optimiser les traitements de donnees complexes a laide de sql avance et de python\n garantir la qualite, la performance et la fiabilite des flux de donnees\n collaborer etroitement avec les equipes bi, developpement et metier pour comprendre les besoins et proposer des solutions adaptees\n participer a lindustrialisation de la plateforme data et a la mise en uvre des bonnes pratiques\n assurer une veille technologique continue et encadrer techniquement certains sujets, en accompagnant les profils plus juniors au besoin etc...\nprofil recherche\n minimum 5 ans dexperience en ingenierie de donnees, avec une expertise sur lecosysteme azure\n maitrise de adf, azure synapse analytics, sql avance, python\n bonne connaissance des architectures data dans le cloud\n esprit danalyse, rigueur, autonomie et sens du travail en equipe\n capacite a encadrer et transmettre son savoir\ntype d'emploi : cdi",
  "company_name": "confidentiel",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": null,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "azure data factory",
    "azure synapse analytics",
    "sql"
  ],
  "soft_skills": [
    "collaboration",
    "analytical skills",
    "problem-solving"
  ],
  "sector": [
    "technology",
    "data engineering"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-audit-interne-at-soci%C3%A9t%C3%A9-g%C3%A9n%C3%A9rale-maroc-4187983001",
  "titre": "data analyst - audit interne",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-23",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "rattache(e) a notre service unit audit et inspection generale, votre role sera d'apporter une expertise data au metier daudit en termes d'acces a la donnee, d'accompagnement des missions, de conception doutils et methodes danalyse ainsi que l'animation du sujet data aupres des auditeurs. \n\n\nvos missions principales: \n comprendre et expliciter les problematiques des missions, notamment avec une orientation data\n explorer et analyser les donnees permettant de mieux orienter la mission d'audit\n organiser la collecte des donnees, en mettant a la disposition des auditeurs les echantillons les plus pertinents a controler\n realiser lanalyse des donnees en accord avec les besoins des intervenants de la mission\n rediger un rapport de synthese detaille et presenter les resultats y afferents\n participer a la formation des inspecteurs et des auditeurs a lanalyse de donnees\n realiser une veille technologique continue sur le sujet de la data science\n contribuer au renouvellement et a l'amelioration des outils et de la methodologie danalyse des donnees appliquee aux missions\n identifier le lien entre les donnees recueillies et les besoins des missions\n\n\nprofil recherche: \ndiplome(e) d'une ecole d'ingenieur ou d'une universite avec une specialisation en data avec 2 ans d'experience au moins en analyse de donnees, idealement en finance. \n excellente maitrise de python \n solides connaissances en sql \n bonne maitrise des outils de visualisation \n rigueur et esprit critique \n bon esprit d'equipe",
  "company_name": "societe generale maroc",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": null,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "sql",
    "data visualization"
  ],
  "soft_skills": [
    "analytical skills",
    "critical thinking",
    "teamwork"
  ],
  "sector": [
    "finance",
    "audit"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/crsa-postdoctoral-researcher-in-coastal-ecosystem-monitoring-using-satellite-data-at-um6p-university-mohammed-vi-polytechnic-4227856257",
  "titre": "crsa - postdoctoral researcher in coastal ecosystem monitoring using satellite data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-11",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position title: postdoctoral researcher  coastal ecosystem monitoring and agricultural runoff impacts\n\nduration: 2 years\n\nlocation: mohammed vi polytechnic university (um6p), morocco\n\nabout um6p\n\nlocated at the heart of the future green city of benguerir, mohammed vi polytechnic university (um6p), a higher education institution with international standards, is established to contribute to the development of morocco and the african continent. its vision is honed around research and innovation at the service of education and development. this unique nascent university, with its state-of-the-art campus and infrastructure, has woven a sound academic and research network, and its recruitment process is seeking high-quality academics and professionals in order to boost its quality-oriented research environment in the metropolitan area of marrakech.\n\nabout crsa\n\ncrsa is a transversal structure across several um6p programs. research within the center is organized around several major areas that aim to ensure the challenging food and water security goal in africa, with a special focus on developing methods/tools that use multi-source remotely sensed data. the research aims to improve our understanding of the integrated functioning of continental surfaces and their interaction with climate and humans, with emphasis on sustainable management of natural resources (soil, land, water, agriculture) in the context of climate change. one of the centers goals is to provide a set of services and operational products to users (local, national, and international) that aid in the decision support of water and food systems.\n\nposition overview\n\nthe mohammed vi polytechnic university (um6p) is seeking a highly motivated postdoctoral researcher to work on an interdisciplinary project focused on monitoring the impacts of agricultural runoff on coastal ecosystems along the moroccan coast. the project will utilize advanced satellite remote sensing data (e.g., sentinel-3, landsat, etc.) combined with additional open datasets to assess phytoplankton dynamics, nutrient loading, and harmful algal blooms (habs). the research will contribute to understanding the ecological health of the region.\n\nkey responsibilities\n\n conduct independent research focused on analyzing satellite-derived data (sentinel-3, landsat) to monitor coastal ecosystem changes.\n develop workflows in r, python, or matlab to process and analyze ocean color data, with a focus on chlorophyll-a, suspended particulate matter, and colored dissolved organic matter (cdom).\n assess the impact of agricultural runoff on coastal water quality, particularly nutrient enrichment and its relationship with phytoplankton blooms.\n use remote sensing to detect harmful algal blooms (habs) and assess their spatiotemporal variability along the moroccan coastline.\n investigate links between satellite data and key ecological indicators, including the presence of phytoplankton species indicative of nutrient imbalances.\n collaborate with researchers and institutions (e.g., ocp group) to align the research with sustainable agriculture and environmental monitoring initiatives.\n contribute to scientific publications, project reports, and presentations at international conferences.\n potentially assist in proposal writing to seek additional funding for fieldwork.\n\n\nqualifications\n\n phd in oceanography, environmental sciences, remote sensing, or a related field.\n strong expertise in satellite remote sensing, including atmospheric correction techniques.\n proficiency in r, python, or matlab for data processing, geospatial analysis, and statistical modeling.\n experience with time series analysis, spatial mapping, and oceanographic data interpretation.\n experience in writing scientific papers and presenting research results.\n ability to work independently and collaboratively in an interdisciplinary research environment.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "research scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "remote sensing",
    "python",
    "matlab"
  ],
  "soft_skills": [
    "collaboration",
    "communication",
    "problem-solving"
  ],
  "sector": [
    "research",
    "environmental science"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/chef-de-projet-data-senior-at-intelcia-it-solutions-4214029486",
  "titre": "chef de projet data senior",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-21",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "nous recherchons un chef de projet data senior ayant une forte experience en gestion de et pilotage de projets pour la mise en place de grandes plateformes data pour notre client.\nvous devez posseder une expertise technique et fonctionnelle dans la gestion de projets data, afin dassurer lexecution des projets dans le respect des delais, budgets et exigences client.\nvous serez responsable de la coordination des equipes et de la gestion de projets impliquant des technologies comme starbust ou equivalents (bigquery ...) et dataiku dss avec un focus sur la mise en uvre de solutions efficaces et innovantes pour lorganisation.\n\n\nmissions principales\n piloter des projets de build complexes, dans un environnement de transformation numerique incluant lintegration.\n gestion des ressources : encadrer une equipe technique multidisciplinaire (architectes, data scientistes, analystes etc..)\n communication efficace : savoir traduire les besoins business en exigences techniques, assurer une communication reguliere et efficace avec les parties prenantes,\n gestion des parties prenantes interface entre les equipes metiers et techniques en assurant une bonne comprehension des enjeux et des objectifs.\n suivi de la qualite et des performances : qualite de la plateforme data a deployer, des livrables a chaque phase du projet en mettant en place les indicateurs de performance pertinents.\n suivi de lavancement et des budgets.\n\n\nprofil recherche\n formation : bac + 5 (master ou ecole dingenieur) en systeme dinformation\n experience ; minimum 5ans dexperience en gestion de projets data complexes (dataiku dss, starbust ou bigquery)\n competences averees en gestion de projet, avec une approche agile et lean.\n leadership et capacite a encadrer une equipe multidisciplinaire.\n bonne maitrise des outils de gestion de projet (jira, confluence.).\n competences interpersonnelles : excellentes capacites de communication et de negociation, sens de lecoute et aptitude a resoudre les conflits\n competences linguistiques : francais et anglais.",
  "company_name": "intelcia it solutions",
  "is_data_profile": true,
  "profile": "unspecified",
  "education_level": null,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "dataiku dss",
    "starburst",
    "project management"
  ],
  "soft_skills": [
    "communication",
    "leadership",
    "problem-solving"
  ],
  "sector": [
    "technology",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-h-f-at-labelvie-4173625133",
  "titre": "data engineer (h/f)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-07",
  "location": {
    "city": "casablanca",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "cree en 1986 et cote a la bourse de casablanca depuis 2008, le groupe marocain labelvie est un acteur economique de reference et leader de la grande distribution au maroc.\nen 2009, a travers la signature du contrat de franchise avec le groupe carrefour, il accede a sa centrale dachat pour optimiser et diversifier son sourcing. il devient ainsi le premier acteur multi-formats de la grande distribution au maroc par lexploitation des hypermarches carrefour, des supermarches carrefour market et du format hyper cash atacadao.\nle groupe labelvie presente chaque annee un plan de developpement soutenu renforcant sa presence territoriale avec ses 136 magasins repartis dans 28 villes du royaume et ses 3 plateformes logistiques et un chiffre daffaires realise de 11,7 milliards de dirhams en 2021.\nen 2021, le groupe labelvie a entame sa transformation digitale afin de repondre aux enjeux dinnovation et aux besoins des consommateurs finaux. ce sont ainsi de nombreux projets structurants qui sont actuellement en construction au sein du groupe pilotes par nos equipes si, digital et data ; constituees dexperts reconnus dans leur domaines et animes par la volonte de relever les challenges de linnovation et de la transformation digitale dans un secteur en plein essor.\n\n\nposte :\n\n\nle data engineer (h/f) a pour mission dassurer la collecte, le traitement et le stockage des donnees dans la plateforme data cloud azure de maniere efficace. il travaille sur limplementation de pipelines optimises et lexposition des donnees repondant aux besoins des cas dusages data ainsi que des applications.\n\n\nles principales responsabilites sont de :\n\n\n conception et developpement de pipelines de donnees pour l'extraction, le chargement et la transformation (elt) des donnees;\n creation et gestion de bases de donnees et d'entrepots de donnees;\n implementation de l'architecture de donnees et des modeles de stockage;\n automatisation des processus de gestion des donnees pour ameliorer l'efficacite et la productivite;\n optimisation des performances des pipelines et assurer un traitement efficace des donnees;\n mise en place de la securite des donnees et des mecanismes de protection des donnees sensibles;\n collaboration avec les parties prenantes (metiers, data scientists, data analysts, developpeurs...) pour soutenir les initiatives liees aux donnees;\n maintenance des pipelines de donnees developpes;\n documentation des processus et des normes lies a la gestion des donnees...\n\n\nprofil recherche :\n\n\nde formation bac+5 d'une ecole dingenierie avec une experience de minimum 2 ans dans la data engineering ou dans un poste similaire, dans laquelle vous avez developpe les competences techniques liees aux technologies suivantes :\n bonne connaissance des technologies data sur azure.\n maitrise des langages de programmation python et sql.\n bonne connaissance des outils et des frameworks de big data tels que hadoop, spark, kafka.\n competences dans la conception et le developpement de pipelines elt.\n competences en modelisation de donnees et gestion des schemas.\n connaissance des bases de donnees relationnelles et non relationnelles.\n capacite a optimiser les performances des bases de donnees...\n\n\n\n\n labelvie sengage a prevenir toute forme de discrimination et notamment celles fondees sur le sexe ou la situation et les responsabilites familiales. labelvie sengage a promouvoir legalite des chances entre les hommes et les femmes, en matiere dacces a lemploi et a la formation, de conditions de travail, de remuneration, devolution de carriere et dacces a des postes a responsabilite .",
  "company_name": "labelvie",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": null,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "azure",
    "python",
    "sql"
  ],
  "soft_skills": [
    "collaboration",
    "problem-solving",
    "communication"
  ],
  "sector": [
    "retail",
    "data engineering"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analytics-senior-data-scientist-casablanca-at-infomineo-4221194075",
  "titre": "data analytics - senior data scientist - casablanca",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-06",
  "location": {
    "city": "casablanca",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "about us\ninfomineo is a brainshoring services company, supporting global clients from various geographies and industries across a range of services: business research, business translation, graphic design and data analytics.\ninfomineo counts +250 employees spread across different offices in the emea region and the americas. our clients include leading consultancies, fortune 500 companies, governments and ngos.\nabout this role\nthis role will give you the opportunity to deliver high-added value data & analytics projects and build high-quality and innovative solutions for our clients within a growing service company.\nwhat will you do?\n propose solutions and strategies to tackle business challenges.\n contribute to the design of the technical solution chosen to collect, analyze data, and display the results obtained.\n manage a project from a to z\n analyze large amounts of information to find patterns and solutions.\n data mining or extracting usable data from valuable data sources.\n carry out preprocessing of structured and unstructured data\n enhance data collection procedures to include all relevant information for developing analytic systems.\n develop prediction systems and machine learning algorithms\n present results in a clear manner\n processing, cleansing, and validating the integrity of data to be used for analysis.\n assist the it teams in all phases of the production, maintenance, and update of the models developed.\n provide internal training to new joiners when needed.\n support the team lead/manager regarding client relationships, business development, and internal projects.\nrequirements\nwho are you?\neducation & professional experience\n master's degree in a relevant field such as computer science, machine learning, data science, statistics, applied mathematics, data engineering\n 4 to 8 years of technical experience in advanced analytics and data science\n full proficiency in english + 1 additional language (french, german, arabic, spanish, italian, portuguese...)\ntechnical skills\n proven hands-on experience in python programming language coupled with additional languages experience if possible (e.g. sas, r, javascript)\n strong skills in statistics & machine learning such as regressions, clustering techniques, time series techniques, bagging & boosting trees, ensemble models, neural networks\n exposure to bi/data visualization platforms such as power bi, tableau, looker, qlikview...\n proven hands-on experience in big data environments and languages such as hadoop, hortonworks, cloudera, spark, scala, pyspark, etc. &big data querying tools, such as pig, hive, and impala\n proven hands-on experience in large data sets both structured and unstructured data: snowflake, sql and relational databases, data warehouse, data lake\n exposure to nosql databases, such as hbase, cassandra, mongodb\n proven hands-on experience in api integration using python for extracting data from different sources\n proven hands-on experience in container technologies  docker, kubernetes, etc.\n proven hands-on experience in solutions development & deployment experience in cloud ecosystems and its associated services aws, azure, google cloud, and ibm cloud.\n experience in building robust data pipelines using etl techniques and frameworks, such as flume\n experience to work with large volumes of structured and unstructured data and leveraging it to build ai/ml model deployment & monitoring/enhancements for standalone solutions or through end-to-end automated data pipelines\n\n\ninterpersonal skills\n can step back, analyze problems, find solutions and the drive to implement these. good management skills with a track record of coordinating workflow and assuring quality with a strong ability to multitask.\n can work & collaborate with variety of stakeholders & clients throughout data project lifecycle\n strong interpersonal skills and organizational skills, high motivation, an attention to detail, flexibility, and ability to cope under stress, a focus on identifying the solutions to problems.\n strong communication skills & ability to translate complex solutions into business implications and at the same time being able to explain mathematical concepts when required\nbenefits\nwhat we offer\n a competitive salary\n a great working environment\n a steep learning curve with interesting and diverse topics to work on\n a healthy work-life balance\n health insurance benefits\n\n\n\n\nequal opportunity employer\ninfomineo is an equal opportunity employer, we prohibit any sort of discrimination (based on color, race, sex, sexual orientation, religion, national origin or any other attributes) in all aspects of employment (recruiting, hiring, wages and salary, promotions, benefits, training and job termination).\nif you believe you match our requirements and values, we would be happy to hear from you. visit our website to know more about us, our services and company culture.",
  "company_name": "infomineo",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 8,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "machine learning",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "problem-solving"
  ],
  "sector": [
    "consulting",
    "data science"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cus-postdoctoral-researcher-in-spatial-data-science-at-um6p-university-mohammed-vi-polytechnic-4222150972",
  "titre": "cus - postdoctoral researcher in spatial data science",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-03",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position description\n\nwe are seeking a postdoctoral researcher specializing in urban modeling and cost analysis to develop an innovative model to estimate the direct and indirect costs of urbanization based on urban morphology (compact or sprawling). the candidate will analyze real case studies, integrate variables related to infrastructure, health, and the environment, and simulate scenarios under different climatic and social contexts to provide decision-making tools for sustainable urban planning.\n\nmain tasks and responsibilities\n\n develop a predictive model integrating the direct and indirect costs of urbanization.\n calibrate this model using real data from specific case studies.\n simulate urbanization costs based on various climatic, morphological, and social scenarios.\n formulate innovative methodological approaches.\n produce publications on research in scientific journals.\n participate in teaching activities.\n develop new research proposals.\n\n\nrequired qualifications\n\n ph.d. in data science, urban planning, urban economics, or a related field.\n experience in research projects applied to urban, environmental, or socio-economic issues.\n proficiency in urban modeling tools such as matlab, python (especially libraries like pandas, numpy, scipy, geopandas, etc.), and r.\n advanced skills in predictive modeling and machine learning, particularly for multi-variable simulations.\n knowledge of complex systems modeling applied to urban dynamics.\n publications in scientific journals.\n\n\npersonal and organizational qualifications\n\n ability to develop innovative methods.\n ambition for research excellence.\n interest in african issues.\n entrepreneurial mindset, dynamism, and organizational skills.\n fluency in both french and english (oral and written) is required.\n\n\nwe offer\n\n excellent working conditions and competitive salary on an international scale.\n an opportunity to contribute to the development of research excellence in africa.\n a highly stimulating multicultural working environment and a great team atmosphere.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "research scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "machine learning",
    "urban modeling"
  ],
  "soft_skills": [
    "innovation",
    "communication",
    "organization"
  ],
  "sector": [
    "research",
    "urban planning"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/stagiaire-business-data-analyst-at-digital-virgo-4182775647",
  "titre": "stagiaire business data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-17",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "le groupe digital virgo compte parmi les specialistes mondiaux du paiement mobile via les solutions de facturation des operateurs telecoms. en connectant les marchands aux operateurs, nous repondons au besoin croissant de digitalisation du paiement en utilisant un canal transactionnel simple, rapide et securise, disponible partout dans le monde.\n\n\nen rejoignant digital virgo, tu integres un groupe international performant et innovant grace a des equipes locales, a taille humaine qui collaborent au quotidien, fortes de leur complementarite. nous venons tous dunivers et de parcours differents, cest cette diversite qui fait notre richesse.\n\n\nnos collaborateurs disent de nous, que l'ambiance de travail est un melange parfait de bonne humeur et de projets ambitieux. nous mettons l'accent sur le developpement de chacun et la prise d'initiatives.\n\n\nplus dinformations sur notre activite et groupe sur digitalvirgo.com\n\n\n\n\ndescription du poste\n\ncollecte et traitement des donnees\n\n\n extraction des donnees via base de donnees ou outils bi\n sassurer de la fiabilite des donnees avant utilisation\n\n\n\nanalyse et interpretation\n\n\n realiser des analyses pour identifier des tendances ou insights business\n construire des tableaux de bord et des rapports pour suivre les perfs cles\n aider a la prise de decision grace a des recommandations basees sur les resultats des analyses\n\n\n\nvisualisation des donnees\n\n\n concevoir des graphiques et dashboards interactifs pour rendre les analyses plus accessibles aux equipes metiers\n utiliser des outils comme tableau ou looker\n\n\n\nsupport aux equipes metier\n\n\n travailler en collaboration avec les equipes marketing, finance, produit, etc., pour repondre a leurs besoins en data.\n expliquer les resultats des analyses et aider a la prise de decision strategique.\n\n\nqualifications\n\ntechniques :\n\n\nmaitrise dexcel (tableaux croises dynamiques, formules avancees, etc.)\nconnaissance en sql (requetes pour extraire et manipuler des donnees)\nfamiliarite avec des outils de data visualisation (tableau, looker.)\nbases en python  (pour lanalyse et le traitement des donnees, un plus)\ncomprehension des statistiques et des modeles analytiques\n\n\n\n\n\nsoft skills :\n\n\nesprit analytique et capacite a interpreter des chiffres\nrigueur et attention aux details\nautonomie et capacite a resoudre des problemes\nbonne communication en francais et en anglais",
  "company_name": "digital virgo",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": null,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "excel",
    "sql",
    "data visualization"
  ],
  "soft_skills": [
    "analytical skills",
    "communication",
    "problem-solving"
  ],
  "sector": [
    "technology",
    "fintech"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-engineer-%E2%80%93-freelance-at-proorga-consulting-4228421640",
  "titre": "senior data engineer freelance",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-12",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "offre de mission  senior data engineer\n\n\n secteur : distribution\n disponibilite : asap\n localisation : casablanca / mode hybride possible\n\n\n description du besoin\ndans le cadre du renforcement de sa data platform, notre client recherche un senior data engineer pour assurer la collecte, le traitement et le stockage des donnees sur microsoft azure. il jouera un role cle dans la mise en place de pipelines de donnees performants et leur exposition selon les besoins metiers.\nle consultant collaborera etroitement avec les equipes metiers et les equipes techniques (cto/dsi) pour concevoir des solutions robustes, securisees et evolutives.\n\n\n missions principales\n-developpement de pipelines de donnees (elt) performants et maintenables.\n-conception et administration de bases de donnees et entrepots de donnees.\n-implementation darchitectures et de modeles de donnees adaptes.\n-automatisation des workflows et optimisation des performances.\n-mise en place de mesures de securite pour la protection des donnees sensibles.\n-collaboration avec les metiers, data scientists, data analysts, developpeurs, etc.\n-maintenance evolutive et corrective des pipelines existants.\n-documentation des processus et normes.\n-veille technologique continue sur les outils et bonnes pratiques en data engineering.\n\n\n competences techniques requises\n-excellente maitrise de python et sql.\n-expertise sur azure data factory et azure databricks.\n-bonne connaissance des bases de donnees relationnelles et nosql.\n-competences solides en modelisation de donnees et gestion de schemas.\n-capacite a optimiser les performances des processus de traitement de donnees.\n\n\n profil recherche\n-formation : bac+5 dune ecole dingenieur ou universite avec specialisation data.\n-langues : maitrise du francais et de larabe.\n-seniorite : confirme / senior.\n-experience : minimum 5 ans en data engineering, idealement dans un environnement azure.",
  "company_name": "proorga consulting",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "azure data factory",
    "azure databricks"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "distribution"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-alten-4202459491",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "fez",
    "region": "fes-meknes",
    "country": null,
    "remote": false
  },
  "description": "alten maroc filiale du leader mondial de lingenierie et du conseil en technologies (ict), avec 46 000 collaborateurs au monde avec plus de 1500 au maroc repartis sur quatre centres dexcellence a fes, rabat, casa et tetouan nous accompagnons nos clients en offrant des solutions dingenierie agiles et novatrices pour les grands donneurs dordre mondiaux dans les secteurs de lautomobile, laeronautique, les reseaux & telecoms, software & outils.\n\n\n\nrejoindre alten maroc cest beneficier :\n\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers.\n des formations certifiantes et diplomantes.\n des evenements reguliers pour combiner bien etre et performance.\n\n\ndescription du poste\n\nnous recherchons un(e) data analyst junior passionne(e) pour rejoindre notre equipe. il/elle sera responsable de :\n\n\n conception et deploiement des systemes d'ia\n modelisation avancee pour resoudre des problemes complexes\n realisation des recettes des evolutions des outils\n developpement des notebooks en utilisant spark python\n test et validation de non-regression des donnees dessais de roulage\n support et animation de la resolution des incidents\n suivi des incidents aupres de la direction des systemes dinformation\n\n\nqualifications\n\ncompetences requises :\n\n\n maitrise du langage python\n bon niveau en francais et en anglais (parler & ecrit)\n maitrise de spark python\n maitrise de jupyter\n maitrise des algorithmes ml et dl\n conception et developpement d'infrastructure necessaire pour prendre en charge les projets d'ia, en utilisant les dernieres technologies et outils\n connaissance en git/github\n connaissance de bases de donnees structurees (oracle, mysql, sql server...)\n connaissance en hadoop\n habilite a acquerir de nouvelles connaissances\ncompetences appreciees :\n\n\n esprit de synthese\n analyse critique\n rigueur\n gestion relation clientele (communication, serviabilite, ecoute active)\n connaissance en culture automobile\n\n\n\n\n\ninformations supplementaires\n\nvous etes rigoureux, creatif, curieux et vous aimez travailler en equipe et monter en competence dans un environnement dynamique. les metiers du service vous animent et vous souhaitez evoluer dans un environnement convivial, rejoignez-nous !",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 2,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "spark",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "automotive",
    "aerospace",
    "telecoms",
    "software"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/client-solutions-engineer-data-at-lumenalta-4223145301",
  "titre": "client solutions engineer - data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-05",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "about lumenalta\nat lumenalta, we create impactful software solutions that drive innovation and transform businesses. since 2000, weve partnered with visionary leaders to build cutting-edge tech, solve complex challenges, and deliver results faster through our elite teams and tech-driven approach. join us in shaping the future of technology.\n\n\nabout the role:\nwe seek a client solutions engineer to architect and deliver technical solutions while fostering strong client relationships. combining technical expertise, sales acumen, and client-facing skills, youll advise senior leaders, identify challenges, propose tailored solutions, and lead implementations. youll also help shape lumenaltas offerings to support business development and long-term partnerships.\n\n\nresponsibilities\n design and implement data-centric solutions, including data pipelines, warehouses, and analytics platforms.\n support business development efforts by contributing to project scoping, proposals, and technical roadmaps.\n partner with senior stakeholdersmanagers, directors, vps, and c-suite leadersto define data strategies and deliver actionable insights.\n architect and optimize scalable systems for data storage, processing, and visualization across diverse business domains.\n lead teams of developers and data engineers, ensuring high-quality and on-time deliverables.\n employ deep knowledge of modern data engineering tools and frameworks to position lumenaltas offerings and meet client needs.\n drive the implementation of data governance, security, and compliance measures.\n take ownership of deliverables, ensuring solutions achieve business objectives and deliver measurable impact.\n\n\nrequirements\n 6+ years of client-facing experience in data architecture, engineering, or analytics, with strong consulting and business analysis skills.\n proven experience designing and implementing data pipelines, etl processes, and cloud-based data infrastructure (e.g., aws, azure, gcp).\n deep proficiency with modern data tools and platforms such as sql, python, apache spark, and bigquery.\n demonstrated ability to design scalable, robust systems tailored to client needs and business objectives.\n experience engaging with c-suite stakeholders, influencing strategic decisions, and communicating technical solutions effectively.\n strong understanding of data governance, security, and compliance standards.\n a proven track record of contributing to business development efforts, including solution positioning and proposal development.\n evidence of thought leadership, such as speaking engagements, publications, or an online portfolio of work.\n advanced english fluency, with excellent verbal and written communication skills.\n\n\nwhy lumenalta is an amazing place to work at\nat lumenalta, you can expect that you will:\n be 100% dedicated to one project at a time so that you can innovate and grow.\n be a part of a team of talented and friendly senior-level developers.\n work on projects that allow you to use leading tech.\n\n\nthe result? we produce meaningful outcomes for our clients that break barriers in their industries.\n\n\nwhat's it like to work at lumenalta?",
  "company_name": "lumenalta",
  "is_data_profile": true,
  "profile": "data consultant",
  "education_level": null,
  "experience_years": 6,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "python",
    "aws",
    "azure",
    "gcp",
    "apache spark",
    "bigquery"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-exp%C3%A9riment%C3%A9-at-alten-4184172626",
  "titre": "data analyst experimente",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-17",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "alten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2024. avec plus de 90 recrutements par mois, alten maroc est desormais un acteur majeur de linsertion professionnelle des  ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\n\n\n\ndescription du poste\n\nintegre(e) dans les equipes marchandises le/la consultant(e) aura pour mission de participer a la conception, au developpement et a la maintenance de solutions d'analyse de donnees. il/elle sera amene(e) a travailler sur des projets d'analyse de donnees pour ameliorer les performances et l'efficacite des operations de l'entreprise. la digital factory marchandise & commerciale a pour objectif de digitaliser les activites commerciales et de marchandises dans le but de simplifier, d'harmoniser et d'automatiser les processus operationnels de l'entreprise. nous travaillons avec les equipes business, product management et design pour concevoir des outils ergonomiques et fiables. nous recherchons un data analyst senior passionne et experimente dans l'analyse de donnees complexes. vous serez responsable de la collecte, du traitement, de l'analyse et de la visualisation des donnees pour fournir des insights strategiques. vous jouerez un role cle dans la prise de decision en collaborant etroitement avec des equipes metier, des developpeurs et des data engineers.\n\n\nanalyse et visualisation de donnees :\n\n\n developper des dashboards interactifs et dynamiques sous lokker et looker studio.\n identifier et suivre des kpis critiques pour le pilotage des activites metiers.\nmodelisation et preparation des donnees :\n\n\n concevoir des pipelines de donnees optimises dans bigquery.\n assurer la qualite et la fiabilite des donnees pour garantir la coherence des analyses. exploration et extraction des donnees :\n rediger et optimiser des requetes sql complexes sur bigquery.\n automatiser les traitements analytiques pour ameliorer les performances.\nsupport et collaboration :\n\n\n travailler en etroite collaboration avec les equipes metier des differents pays du groupe pour comprendre leurs besoins analytiques.\n former et accompagner les utilisateurs dans l'utilisation des dashboards et des outils danalyse.\n\n\nqualifications\n\n diplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique, ou justifiant d'une experience significative equivalente\n experience de plus de 5 ans en sql\n experience avec dbt, looker, looker studio et outils bi similaires\nune experience dans le secteur du commerce de detail ou de la grande distribution serait un plus.\n\n\n bonne maitrise des bases de donnees sql / nosql (dbl, postgresql, mongodb...)\n excellente maitrise de sql et experience avec bigquery.\n expertise dans la creation et loptimisation de dashboards sous looker studio.\n excellente communication ecrite et orale : aptitude a produire des livrables et des reportings de haute qualite.\n expertise en python (pandas, numpy, pyspark...)\n esprit d'analyse et d'amelioration continue : capacite a evaluer le code et ses impacts, ainsi qu'a remettre en question les solutions existantes pour les ameliorer.\n comprehension des principes devops et cloud (aws, gcp, azure)\n connaissance des architectures data modernes (data lake, data warehouse)\n capacite de prise de recul : aptitude a evaluer les problematiques avec objectivite et a proposer des solutions d'amelioration.\n esprit d'equipe : capacite a collaborer efficacement avec les membres de l'equipe pour atteindre des objectifs communs.\n maitrise des concepts dagilite (scrum, sprint planning, backlog...).\n capacite a travailler de maniere autonome et a gerer son temps efficacement.\n gestion des versions et ci/cd avec gitlab ci",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "bigquery",
    "looker",
    "looker studio",
    "python"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "retail"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-at-stellantis-middle-east-africa-4185257396",
  "titre": "data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-23",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "about the company: we are seeking a skilled and motivated data engineer to join our data & analytics team. the ideal candidate will be responsible for designing, developing, and maintaining our data infrastructure, ensuring the efficient and reliable flow of data across the organization. this role requires a strong understanding of data architecture, data modeling, and processes.\n\n\n\n\nabout the role: the ideal candidate is an experienced data engineer with a strong background in snowflake, sql, and cloud-based data solutions. self-motivated, independent problem-solver who is eager to learn new skills and adapt to changing technologies. collaboration, performance optimization, and a commitment to designing and maintaining the data platform, data security and compliance are critical for success in this role.\n\n\n\n\nresponsibilities:\n\n\n\n\n design, implement, and manage snowflake e2e data warehouse solutions.\n design, develop, and maintain scalable data pipelines, data models, transformations and etl processes according to business needs and aligned with standards and best practices.\n create and maintain data pipelines, data storage solutions, and data processing systems on the azure platform.\n work with azure sql database, azure data lake storage, azure cosmos db, and other storage solutions to design scalable and efficient data storage systems.\n utilise big data technologies like azure databricks and apache spark to handle and analyze large volumes of data.\n collaborate with data scientists, analysts, suppliers, and other stakeholders to understand data requirements and deliver solutions.\n develop dashboard, reports, and other visual representations\n optimize and improve existing data systems for performance optimization and scalability.\n ensure data quality and integrity through rigorous testing and validation.\n implement tools for monitoring and documenting pipelines.\n monitor and troubleshoot data pipeline issues to ensure timely resolution.\n be proficient in creating and optimizing snowflake schema design for performance and scalability.\n utilize snowflake features such as data sharing, cloning and time travel.\n analyze and optimize snowflake compute resources (e.g. virtual warehouses).\n optimize queries, indexes and storage for improved performance.\n implement and maintain data security, data privacy best practices and ensure compliance with regulations. knowledge with soc compliance standards is nice to have.\n integrate snowflake with ms azure services\n monitor ms azure cloud to drive good performance\n effectively manage delivery and suppliers\n effectively document and communicate technical solutions to diverse audiences.\n demonstrate a strong ability to work independently, take ownership of tasks and drive them to completion.\n stay up to date with the latest industry trends and technologies in data engineering.\n\n\n\n\nqualifications:\n\n\n\n\n education : bachelors degree in computer science, big data, engineering, or a related field.\n demonstrated experience in data analysis , data engineering and successful project management .\n excellent problem-solving skills and attention to detail.\n strong communication and collaboration skills (with stakeholders at all levels, both locally and globally)\n experience with agile methodologies and modern software development lifecycle.\n a solid understanding of data science concepts is required\n solid understanding of relational databases and database concepts\n snowflake certification (preferred).\n ms azure certification (preferred).\n expertise with python, r, sql and/or java for snowflake-related automation (preferred).\n advanced skills in ms azure cloud engineering\n data analysis expertise\n experience with etl tools and building data ingestion pipelines.\n knowledge of bi tools; ms power bi, embedded (preferred)\n experience with big data technologies\n extensive experience with ml frameworks and libraries\n experience designing and implementing a full-scale data warehouse solution based on snowflake.\n experience in developing production-ready data ingestion and processing pipelines using java, spark, scala, or python.\n expertise and excellent proficiency with snowflake internals and integration of snowflake with other technologies for data processing and reporting.\n experience architecting large-scale data solutions, performing architectural assessments, examining architectural alternatives, and choosing the best solution in collaboration with both it and business stakeholders.\n\n\n\n\nat stellantis, we assess candidates based on qualifications, merit and business needs.\nwe welcome applications from people of all gender identities, age, ethnicity, nationality, religion, sexual orientation and disability. diverse teams, will allow us to better meet the evolving needs of our customers and care for our future.\n\n\nwe celebrate diversity and are committed to creating an inclusive environment for all our employees. we aim to encourage a culture where people can be themselves and be valued for their contribution. we are committed to making reasonable adjustments to the recruitment process as required. please add any adjustment requests to your application.",
  "company_name": "stellantis middle east & africa",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 2,
  "experience_years": null,
  "seniority": "mid",
  "hard_skills": [
    "snowflake",
    "sql",
    "azure",
    "python",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-s%C3%A9nior-gcp-at-alten-4187190784",
  "titre": "data engineer senior gcp",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-23",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "alten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2027.  alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\n\nrejoindre alten maroc cest beneficier :\n\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers.\n des formations certifiantes et diplomantes.\n des evenements reguliers pour combiner bien etre et performance.\n\n\ndescription du poste\n\nintegre(e) dans les equipes supply,  le/la consultant(e) aura pour mission de :\n\n\n concevoir, developper et maintenir des solutions de traitement de donnees massives en utilisant les technologies big data et les outils gcp.\n mettre en place et optimiser les pipelines de donnees, de lanalyse des performances et de lamelioration continue des solutions existantes\n\n\nqualifications\n\ndiplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique, ou justifiant d'une experience significative equivalente\n\n\nexperience : de plus de 7 ans en gcp\n\n\nune experience dans le secteur du commerce de detail ou de la grande distribution serait un plus.\n\n\ncompetences techniques :\n\n\n maitriser les technologies cloud de google cloud platform (gcp) pour la gestion des donnees, lorchestration et le deploiement des solutions big data.\n avoir une expertise approfondie de bigquery et bigtable pour le stockage, la manipulation et lanalyse de donnees a grande echelle.\n maitriser les langages de programmation scala ou java pour le developpement de solutions big data, avec une experience significative dans lun des deux.\n avoir une experience pratique avec lecosysteme hadoop et ses outils associes comme spark et apache kafka pour le traitement distribue de donnees.\n etre capable de concevoir et dimplementer des pipelines de donnees complexes en utilisant des outils comme apache kafka et avro pour la gestion des flux de donnees.\n maitriser les concepts de base de kafka pour la conception et la mise en uvre de systemes de messagerie distribues.\n avoir une bonne comprehension des bases de donnees nosql, notamment cassandra et bigtable, pour le stockage et la recuperation de donnees non structurees.\n avoir une experience avec les moteurs de recherche comme elastic search pour la recherche et lanalyse de donnees textuelles.\n maitriser les outils de ci/cd et les pratiques de developpement logiciel pour lautomatisation du deploiement et de lintegration continue.\n avoir une experience pratique avec les outils de deploiement et dorchestration comme jenkins, gitlab, kubernetes, docker et ansible.\n etre capable de travailler avec docker pour la creation et la gestion des conteneurs dapplications.\ncompetences linguistiques :\n\n\n avoir une excellente communication ecrite et orale, avec la capacite de produire des livrables et des reportings de haute qualite.\nsoft skills :\n\n\n avoir un esprit danalyse et damelioration continue, avec la capacite devaluer le code et ses impacts, ainsi que de remettre en question les solutions existantes pour les ameliorer.\n avoir la capacite de prendre du recul et devaluer les problematiques avec objectivite, en proposant des solutions damelioration.\n avoir un esprit dequipe et la capacite de collaborer efficacement avec les membres de lequipe pour atteindre des objectifs communs.\n maitriser les concepts dagilite (scrum, sprint planning, backlog...).\n\n\ninformations supplementaires\n\nau plaisir de vous lire !",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "gcp",
    "bigquery",
    "bigtable",
    "scala",
    "java",
    "hadoop",
    "spark",
    "apache kafka",
    "cassandra"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "retail"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/big-data-engineer-at-leyton-cognitx-4210460624",
  "titre": "big data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "leyton cognitx is the ai & tech advisory of leyton, bringing together a dynamic team of over 200 tech experts and data scientists. we specialize in delivering innovative ai and technology solutions that transform how organizations operate and compete.\n\n\nour approach combines strategic advisory services with custom development, enabling businesses to harness the power of ai and advanced technologies. we work closely with each client to design intelligent, streamlined solutions that address their specific challenges and align with their strategic objectives.\n\n\nat leyton cognitx, we believe that technology is more than just toolsit's a catalyst for meaningful organizational and technological transformation. our mission is to empower companies to leverage ai and cutting-edge tech, turning complex challenges into opportunities for growth, efficiency, and innovation.\n\n\nwho we're looking for :\n\n\nwe need a data engineer who thrives at the intersection of backend development and data engineering. if you have strong python skills, fluency in sql / data modeling, and experience working with big data technologies, you're exactly who we need !\n\n\nrequired skills & experience :\n python expertise - strong experience in backend development and data transformation using pandas, flask, fastapi or django.\n sql & data modeling - solid understanding of relational database design and optimization.\n web scraping & automation - experience using selenium or beautifulsoup for data extraction from websites.\n big data processing - hands-on experience with pyspark and familiarity with the hadoop ecosystem.\n communication - professional profeciency in french & english.\n bonus skills - knowledge of docker and ci/cd workflows is a plus.\n experience - 1 to 3 years as a software engineer or in a similar position (with a strong focus in backend development).\n education - master's degree in software development or a related field.\n\n\nwhat we offer:\n- competitive salary with flexible working hours.\n- work-life balance and numerous social benefits.\n- a start-up spirit within a fast-growing multinational group.\n- career growth and project diversification.\n- a continuous learning environment with team-building activities and knowledge sharing.\n- health and wellness perks via corporate partnerships.\n\n\njoin us to leverage your big data expertise and contribute to innovative projects in a dynamic and supportive environment!",
  "company_name": "leyton cognitx",
  "is_data_profile": true,
  "profile": "big data engineer",
  "education_level": 3,
  "experience_years": 1,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "sql",
    "pyspark"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/marketing-et-data-entry-at-confidentiel-4172655156",
  "titre": "marketing et data entry",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-07",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "pour le compte de l'un de nos partenaires, une multinationale dans le domaine de la transformation digitale , nous sommes a la recherche d'un(e) marketing & data entry specialist qui aura pour role principale la coordination de la recherche sur la generation de la demande.\n\n\n\n\nle coordonnateur de la recherche sur la generation de la demande fera partie d'une equipe dynamique et innovante qui dirigera les initiatives de marketing numerique de gurus solutions. ce role combine la creativite, la gestion des donnees et la reflexion strategique pour aider a identifier les prospects marketing pour les campagnes cibles. le candidat retenu collaborera avec des equipes interfonctionnelles, en s'appuyant sur des outils tels que hubspot et linkedin sales navigator pour soutenir la generation de prospects et les taches de reporting.\n\n\nquelle est la journee habituelle de notre coordonnatrice de la recherche sur la generation de la demande ?\n\n\n identification du compte cible : a l'aide de linkedin sales navigator, de zoominfo, d'indeed et d'autres sources de donnees accessibles au public, identifiez les comptes cibles cles de l'offre gurus.\n identification des prospects : utilisez linkedin sales navigator pour rechercher et identifier des prospects potentiels en fonction de filtres tels que le secteur d'activite, la taille de l'entreprise, l'intitule du poste, l'emplacement, etc.\n recherche de prospects : recherchez des informations cles sur les prospects, y compris les coordonnees dans zoominfo, et remplissez notre crm hubspot, ce qui permet a notre equipe bdr et marketing d'atteindre efficacement les prospects les plus prometteurs\n collaboration avec les equipes interfonctionnelles : travaillez en etroite collaboration avec le directeur marketing, les ventes et d'autres departements pour aligner les efforts et assurer un flux fluide d'informations et de processus entre les equipes.\n gestion continue des listes : mettez a jour et gerez regulierement les listes de prospects dans sales navigator, ainsi que dans hubspot, en veillant a ce qu'elles restent exactes et pertinentes au fur et a mesure de l'evolution de votre public cible.\n enrichissez les informations sur les prospects : preparez des rapports d'engagement a partir de hubspot et enrichissez les informations sur les prospects les plus prometteurs, ce qui permet a notre bdr d'avoir une conversation efficace et significative avec eux.\n suivi des prospects : effectuez un premier suivi par email et linkedin aupres des prospects les plus prometteurs identifies sur le rapport d'engagement hebdomadaire.\n\n\ncoordonnatrice de la recherche sur la generation de la demande\n 1 a 2 ans d'experience dans un poste similaire\n maitrise du francais (ecrit) et de l'anglais (ecrit) et aisance a parler au moins l'un d'entre eux.\n familier avec les feuilles de calcul (excel, google sheet), y compris une comprehension des fonctions plus avancees comme recherchev.\n envie d'apprendre et de s'adapter aux nouveaux outils numeriques. une experience avec hubspot, netsuite, linked salesnavigator, zoominfo est un atout.\n tres organise et capable de gerer plusieurs projets tout en respectant des delais serres.\n familiarite avec les outils de generation de prospects sociaux et les techniques de segmentation d'audience.",
  "company_name": "confidentiel",
  "is_data_profile": true,
  "profile": "unspecified",
  "education_level": null,
  "experience_years": 1,
  "seniority": "junior",
  "hard_skills": [
    "excel",
    "linkedin sales navigator",
    "hubspot"
  ],
  "soft_skills": [
    "communication",
    "organization",
    "adaptability"
  ],
  "sector": [
    "digital transformation"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cbs-postdoctoral-position-artificial-intelligence-applied-to-multi-omics-data-integration-at-um6p-university-mohammed-vi-polytechnic-4227853573",
  "titre": "cbs - postdoctoral position: artificial intelligence applied to multi-omics data integration",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-11",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position overview\n\nwe are seeking an outstanding postdoctoral researcher in artificial intelligence (ai) and data science with expertise in multi-omics data integration for health and precision medicine. the successful candidate will join a multidisciplinary team developing ai-driven approaches to integrate and analyze genomics, transcriptomics, proteomics, metabolomics, and microbiome datasets to uncover biomarkers, therapeutic targets, and mechanistic insights into complex diseases.\n\nthe project addresses critical challenges in personalized medicine, disease stratification, and multi-modal data fusion, enabling next-generation solutions in precision health and biomedical research.\n\nscientific challenges addressed in the position\n\n heterogeneity and high dimensionality of multi-omics data requiring advanced ai/ml methods for robust analysis and integration.\n data sparsity, batch effects, and missing values across different omics layers and platforms.\n cross-omics data fusion and representation learning for comprehensive systems biology modeling.\n identification of causal relationships and biomarker discovery through integrative approaches.\n time-series and longitudinal multi-omics data analysis for disease progression modeling.\n explainability and interpretability of ai models to support clinical decision-making and regulatory compliance in healthcare settings.\n scalability and computational efficiency in processing and integrating massive multi-omics datasets from clinical cohorts.\n\n\nkey responsibilities\n\n design and implement ai/ml pipelines for multi-omics data integration, including supervised and unsupervised learning methods.\n develop deep learning architectures (e.g., variational autoencoders, graph neural networks, transformers) for cross-omics data representation and feature extraction.\n apply multi-view learning, transfer learning, and data fusion techniques to integrate heterogeneous omics datasets and clinical metadata.\n conduct network-based analysis (gene regulatory networks, protein-protein interaction networks, metabolic networks) to identify key disease drivers and biomarkers.\n build predictive models for disease classification, patient stratification, and treatment response prediction.\n collaborate with biologists, clinicians, and bioinformaticians for data interpretation and validation of computational findings in clinical or experimental settings.\n disseminate research outcomes through publications in high-impact journals, conference presentations, and workshops.\n mentor and support the training of graduate students and early-career researchers in ai and multi-omics integration.\n\n\nrequired qualifications\n\n ph.d. in bioinformatics, computational biology, data science, artificial intelligence, or a related field.\n proven experience in multi-omics data integration, omics data analysis (genomics, transcriptomics, proteomics, metabolomics, microbiome).\n strong expertise in machine learning, deep learning, and advanced ai frameworks (tensorflow, pytorch, scikit-learn). experience with bioinformatics tools and databases (e.g., bioconductor, galaxy, kegg, reactome, string).\n proficiency in python, r, and unix/linux-based environments for high-performance data analysis. knowledge of biological network inference, causal modeling, and graph-based ai approaches.\n experience in multi-modal data fusion, representation learning, and heterogeneous data integration.\n strong publication record in relevant peer-reviewed journals.\n excellent communication skills and ability to work in a multidisciplinary environment.\n familiarity with cloud-based computing platforms (aws, azure, google cloud) and high-performance computing (hpc) environments.\n understanding of data privacy, security, and ethical considerations in handling clinical data.\n\n\napplication process\n\ninterested candidates should submit the following documents in a single pdf:\n\n a cover letter outlining their research interests, motivation, and relevant experience.\n a detailed curriculum vitae (cv) with a list of publications.\n contact details of two academic referees.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "research scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "r",
    "tensorflow",
    "pytorch",
    "scikit-learn"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "problem-solving"
  ],
  "sector": [
    "research",
    "healthcare"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-snowflake-mid-level-at-lumenalta-4223161845",
  "titre": "data engineer - snowflake - mid level",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-05",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "experience remote done right. with over 20 years of remote experience, our 500+ team members are 100% remote, and we continue to cultivate vibrant relationships and provide exceptional opportunities for career growth while working with stellar clients on ambitious projects.\n\n\nwhat we're working on:\nenterprise companies turn to us to help them launch innovative digital products that interact with hundreds of millions of customers, transactions, and data points. the challenges we solve daily are real and require creativity, grit, and determination. we are building a culture that challenges norms while fostering experimentation and personal growth. to grasp the scale of the problems we face, ideally, you have some exposure to logistics, fintech, transportation, insurance, media, or other complex multifactor industries.\n\n\nrequirements\n 3+ years experience in a senior developer role using python; ideally, you have delivered business-critical software to large enterprises\n you are comfortable manipulating large data sets and handling raw sql\n experience using technologies such as snowflake, aws, and etl pipelines is essential.\n have extensive experience with data warehousing and working with scalability of large volumes of structured data\n financial services industry experience preferred\n english fluency, verbal and written\n personality traits: professional, problem solver, proactive, passionate, team player.\n\n\nwhy lumenalta is an amazing place to work at\nat lumenalta, you can expect that you will:\n be 100% dedicated to one project at a time so that you can innovate and grow.\n be a part of a team of talented and friendly senior-level developers.\n work on projects that allow you to use leading tech.\n\n\nthe result? we produce meaningful outcomes for our clients that break barriers in their industries.\n\n\nthe job is 100% remote; please ensure you have a comfortable office set at your desired work location.\n\n\nlumenalta is committed to hiring exceptional talent from a wide variety of diverse backgrounds. if you share our values and enthusiasm for digital transformation, we encourage you to apply\n\n\nwhat's it like to work at lumenalta?",
  "company_name": "lumenalta",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": null,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "sql",
    "snowflake",
    "aws",
    "etl"
  ],
  "soft_skills": [
    "problem-solving",
    "teamwork",
    "proactive"
  ],
  "sector": [
    "fintech"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/developpeur-bi-sap-business-objects-data-services-at-brome-consulting-technology-4228456116",
  "titre": "developpeur bi (sap business objects & data services)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-12",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "dans le cadre de son developpement, notre client dans le secteur public renforce son pole data & analytics. nous recherchons un developpeur business intelligence experimente en sap business objects & data services.\n\nvos principales missions\n\n developpement et integration de nouveaux flux, datamarts et rapports pour differents services (rh, finances, pilotage).\n amelioration et optimisation des interfaces existantes.\n support technique a lequipe data & analytics et accompagnement a la montee en competence.\n contribution aux projets lies a lopen data et au pilotage de la performance.\n\n\n votre profil\n\n formation bac+5 en informatique ou systeme d'information.\n experience minimum 10 ans\n certifie sap bo/ds\n maitrise de sap bo (webi, designer) et sap data services.\n capacite a travailler en equipe et a documenter vos developpements.",
  "company_name": "brome consulting & technology",
  "is_data_profile": true,
  "profile": "business intelligence analyst",
  "education_level": 3,
  "experience_years": 10,
  "seniority": "senior",
  "hard_skills": [
    "sap bo",
    "sap data services",
    "sql"
  ],
  "soft_skills": [
    "teamwork",
    "documentation",
    "communication"
  ],
  "sector": [
    "public sector"
  ],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-casablanca-at-vivadata-4184459258",
  "titre": "data analyst - casablanca",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-17",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "who we are\n\nartefact is a new generation of data service provider, specialised in data consulting and data-driven digital marketing.\n\nour purpose?\n\nevery day we boost our clients data transformation into business impact across the entire value chain of organisations.\n\nour strength?\n\nour data services stand on double expertise: the combination of artificial intelligence and the business prowess acquired from our customers around the world, such as accorhotels, orange, carrefour, engie, samsung, l'oreal, nissan...\n\nartefacts success comes from a unique mix of company assets: cutting-edge data technologies, agile methodologies for fast delivery, cohesive teams assembling the finest business consultants, data analysts, data scientists, data engineers, and digital marketing experts.\n\nartefact is\n\n 20 offices in paris, london, shanghai, dubai...\n +1300 employees\n 4 practices: data consulting, data marketing, activation and creation\n\n\nwhat you will be doing: key responsibilities\n\nas a senior data analyst, your role will encompass\n\n conducting projects to accompany the transformation of your clients businesses through the effective collection, processing, and visualisation of data\n extracting valuable insights from our clients marketing-related data sources.\n designing dashboards for marketing decision-making while taking into account the business needs\n accompanying our clients in the conception and implementation of data architectures and data pipelines, from collection to monitoring.\n actively contributing to the expertise level and competencies of the data & analytics team\n closely collaborate with the other divisions (media & activation, creation, consulting, data science and data engineer) to provide comprehensive services to your clients\n\n\nbeing a great tech role model\n\n demonstrating the skill and credibility required to ensure the success of our clients initiatives\n researching and developing new technical approaches to address problems efficiently\n staying up-to-date on developments within the industry, sharing best practices and actively contributing to artefacts institutional knowledge\n embodying artefacts values and inspiring others to do the same\n\n\nqualifications: education & experience required\n\n having an academic level of education (bachelor or master), in a data-driven working environment, you have experience or have knowledge in :\n a minimum of 3 year of work experience in a data-driven working environment\n 1 or more data collection (google analytics, adobe analytics, sql database, crm database, transactional data)\n 1 or 2 programming languages among sql, python and/or r.\n 1 or more data visualisation tool (tableau, data studio, dataviz, r / python dataviz libraries, ...)\n\nin addition, you have the knowledge in one or more of the following technologies:\n\n google cloud platform resources (big query, google cloud storage) or its equivalent in azure or aws\n you know how to connect to an api through the knowledge of the different authentication method (oauth, http basic, api key)\n advertising tool, linked to tracking and/or analytics in a marketing context (google analytics, adobe analytics, dmp, dsp, adservers, dv 360...) \n etl tool (airflow, dataiku, dataflow, dataprep...) \n web application (r-shiny, python flask) that you have industrialized\n\n\nideally you have\n\n knowledge of statistics \n knowledge of machine learning and data engineering\n\n\nwhat we are looking for\n\n a doer: you get things done and inspire your team to do the same\n an analyst: you love data and think every company should take their decisions based on facts\n a pragmatist: you have a no-nonsense mindset that seeks for practical and realistic solutions\n a mentor: your clients and colleagues naturally seek you out for advice\n an adventurer: youre an entrepreneur constantly looking for business opportunities\n\n\nwhy you should join us\n\n artefact is the place to be: come and build the future of marketing\n progress: every day offers new challenges and new opportunities to learn\n culture: join the best team you could ever imagine\n entrepreneurship: you will be joining a team of driven entrepreneurs. we wont give up until we make a huge dent in this industry!\n\n\ncome join us!\n\napply now\n\napply for this jobapply for this job\n\nshare this offer\n\nsimilar jobs\n\nconsulting\n\nview more\n\ndata engineering\n\nview more\n\ndata science\n\nview more\n\nteamwork makes the dream works.\n\nartefacts teams are made up of the best experts in their fields, and its our biggest responsibility to ensure their professional development and personal wellbeing.\n\nlearn more",
  "company_name": "vivadata",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "sql",
    "python",
    "tableau"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "consulting",
    "marketing"
  ],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-engineer-freelance-at-proorga-consulting-4175223876",
  "titre": "senior data engineer (freelance)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-05",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "notre client, un acteur majeur du secteur de la distribution, recherche un senior data engineer pour renforcer ses equipes data & it. ce role cle vise a assurer la collecte, le traitement et le stockage des donnees de maniere optimale, tout en garantissant la fiabilite et la performance des pipelines de donnees.\n\n\n missions principales\n-concevoir et developper des pipelines de donnees (elt) pour optimiser lextraction, la transformation et le chargement des donnees.\n-mettre en place et gerer des bases de donnees et entrepots de donnees.\n-implementer des architectures et des modeles de stockage performants.\n-automatiser les processus pour ameliorer lefficacite et la productivite.\n-optimiser les performances des pipelines et garantir un traitement efficace des donnees.\n-assurer la securite et la protection des donnees sensibles.\n-collaborer avec les equipes metiers, data scientists, data analysts et developpeurs pour repondre aux besoins des utilisateurs.\n-maintenir, monitorer et documenter les pipelines de donnees developpes.\n-assurer une veille technologique pour integrer les meilleures pratiques du data engineering.\n\n\n competences techniques requises\n-experience : minimum 5 ans dans un role similaire, idealement en environnement azure.\n-langages : maitrise de python et sql.\n-big data : bonne connaissance des outils et frameworks comme hadoop, spark, kafka.\n-pipelines elt : conception et developpement avances.\n-bases de donnees : expertise en bases relationnelles et nosql.\n-performance & securite : optimisation des performances et mise en place de solutions securisees.\n-certifications azure (souhaitees).\n\n\n profil recherche\n-formation : bac+5 en ecole dingenieur, specialisation data.\n-langues : bonne maitrise du francais, anglais et arabe.\n\n\n soft skills\n-capacite danalyse et de resolution de problemes.\n-bonnes competences en communication et collaboration.\n-orientation resultats et gestion efficace du temps.\n-capacite a sadapter aux nouvelles technologies et aux changements.\n-proactivite et volonte dapprentissage continu.\n\n\nvous souhaitez evoluer dans un environnement dynamique et innovant, ou la gestion et loptimisation des donnees sont au cur de la strategie ? rejoignez un leader du secteur de la distribution et participez a des projets a forte valeur ajoutee !",
  "company_name": "proorga consulting",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "hadoop"
  ],
  "soft_skills": [
    "problem-solving",
    "communication",
    "teamwork"
  ],
  "sector": [
    "distribution"
  ],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-anglophone-at-alten-4205940474",
  "titre": "data analyst anglophone",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\nalten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2024. avec plus de 90 recrutements par mois, alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\nrejoindre alten maroc cest beneficier :\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers. \n des formations certifiantes et diplomantes. \n des evenements reguliers pour combiner bien etre et performance\n\n\ndescription du poste\n\nen tant que data analyst, vous serez amene a :\n\ngerer le processus de deploiement:\n\n developpement des kpis. \n analyse et difitalisation des processus de deploiement de diverses technologies. \n collection et organisation de donnees issues de differentes sources. \n developpement de rapports power bi. \n collaboration avec les departements fonctionnels et les equipes techniques.\n\n\nqualifications\n\n bac+5 en data. \n ayant 1 a 3ans d'experiencedans un poste similaire.\n\n\ncompetences requises:\n\ntechnique:\n\n power bi\n gcp\n sql\n dax\n\n\nlangues :\n\n allemand b2\n anglais courant, assurant lautonomie dans les echanges professionnels et la redaction de documentation technique.\n\n\nsoft skills:\n\n capacite danalyse : aptitude a comprendre des problematiques complexes et a concevoir des solutions adaptees. \n esprit de synthese et redactionnel : clarte dans la presentation des resultats et des recommandations. \n capacite de collaboration : faculte a travailler efficacement avec des equipes interdisciplinaires. \n force de proposition : initiative et creativite dans lidentification d'opportunites d'amelioration et de solutions innovantes. \n reactivite : capacite a gerer les priorites et a sadapter rapidement aux besoins.",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "power bi",
    "gcp",
    "sql"
  ],
  "soft_skills": [
    "problem-solving",
    "communication",
    "teamwork"
  ],
  "sector": [
    "automotive",
    "rail",
    "it",
    "telecoms"
  ],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/implementation-data-analyst-at-teladoc-health-4221379493",
  "titre": "implementation data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-02",
  "location": {
    "city": "arg",
    "region": "draa-tafilalet",
    "country": null,
    "remote": false
  },
  "description": "teladoc health is a global, whole person care company made up of a diverse community of people dedicated to transforming the healthcare experience. as an employee, youre empowered to show up every day as your most authentic self and be a part of something bigger  thriving both personally and professionally. together, lets empower people everywhere to live their healthiest lives.\n\nsummary of position\n\nunder the direction of the technical manager, the implementation data analyst will collaborate with various team members to configure key accounts. the main responsibility of this role is to ensure accurate configuration of new account set-up. work will be measured by achievement of business objectives and progress towards strategic goals leading to improved productivity or profitability.\n\nthe implementation data analyst exemplifies values and inspires commitment to the company vision and mission, setting the example of leadership for the organization. as key core value, this role acts with integrity while influencing others through involvement in processes and decision making.\n\nessential duties and responsibilities\n\n provision new accounts by collecting necessary information then configure the platform.\n required to maintain an accuracy rating of 95%.\n responsible for successfully coordinating internal and external deliverables related to the deployment and implementation of teladoc health products to its customers.\n maintaining clear and on-going communication with all internal and external stakeholders, identifying and prioritizing issues and needs, tracking action items, and ensuring the timely delivery of configuration to exceed expectations.\n implement and coordinate data management goals and objectives for the purpose of providing for the efficient and effective functioning of system policies and procedures.\n ensure individual and team unit deliverable targets are achieved.\n this position will not access protected health information (phi) or personally identifiable information (pii)\n\n\nqualifications expected\n\n 2-4 years working experience in a data analyst role.\n detail-oriented and comfortable in a rapidly changing environment.\n problem solver with the ability to clearly articulate findings and resolution.\n ability to act independently on assignment and understands appropriate escalation protocol.\n ability to meet deadlines by recognizing best use of time and working with end results very clearly in mind.\n\n\nqualifications preferred\n\n prior experience with data entry and analysis preferred.\n previous implementation and/or support experience a plus.\n able to work cooperatively in a team environment.\n\n\nwhy join teladoc health?\n\na new category in healthcare:  teladoc health is transforming the healthcare experience and empowering people everywhere to live healthier lives.\n\nour work truly matters: recognized as the world leader in whole-person virtual care, teladoc health uses proprietary health signals and personalized interactions to drive better health outcomes across the full continuum of care, at every stage in a persons health journey.\n\nmake an impact: in more than 175 countries and ranked best in klas for virtual care platforms in 2020, teladoc health leverages more than a decade of expertise and data-driven insights to meet the growing virtual care needs of consumers and healthcare professionals.\n\nfocus on people:  teladoc health has been recognized as a top employer by numerous media and professional organizations. talented, passionate individuals make the difference, in this fast-moving, collaborative, and inspiring environment.\n\ndiversity and inclusion:  at teladoc health we believe that personal and professional diversity is the key to innovation. we hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.\n\ngrowth and innovation:  weve already made healthcare yet remain on the threshold of very big things. come grow with us and support our mission to make a tangible difference in the lives of our members.\n\nas an equal opportunity employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy.",
  "company_name": "teladoc health",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 2,
  "experience_years": 4,
  "seniority": "mid",
  "hard_skills": [
    "data analysis",
    "data entry",
    "communication"
  ],
  "soft_skills": [
    "problem-solving",
    "communication",
    "teamwork"
  ],
  "sector": [
    "healthcare"
  ],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/dba-senior-data-base-administrator-h-f-at-gentis-4223495766",
  "titre": "dba senior - data base administrator h/f",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-05",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": true
  },
  "description": "une multinationale, en pleine croissance et specialisee dans la gestion de donnees et de solutions d'externalisation/delocalisation, situee dans l'axe rabat et casablanca, est a la recherche de son nouvel administrateur de base de donnees a rabat.\n\n\nmission :\nconcoit, gere et administre les systemes de gestion de bases de donnees, il garantit la coherence, la qualite, la securite et laccessibilite permanente des informations.\n\n\nles taches :\n\n\n gestion des changes (nssr - non standard, normal) et probleme (recurrent et/ou avec impact majeur) / capacite / config (rtpa/maj esl ou autre knowledge base)\n participation aux projets (clients et interne)\n assister a des reunions operationnelles internes et externes pour le suivi des cab/tab/ngdm\n proposer des solutions techniques innovantes ou plus adaptees a lenvironnement clients\n assurer lactivite et accompagner les profils juniors / confirme et/ou middle senior\n participer a la preparation des reponses des cahiers de charges\n\n\nprofil : \n bac +3/5 (en informatique de preference).\n\n\nniveau dexperience professionnelle :\n3 a 7 ans d'experience en tant que dba.\n\n\ncompetences :\n must have : oracle ; sql server ; mysql ; ibm db2 ; rac ; dataguard\n nice to have : oracle tuning certification: - oca/ocp/mssql server certif/ mysql\n\n\ncompetences comportementales :\n- esprit dequipe ; esprit danalyse\n\n\nlangues :\n- francais ; anglais\n\n\ncette offre est faite pour toi :\n\n\n un salaire competitif\n un environnement de travail flexible (teletravail)\n une entreprise a taille humaine\n\n\ninteresse(e) ? organisons un meeting !\n\n\nn'hesite pas a me contacter sur :\nmehdi.a@gentis.com",
  "company_name": "gentis",
  "is_data_profile": true,
  "profile": "database administrator",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "oracle",
    "sql server",
    "mysql"
  ],
  "soft_skills": [
    "teamwork",
    "problem-solving",
    "communication"
  ],
  "sector": [
    "data management",
    "outsourcing"
  ],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/ingenieur-data-analyste-sur-risque-operationnel-at-societe-generale-4219003648",
  "titre": "ingenieur data analyste sur risque operationnel",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-28",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "vos missions au quotidien\n\nau sein de la filiale societe generale africa technologies & services (sg ats), le departement business, transformation & oversight (bto) pilote le developpement commercial des activites de marches (mark), conduit leur transformation et supervise leurs chaines operationnelles, leurs finances et leurs risques (financiers & non financiers)\n\nle pole bto est present a paris, londres, hongkong, new-york et casablanca.\n\nlequipe operational risk management (bto/orm) a pour role didentifier, mesurer et controler les risques non financiers de mark (risques operationnels et risques de conduite) et effectuer des controles de premier niveau (y compris des controles de supervision permanente) en tant que premiere ligne de defense.\n\nmissions\n\nvous serez base(e)s a casablanca, au sein de lequipe operational risk management. vous serez amene a travailler en etroite collaboration avec tous les acteurs de la banque dinvestissement a savoir, les traders, les vendeurs, les ingenieurs etc.\n\nen tant quoperational risk analyst, votre role consistera a :\n\n realiser des controles de premiere ligne de defense sur les risques non financiers, essentiellement reglementaires et operationnels\n reporting et analyse des resultats de controles\n participer aux projets reglementaires impactant le groupe ainsi que les audits internes & externes.\n challenger les controles afin de garantir la pertinence, la robustesse et lefficacite du dispositif en place pour securiser les activites de mark\n interagir, en bonne intelligence, avec les differentes fonctions de support ou de controle de la banque, en sassurant du bon alignement des priorites et dune cooperation fructueuse.\n\n\nla capacite a initier ou implementer des ameliorations de processus (controles, automatisation, simplification, homogeneisation et renforcement de la qualite), est un facteur cle de succes.\n\net si cetait vous ?\n\nvous etes titulaire dun bac+5 (ecole d'ingenieur / ecole de commerce / master en ingenierie financiere), avec une experience minimum de 2 ans dans l'environnement de la banque d'investissement (trading, produits financiers, etc...).\n\nla maitrise de francais et danglais sont un prerequis pour le poste.\n\nune connaissance/pratique des langages de scripting vba (macros) / python serait un plus.\n\ncuriosite, rigueur, capacite d'adaptation a un environnement en evolution constante, une bonne communication, une faculte a anticiper les risques et une forte proactivite, sont des qualites necessaires a la reussite dans ce poste.\n\npourquoi nous choisir ?\n\ncreee en 2014, sg ats est une filiale du groupe societe generale qui fournit des solutions agiles et efficaces aux salles des marches sg en europe (principalement a paris et londres) afin de les aider a se developper et a repondre aux exigences de plus en plus fortes imposees par les differentes legislations bancaires internationales.\n\nforte de son succes, sg ats fournit aujourd'hui des prestations a forte valeur ajoutee a differentes lignes de metiers du groupe (en europe principalement mais egalement aux etats-unis et en asie) sur des activites de marches, mais egalement a plusieurs directions du groupe societe generale.\n\nsacree  meilleur employeur 2023  maroc  sg ats est une structure jeune, dynamique qui positionne le capital humain au centre de son developpement. sg ats souhaite donc sentourer de talents qui participeront activement a la reussite de lentreprise tout en evoluant dans un environnement international propice au developpement de competences a forte valeur ajoutee. vous serez base a casablanca au sein de la filiale sg africa technologies & services (sgt ats).\n\n les informations recueillies sur ce site font lobjet dun traitement destine a repondre aux besoins de recrutement de la societe sg ats. ces donnees sont traitees par les services internes de la societe. conformement a la loi n 09-08 promulguee par le dahir 1-09-15 du 18 fevrier 2009, relative a la protection des personnes physiques a legard du traitement des donnees a caractere personnel, vous beneficiez dun droit dacces et de rectification aux informations qui vous concernent, que vous pouvez exercer en vous adressant a donnees-personnelles.sgats@sgcib.com .vous pouvez egalement, pour des motifs legitimes, vous opposer a ce que les donnees qui vous concernent fassent lobjet dun traitement. ces donnees peuvent faire lobjet dun transfert a letranger. ces traitements ont ete notifies et autorises par la cndp sous les numeros a-rh-354/2016 et t-rh-129/2016.\n\ndiversite et inclusion\n\nnous sommes un employeur garantissant l'egalite des chances et nous sommes fiers de faire de la diversite une force pour notre entreprise. le groupe sengage a reconnaitre et a promouvoir tous les talents, quels que soient leurs croyances, age, handicap, origine ethnique, nationalite, appartenance a une organisation politique, religieuse, syndicale ou a une minorite, ou toute autre caracteristique qui pourrait faire lobjet dune discrimination.",
  "company_name": "societe generale",
  "is_data_profile": true,
  "profile": "risk analyst",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "vba",
    "python",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "proactivity"
  ],
  "sector": [
    "investment banking"
  ],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consulting-data-manager-at-vivadata-4189982855",
  "titre": "consulting data manager",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-27",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "qui sommes-nous?\n\nartefact est une nouvelle generation de cabinet de conseil specialisee en data dont plus de 1200 collaborateurs repartis sur 19 pays ont pour mission daccompagner la transformation chez nos clients.\n\nnous offrons une large gamme de solutions data-driven, que nous adaptons aux besoins specifiques de nos clients, que ce soit des projets ia pour l'automatisation des process internes a chaque etape de leur chaine de valeur, la creation d'experiences consommateurs innovantes et personnalisees, le conseil en strategie data et marketing digital jusqu'a la gestion du mix-media et plus encore !\n\nla performance de nos services data repose sur une reelle expertise technologique en intelligence artificielle et des competences metiers acquises aupres de plus de 1000 clients dans le monde, tels que accorhotels, orange, carrefour, engie, emirates, deutsche telekom, monoprix...\n\nla force d'artefact repose sur un mix unique d'atouts: une connaissance des technologies de pointe en data, des methodes agiles permettant de delivrer tres rapidement les projets et des equipes composees des meilleurs experts dans leurs domaines (business consultants, data analysts, data scientists, ingenieurs data...).\n\npour accompagner cette croissance, notre departement conseil recherche un(e) manager data consultant.\n\nresponsabilites principales\n\ndelivery et management de projets\n\n piloter et faire grandir des equipes pluridisciplinaires (consultants, data scientists, data/software engineers, data analysts) en :\n organisant des projets en sous chantier (avec pour chacun des objectifs, livrables clairs, des deadlines,....).\n definissant les roles et responsabilites au sein de l'equipe.\n fixant des objectifs aux membres de l'equipe.\n etant garant de la qualite des livrables et de la satisfaction client.\n\nimpact business\n\n comprendre les besoins de nos clients et leur apporter des solutions data adaptees.\n renforcer nos relations avec les clients actuels, identifier les opportunites commerciales et proposer des solutions pertinentes. \n accompagner louverture de nouveaux territoires commerciaux pour artefact.\n avoir une bonne capacite dadaptation a l'environnement de travail en passant facilement dun contexte a un autre (industrie, client, entites metiers au sein d'un meme client, ...)\n\n\nimpact interne\n\n devenir referent sur une ou plusieurs expertises et les developper (strategie, data gouvernance, data marketing,... ) : construction de nouvelles offres, formation des consultants, actions marketing, developpement de partenariats, pitchs clients.... \n participer a des evenements externes et a la creation de contenu marketing faisant la promotion dartefact.\n developper / enrichir l'offre d'artefact afin de repondre aux besoins de nos clients. \n le consulting manager agit egalement en tant que leader des operations, prenant la tete de sujets strategiques tels que les rh, les entretiens de recrutement, l'innovation, le management agile ou l'industrialisation.\n\n\nprofil\n\n vous disposez dune experience de 4 ans dans un cabinet de conseil.\n vous avez une experience en gestion du personnel et une capacite averee a developper de jeunes talents\n vous savez comment identifier les opportunites commerciales et vous aimez les interactions.\n vous etes curieux et passionne par les sujets lies a la data et a levolution technologique.\n vous avez un etat d'esprit analytique et aimez la resolution de problemes.\n vous faites preuve de rigueur et proactivite\n vous maitrisez : suite google/ pack office.. \n une excellente communication (ecrite / orale) en francais et en anglais est obligatoire.\n\n\npourquoi nous rejoindre\n\n un melange unique de talents (data consultants, data analyst, data scientist, data engineer), et une hyper croissance continue offrant de nombreuses opportunites de carrieres rapides. \n un endroit ideal pour apprendre : vous maitriserez les competences cles du monde de l'entreprise de demain : vous recevez des formations regulieres sur la technologie (offre artefact, technologies de la donnee,...), votre travail en equipes hybrides, vous apprenez les facons de travailler specifiques a la tech (product mindset, agilite...). a la fin de votre experience artefact, vous etes un leader technologique experimente.\n la culture : innovation, collaboration et action sont nos valeurs, pour faire simple, nous sommes des faiseurs qui travaillent ensemble afin de creer des solutions innovantes.\n\n\nchez artefact, nous recrutons nos collaborateurs uniquement en fonction de nos besoins et des qualites propres de chaque candidat. nous assurons le developpement de leurs competences professionnelles et de leurs responsabilites sans discrimination daucune sorte, notamment de croyances, de genre, dage, de situation d'handicap, dorigine ethnique, dorientation sexuelle, dappartenance a une organisation politique, religieuse, syndicale ou a une minorite.\n\napply now\n\napply for this jobapply for this job\n\nshare this offer\n\nsimilar jobs\n\ndata analytics\n\nview more\n\ndata engineering\n\nview more\n\ndata science\n\nview more\n\nteamwork makes the dream works.\n\nartefacts teams are made up of the best experts in their fields, and its our biggest responsibility to ensure their professional development and personal wellbeing.\n\nlearn more",
  "company_name": "vivadata",
  "is_data_profile": true,
  "profile": "data consultant",
  "education_level": 3,
  "experience_years": 4,
  "seniority": "mid",
  "hard_skills": [
    "sql",
    "data analysis",
    "project management"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "consulting"
  ],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-at-agoya-4224334461",
  "titre": "data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-06",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "about us\nlocal expertise supported by global talent!\nat agoya, we are a data and digital agency helping businesses innovate and grow. our expertise covers talent solutions, product development, and advisory services, empowering clients with the right people, tools, and strategies to succeed.\nthrough long-term partnerships and our global hubs (e.g., agoya morocco & greece), we connect businesses with top-tier talent and deliver tailored solutions in data, cloud, and digital transformation. whether through expert consultants, custom digital products, or strategic guidance, we help organizations turn challenges into opportunities.\n\n\nthe opportunity\nwe are hiring a talented data engineer to join our team and contribute to transformative projects within the dynamic event management domain. you will play a critical role in developing scalable data solutions, optimizing data processes, and enhancing cloud-based systems to support innovative event technology platforms. this position offers a unique chance to create impactful solutions for this fast-evolving industry.\n\n\nyour responsibilities\n design, develop, and implement scalable solutions for the data platform while ensuring alignment with architectural best practices and client goals.\n gain a comprehensive understanding of event-related data structures to support efficient data management.\n develop and optimize data pipelines, ensuring seamless integration of data from diverse platforms commonly used in the events industry.\n collaborate with the head of data intelligence and event data analytics teams to align on project requirements and deliverables.\n effectively communicate updates, insights, and solutions to project stakeholders and cross-functional teams.\n identify opportunities for improving event data workflows and processes, proposing and implementing enhancements.\n ensure high-quality, reliable data engineering solutions tailored to the event management sector.\n provide mentorship and informal guidance to junior team members or new hires as needed.\n\n\nare you the one?\n education & experience: bachelor's or masters degree in computer science, engineering, or a related field; at least 3 years experience in data engineering.\n cloud expertise: hands-on experience with cloud platforms, particularly google cloud platform (gcp).\n technical skills: proficiency in sql, etl/elt processes, and data integration from event management systems.\n problem-solving: strong analytical skills with the ability to propose creative and effective solutions.\n team collaboration: excellent communication skills and a collaborative, team-oriented mindset.\n detail-oriented: keen attention to detail with a focus on high-quality data engineering outputs.\n language skills: fluent in english, with strong written and spoken proficiency+ french/dutch.\n\n\nour benefits\n work remotely from morocco or greece with a supportive team environment.\n autonomy to manage your work, with trust as a cornerstone.\n market-aligned compensation that recognizes your expertise.\n work with a multicultural team in the exciting event management sector.\n an interesting, challenging opportunity in a growing, dynamic company\n a job with much variation in terms of projects and technologies\n\n\nready to make an impact?\nif you're ready to take on exciting challenges and contribute to transformative data projects in the event management domain, we'd love to hear from you. apply now and join us in shaping the future of data-driven innovation at agoya!",
  "company_name": "agoya",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "sql",
    "gcp",
    "etl"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "event management"
  ],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-scientist-at-red-tic-4180457819",
  "titre": "data scientist",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-09",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "freelance\n casablanca\n publie il y a 4 mois\n\n\nred tic recrute pour lun de ses clients un profil data scientist.\n\nmission\n\n collecte de donnees : identifier et rassembler des donnees pertinentes a partir de diverses sources, quelles soient internes (bases de donnees de lentreprise) ou externes (api, web scraping, etc.).\n preparation et nettoyage des donnees: nettoyer et transformer les donnees pour les rendre exploitables. cela inclut le traitement des valeurs manquantes, la normalisation des formats, et lelimination des doublons.\n analyse exploratoire : analyser les donnees pour en degager des insights preliminaires. cela peut inclure des vistalisationg. des statistiques descriptives et la recherche de correlations.\n modelisation : developper des modeles statistiques ou de machine learning pour resoudre des problemes specifiques (prediction, classification, etc.). cela implique le choix des lalgorithme, lentrainement du modele et levaluation de ses performances.\n interpretation des resultats : interpreter les resultats des analyses et des modeles, en traduisant les donnees en recommandations concretes et en insights exploitables pour les decideurs.\n\n\nprofil recherche : scientist\n\n langages de programmation : python et r sont les plus couramment utilises pour lanalyse de donnees et le machine learning.\n outils de manipulation de donnees : pandas et numpy pour python, dplyr pour r.\n visualisation : matplotlib, seaborn, plotly pour python, ggplot2 pour r.\n bases de donnees : sql pour interroger des bases de donnees relationnelles, ainsi que nosql comme cassandra.\n environnements de developpement : jupyter notebook, rstudio et ide comme pycharm.\n machine learning : scikit-learn, tensorflow, keras et pytorch pour developper des modeles.\n big data : hadoop, spark pour traiter de grandes quantites de donnees.\n outils de versionnage : git pour gerer le code.\n outils de deploiement: docker, kubernetes pour la mise en production des modeles.\n\n\nrecruitment consulting management training sourcing job jobs offer internship morocco africa java developpement developpement developpeur developpeur informatique application it jee android consultant devops fullstack. dabord. tout dabord. en premier lieu. ensuite, de plus. finalement. en outre. par ailleurs. en dernier lieu. enfin. dabord, en premier lieu, pour commencer, premierement, en conclusions ur conclure, enfn, finalement, en dernier lieu, bien que. il y a aussi il est vrai que... mais. tout en reconnaissant que... on peut supposer que. par exemple . en fait . prenons le cas de. considerons, par exemple. lexemple le plus r. cependant. mais. pourtant. toutefois. neanmoins. contraste. alors que. tandis que. par contre. en revanche scientist\n\nnom et prenom\n\nadresse email\n\nmobile\n\nniveau d etude\n\nbac bac +1 bac +2 bac +3 bac +4 bac +5 bac + x\n\nannees dexperience\n\n0 +1 +2 +3 +4 +5 +6 +7 +8 +9 + 10\n\npreavis\n\ndisponible immediatement -1 mois 1 mois 2 mois +2 mois\n\nmessage\n\nupload cv\n\nteleverser votre cv ou tout autre document relatif. taille max: 2 mb.",
  "company_name": "red tic",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": null,
  "experience_years": null,
  "seniority": "none",
  "hard_skills": [
    "python",
    "r",
    "sql"
  ],
  "soft_skills": [],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-scientist-at-aiqu-4212629012",
  "titre": "data scientist",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "we are hiring data scientist to join one of our clients.\n\n\nemployment type - 6 months & extendable contract\njob location - morocco\n\n\nrequired skills:\n 3-5+ years of experience\n predictive modeling\n machine learning\n clustering analysis\n statistical modeling\n sentiment analysis\n computer vision (ocr)\n natural language processing\n large language models (llm) e.g. openai\n ai-powered forecasting\n programming languages =python, r, sql, c/c++, javascript, bash, dax, vba",
  "company_name": "aiqu",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "r",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-manager-data-analyst-editeur-de-logiciels-specialise-dans-lenergie-at-inautalent-4192212114",
  "titre": "data manager / data analyst - editeur de logiciels specialise dans lenergie",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-27",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "nous recherchons pour notre client, une societe francaise specialisee dans le secteur de l'energie, en pleine expansion au maroc, un data manager / data analyste. ce poste est base a rabat et fait partie de l'equipe locale qui connait une croissance importante. l'equipe au maroc travaillera en etroite collaboration avec les equipes basees en france pour soutenir le developpement des solutions logicielles d'analyse de la consommation et de la depense d'energie.\n\nle candidat ideal aura une solide experience dans la gestion et l'analyse des donnees, notamment dans le secteur de l'energie, et une bonne maitrise des outils de business intelligence.\n\nresponsabilites :\n\n recuperer et integrer les donnees de consommation et de facturation des fournisseurs d'energie et des gestionnaires de reseaux en france et en europe. \n transformer les donnees via un processus etl (extract, transform, load). \n assurer le controle de la qualite des donnees et leur validation. \n assister le responsable du back-office ainsi que l'equipe de consultants dans l'exploitation des donnees energetiques. \n creer des rapports et des analyses bases sur des bases de donnees sql, influxdb ou des outils decisionnels (microsoft analysis services).\n\n\n\nrequirements\n\n maitrise des outils business intelligence (bi) tels que azure power bi, microsoft ssis, microsoft ssas. \n connaissances des outils devops : git, azure devops. \n connaissances de base en c#. \n solides competences en analyse de donnees et en gestion de donnees dans le secteur de l'energie. \n autonomie, rigueur et capacite a travailler en equipe. \n formation : bac+5 en base de donnees, analyse de donnees, ou domaine equivalent. \n experience : minimum 2 ans d'experience dans un poste similaire ou dans la gestion de donnees pour le secteur de l'energie.\n\n\n\nbenefits\n\nce poste represente une excellente opportunite pour un candidat desireux de travailler dans une entreprise en pleine expansion, avec des projets a fort impact et une forte collaboration internationale.",
  "company_name": "inautalent",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "power bi",
    "ssis"
  ],
  "soft_skills": [
    "teamwork",
    "communication",
    "problem-solving"
  ],
  "sector": [
    "energy",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/chef-de-projet-data-senior-at-intelcia-it-solutions-4187258124",
  "titre": "chef de projet data senior",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-17",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "nous recherchons un chef de projet data senior ayant une forte experience en gestion de et pilotage de projets pour la mise en place de grandes plateformes data pour notre client.\nvous devez posseder une expertise technique et fonctionnelle dans la gestion de projets data, afin dassurer lexecution des projets dans le respect des delais, budgets et exigences client.\nvous serez responsable de la coordination des equipes et de la gestion de projets impliquant des technologies comme starbust ou equivalents (bigquery ...) et dataiku dss avec un focus sur la mise en uvre de solutions efficaces et innovantes pour lorganisation.\n\n\nmissions principales\n piloter des projets de build complexes, dans un environnement de transformation numerique incluant lintegration.\n gestion des ressources : encadrer une equipe technique multidisciplinaire (architectes, data scientistes, analystes etc..)\n communication efficace : savoir traduire les besoins business en exigences techniques, assurer une communication reguliere et efficace avec les parties prenantes,\n gestion des parties prenantes interface entre les equipes metiers et techniques en assurant une bonne comprehension des enjeux et des objectifs.\n suivi de la qualite et des performances : qualite de la plateforme data a deployer, des livrables a chaque phase du projet en mettant en place les indicateurs de performance pertinents.\n suivi de lavancement et des budgets.\n\n\nprofil recherche\n formation : bac + 5 (master ou ecole dingenieur) en systeme dinformation\n experience ; minimum 5ans dexperience en gestion de projets data complexes (dataiku dss, starbust ou bigquery)\n competences averees en gestion de projet, avec une approche agile et lean.\n leadership et capacite a encadrer une equipe multidisciplinaire.\n bonne maitrise des outils de gestion de projet (jira, confluence.).\n competences interpersonnelles : excellentes capacites de communication et de negociation, sens de lecoute et aptitude a resoudre les conflits\n competences linguistiques : francais et anglais.",
  "company_name": "intelcia it solutions",
  "is_data_profile": true,
  "profile": "data strategist",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "dataiku dss",
    "starbust",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "leadership"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-anglophone-at-alten-maroc-4190599628",
  "titre": "data analyst anglophone",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-27",
  "location": {
    "city": "rabat metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "alten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2024. avec plus de 90 recrutements par mois, alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\nrejoindre alten maroc cest beneficier :\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers.\n des formations certifiantes et diplomantes.\n des evenements reguliers pour combiner bien etre et performance\n\n\ndescription du poste :\n\n\nen tant que data analyst, vous serez amene a :\n\n\ngerer le processus de deploiement :\n\n\n developpement des kpis.\n analyse et difitalisation des processus de deploiement de diverses technologies.\n collection et organisation de donnees issues de differentes sources.\n developpement de rapports power bi.\n collaboration avec les departements fonctionnels et les equipes techniques.\n\n\nqualifications :\n\n\n bac+5 en data.\n ayant 1 a 3 ans d'experience dans un poste similaire.\n\n\ncompetences requises: \n\n\ntechnique:\n power bi\n gcp\n sql\n dax\n\n\nlangues :\n allemand b2\n anglais courant, assurant lautonomie dans les echanges professionnels et la redaction de documentation technique.\n\n\nsoft skills:\n\n\n capacite danalyse : aptitude a comprendre des problematiques complexes et a concevoir des solutions adaptees.\n esprit de synthese et redactionnel : clarte dans la presentation des resultats et des recommandations.\n capacite de collaboration : faculte a travailler efficacement avec des equipes interdisciplinaires.\n force de proposition : initiative et creativite dans lidentification d'opportunites d'amelioration et de solutions innovantes.\n reactivite : capacite a gerer les priorites et a sadapter rapidement aux besoins.",
  "company_name": "alten maroc",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "power bi",
    "gcp",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-integration-data-engineer-at-alchemy-global-talent-solutions-4192434364",
  "titre": "senior integration data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-24",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "we are seeking a senior data engineer to join our team and play a crucial role in integrating customer data into our cloud-based analytics platform. this position focuses on ensuring data accuracy, quality, and seamless integration to support actionable insights and business outcomes.\nthis role is ideal for a technically skilled and detail-oriented individual who thrives in a fast-paced environment.\n\n\nthe candidate should be passionate about data, automation, and delivering impactful results.\n\n\nkey responsibilities:\n\n\n perform initial data integration for new customers.\n develop and maintain etl processes to extract, transform, and load data from various systems.\n integrate data from multiple sources, including apis, erps, databases, and web services.\n automate workflows to improve efficiency and performance.\n continuously enhance data pipelines for scalability and reusability.\n identify and resolve data quality issues to ensure consistency and accuracy.\n analyze customer data to support their business goals.\n serve as the primary technical point of contact for assigned customers.\n work closely with cross-functional teams, including engineering, product management, and customer success.\n\n\nrequired skills & expertise:\n\n\n bachelors or masters degree in computer science, data science, engineering, or a related field.\n fluency in english and french \n proficiency in programming languages such as python, java, or sql.\n experience with relational and nosql databases.\n familiarity with cloud platforms like aws or azure.\n advanced sql skills for data transformation and querying.\n strong understanding of data pipeline engineering and data design principles.\n strong knowledge of supply chain processes.\n familiarity with devops practices, including ci/cd pipelines.\n excellent communication skills, with the ability to explain technical concepts to non-technical audiences.\n french language proficiency is a significant advantage.",
  "company_name": "alchemy global talent solutions",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "sql",
    "aws"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/sr-data-scientist-llm-at-yo-it-group-4177113173",
  "titre": "sr data scientist - llm",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-03-12",
  "location": {
    "city": null,
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "python data scientist/analyst\n\nexperience: 4 - 20 years\n\nlocation: - anywhere in the world - permanent remote\n\ncontract duration:  6-12 months\n\nwork hours: 5 hours overlap with pst time zone\n\nstandard work hours are 8 am pst - 4 pm pst.\n\nmust-have\n\n bachelors/masters degree in engineering, computer science (or equivalent experience) \n at least 4 years of relevant experience as a data scientist \n 3+ years of data analysis experience and a desire to have a significant impact on the field of artificial intelligence \n 4+ years of experience working with python programming.\n fluent in conversational and written english communication skills.\n\n\njob description\n\nwe are actively seeking talented data scientists & analysts proficient in python to join our ambitious team dedicated to pushing the frontiers of ai technology. this opportunity is tailored for professionals who thrive on developing innovative solutions and aspire to be at the forefront of ai advancements. you will work with companies in the us looking to develop cutting-edge commercial and research ai solutions.\n\njob responsibilities\n\n write effective python code to tackle complex issues, but also use your business sense and analytical abilities to glean valuable insights from public databases \n communicate clearly with researchers and help the organization in realizing its objectives \n clearly express the reasoning and logic when writing code in jupyter notebooks, or other suitable mediums \n fix bugs in the code and create thorough documentation \n utilize extensive data analysis skills to develop and respond to important business queries using available datasets (such as those from kaggle, the un, the us government, etc.) \n effectively communicate with the researchers to comprehend the needs and provide the results\n\n\njob requirements\n\n bachelors/masters degree in engineering, computer science (or equivalent experience) \n at least 4 years of relevant experience as a data scientist \n 3+ years of data analysis experience and a desire to have a significant impact on the field of artificial intelligence \n 4+ years of experience working with python programming \n strong data analytic abilities and business sense are required to draw the appropriate conclusions from the dataset, respond to those conclusions, and clearly convey the key findings \n excellent problem-solving and analytical skills \n excellent communication abilities to work with stakeholders and researchers successfully \n fluent in conversational and written english communication skills\n\n\nskills: conversational english communication skills,stakeholder communication,english communication,bachelors/masters degree in engineering,ai technology,programming,written communication,spoken communication,problem-solving,business sense,python code writing,data analyst,excellent communication abilities,documentation,python,english communication skills,analytical skills,artificial intelligence,python code,kaggle datasets,written english communication skills,analytical abilities,problem solving,data scientist,business queries,conversational english communication,data science,data,computer science,data analytics,data analytic abilities,communication abilities,problem-solving skills,data analysis,bug fixing,data analysis skills,extensive data analysis,communication,un datasets,written english communication,data analytic,communication skills,engineering,python programming,us government datasets,jupyter notebooks,stakeholder management",
  "company_name": "yo it group",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 4,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "data analysis"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [
    "it",
    "artificial intelligence"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/chef-de-departement-data-analytics-at-orh-assessment-4182952176",
  "titre": "chef de departement data & analytics",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-12",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "orh assessment, cabinet specialise en recrutement et evaluation, fait partie du groupe lms, leader du conseil rh au maroc. nous aidons les entreprises a trouver les meilleurs talents et les candidats a saisir des opportunites de carriere enrichissantes.\n\n\nnous accompagnons aujourdhui notre client dans la recherche de son/sa futur(e) chef de departement data & analytics\n\n\n vos missions principales\nen tant que chef de departement data & analytics, vous serez en charge de piloter lensemble des activites liees a la collecte, lanalyse et la valorisation des donnees pour optimiser le pricing et la veille concurrentielle.\n\n\n collecte & fiabilisation des donnees\n superviser les strategies de collecte (scraping, releves terrain, partenaires).\n garantir la qualite et lintegration des donnees dans les bases internes.\n collaborer avec les equipes it et data engineering pour fluidifier les flux de donnees.\n analyse & production dinsights\n developper des analyses avancees pour optimiser le pricing et les performances commerciales.\n identifier les tendances de marche et proposer des recommandations strategiques.\n produire des dashboards et reportings interactifs pour le top management.\n gestion des outils & technologies\n superviser et ameliorer les outils bi et analytiques.\n implementer des modeles predictifs et algorithmes pour la prise de decision.\n assurer une veille sur les innovations en data science & analytics.\n management & coordination\n encadrer une equipe de 4 personnes (2 data analysts).\n travailler en transverse avec les equipes pricing, commerciales et it.\n mettre en place des bonnes pratiques en gouvernance et gestion des donnees.\n\n\n votre profil\n\n\n competences techniques :\n outils bi : power bi, tableau, qlik sense, looker\n langages : sql, python (pour automatisation et scraping)\n bases de donnees : bigquery, snowflake, redshift\n methodologies : data scraping, api, automatisation\n\n\n soft skills :\n esprit analytique et vision strategique\n leadership et capacite a federer une equipe\n bonne communication et approche orientee business\n\n\n pourquoi nous rejoindre ?\n\n\n un poste cle dans la strategie pricing et data de lentreprise \n une forte exposition aux directions strategiques et operationnelles \n un environnement stimulant et des defis analytiques a fort impact",
  "company_name": "orh assessment",
  "is_data_profile": true,
  "profile": "data strategist",
  "education_level": null,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "power bi",
    "sql",
    "python"
  ],
  "soft_skills": [
    "communication",
    "leadership",
    "problem-solving"
  ],
  "sector": [
    "consulting",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-snowflake-tech-lead-at-lumenalta-4214866824",
  "titre": "data engineer - snowflake - tech lead",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-26",
  "location": {
    "city": null,
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "experience remote done right. with over 20 years of remote experience, our 500+ team members are 100% remote, and we continue to cultivate vibrant relationships and provide exceptional opportunities for career growth while working with stellar clients on ambitious projects.\n\n\nwhat we're working on:\nenterprise companies turn to us to help them launch innovative digital products that interact with hundreds of millions of customers, transactions, and data points. the challenges we solve daily are real and require creativity, grit, and determination. we are building a culture that challenges norms while fostering experimentation and personal growth. to grasp the scale of the problems we face, ideally, you have some exposure to logistics, fintech, transportation, insurance, media, or other complex multifactor industries.\n\n\nrequirements\n 10+ years experience in a senior data engineering role using python; ideally, you have delivered business-critical software to large enterprises\n you are comfortable manipulating large data sets and handling raw sql\n experience using technologies such as snowflake, aws, and etl pipelines is essential.\n have extensive experience with data warehousing and working with scalability of large volumes of structured data\n financial services industry experience preferred\n proven track record managing teams and projects\n english fluency, verbal and written\n personality traits: professional, problem solver, proactive, passionate, team player.\n\n\n\n\nwhy lumenalta is an amazing place to work at\nat lumenalta, you can expect that you will:\n be 100% dedicated to one project at a time so that you can innovate and grow.\n be a part of a team of talented and friendly senior-level developers.\n work on projects that allow you to use leading tech.\n\n\nthe result? we produce meaningful outcomes for our clients that break barriers in their industries.\n\n\nthe job is 100% remote; please ensure you have a comfortable office set at your desired work location.\n\n\nlumenalta is committed to hiring exceptional talent from a wide variety of diverse backgrounds. if you share our values and enthusiasm for digital transformation, we encourage you to apply\n\n\nwhat's it like to work at lumenalta?",
  "company_name": "lumenalta",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": null,
  "experience_years": 10,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "snowflake"
  ],
  "soft_skills": [
    "teamwork",
    "problem-solving",
    "communication"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-scientist-data-architect-at-wama-invest-4209690264",
  "titre": "data scientist/ data architect",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-14",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "offre demploi  data scientist / data architect (5 ans dexperience minimum)\nnous recherchons des profils experimentes de data scientist et data architect, capables dintervenir sur des projets strategiques a forte valeur ajoutee.\n lieu : casablanca\n experience requise : minimum 5 ans dans un poste similaire\n missions principales (selon le profil)\npour le data scientist :\n developpement et integration de modeles predictifs dans les workflows existants\n evaluation de la qualite des donnees et fiabilisation des resultats\n documentation des modeles, tests et procedures\n veille technologique reguliere et amelioration continue des pratiques\n support n3 et contribution a la resolution des problematiques liees aux donnees\npour le data architect :\n conception et structuration de larchitecture des systemes de donnees\n mise en place des normes de qualite, de securite et de gouvernance\n supervision des flux de donnees et coordination avec les equipes data\n participation aux choix technologiques et a levolution de lecosysteme big data\n documentation des referentiels et architecture globale\n competences techniques attendues\n langages : python, scala\n stack data : hadoop (cloudera), spark, sql\n outils ml/ds : scikit-learn, pandas, pytorch, keras (pour le data scientist)\n architecture : kafka, outils de modelisation, gouvernance data (pour le data architect)\n systemes : windows, rhel\n bonus : mlflow, connaissance du cloud ou denvironnements hybrides",
  "company_name": "wama invest",
  "is_data_profile": true,
  "profile": "unspecified",
  "education_level": null,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "scala",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-it-alm-at-societe-generale-maroc-4173614578",
  "titre": "data analyst it alm",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-07",
  "location": {
    "city": "prefecture of casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "poste:\n\n\nrattache au departement alm au sein de la service unit finance, vous aurez pour mission la gestion des differentes nouvelles demandes des regulateurs bam et groupe. vous participerez aussi aux projets geres par lalm et serez le principal responsable de la refonte des outils et de la maintenance des bases et des outils utilises par lalm.\n\n\nmissions principales:\n point dentree des travaux & projets de lalm (evolution des si, projets reglementaires ou de pilotage financier) ;\n recette bancaire des metriques des projets et des evolutions des outils alm ;\n lien entre les outils et lequipe production dans le but d'instaurer un processus d'amelioration continue des reportings et des tdb, formation des equipes sur les nouveaux metriques et nouveaux reportings ;\n automatisation et optimisation des outils de production des indicateurs alm ;\n maintenance evolutive des outils adhoc alm (bases de donnees, outils de reference...) vs nouveaux besoins alm ;\n reference de loutil alm fusion risk, correspondant avec le groupe et les differents metiers ;\n calcul des taux de cession internes et analyse des marges.\n\n\nprofil recherche:\n\n\n de formation scientifique sanctionnee par un diplome dingenieur ;\n experience minimum de 2 ans dans le domaine financier bancaire ;\n maitrise des mathematiques financieres ;\n connaissances de base des produits bancaires, des marches financiers, gestion projets, risques structurels ;\n maitrise avancee de loutil excel et macros vba, connaissances de base en sgbd (access, sql) ;\n maitrise doutils alm souhaitable;\n esprit danalyse et facilites redactionnelles;\n bonnes capacites relationnelles;\n sens de linitiative et autonomie dans la gestion de son temps.",
  "company_name": "societe generale maroc",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "excel",
    "vba",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [
    "finance",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cus-postdoctoral-researcher-in-spatial-data-science-at-um6p-university-mohammed-vi-polytechnic-4213743965",
  "titre": "cus - postdoctoral researcher in spatial data science",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-20",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "postdoctoral researcher in spatial data science\n\nposition description\n\nwe are seeking a postdoctoral researcher specializing in urban modeling and cost analysis to develop an innovative model to estimate the direct and indirect costs of urbanization based on urban morphology (compact or sprawling). the candidate will analyze real case studies, integrate variables related to infrastructure, health, and the environment, and simulate scenarios under different climatic and social contexts to provide decision-making tools for sustainable urban planning.\n\nmain tasks and responsibilities\n\n develop a predictive model integrating the direct and indirect costs of urbanization.\n calibrate this model using real data from specific case studies.\n simulate urbanization costs based on various climatic, morphological, and social scenarios.\n formulate innovative methodological approaches.\n produce publications on research in scientific journals.\n participate in teaching activities.\n develop new research proposals.\n\n\nrequired qualifications\n\n ph.d. in data science, urban planning, urban economics, or a related field.\n experience in research projects applied to urban, environmental, or socio-economic issues.\n proficiency in urban modeling tools such as matlab, python (especially libraries like pandas, numpy, scipy, geopandas, etc.), and r.\n advanced skills in predictive modeling and machine learning, particularly for multi-variable simulations.\n knowledge of complex systems modeling applied to urban dynamics.\n publications in scientific journals.\n\n\npersonal and organizational qualifications\n\n ability to develop innovative methods.\n ambition for research excellence.\n interest in african issues.\n entrepreneurial mindset, dynamism, and organizational skills.\n fluency in both french and english (oral and written) is required.\n\n\nwe offer\n\n excellent working conditions and competitive salary on an international scale.\n an opportunity to contribute to the development of research excellence in africa.\n a highly stimulating multicultural working environment and a great team atmosphere.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "research scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": "none",
  "hard_skills": [
    "python",
    "matlab",
    "r"
  ],
  "soft_skills": [
    "innovation",
    "research",
    "communication"
  ],
  "sector": [
    "research",
    "education"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-scientist-at-altados-by-niji-4174454271",
  "titre": "data scientist",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-03-04",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "altados by niji recrute un data scientist avec au moins 5 ans dexperience pour une mission en sous-traitance a casablanca.\n\n\nmissions :\n collecter, analyser et modeliser des donnees pour generer des insights business\n concevoir et entrainer des modeles de machine learning et deep learning\n optimiser les algorithmes pour une mise en production efficace\n collaborer avec les data engineers pour industrialiser les modeles\n mettre en place des tableaux de bord et des visualisations pour faciliter linterpretation\n\n\ncompetences requises :\n excellente maitrise de python (pandas, scikit-learn, tensorflow, pytorch)\n experience avec sql, spark\n solide comprehension des modeles statistiques, nlp, computer vision (un plus)\n experience en deploiement de modeles en production (mlops, docker, kubernetes)\n maitrise des plateformes cloud (aws, gcp, azure)",
  "company_name": "altados by niji",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": null,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "spark"
  ],
  "soft_skills": [
    "collaboration",
    "problem-solving",
    "communication"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analytics-data-science-team-lead-casablanca-at-infomineo-4225531378",
  "titre": "data analytics - data science team lead - casablanca",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": "morocco",
    "remote": false
  },
  "description": "about us\n\ninfomineo is a brainshoring services company, supporting global clients from various geographies and industries across a range of services: business research, business translation, graphic design and data analytics.\n\ninfomineo counts +250 employees spread across different offices in the emea region and the america's. our clients include leading consultancies, fortune 500 companies, governments and ngos.\n\nabout this role\n\nthis role will give you the opportunity to deliver high added value data & analytics projects and build high quality and innovative solutions for our clients within a growing service company.\n\nwhat will you do?\n\n analyze a project from a to z with full autonomy being able to create with them a solution end to end to their data use case by showing problem solving, analytical skills and decision making\n be the primary contact for our clients, perform and set up qa processes for the team ensuring that requests are verified, reliable and up to the very high client standards\n manage projects, and coordinates priorities and budget time for each component with the project director\n serve as a mentor and coach, providing guidance, training, and career development opportunities to the team\n teach team members how to approach problems effectively and empower them to replicate these strategies in the future\n assist the manager in maintaining client relationships, pursuing business development opportunities, and managing internal projects\n\n\n\nwho are you?\n\neducation & professional experience\n\n master's degree in a relevant field such as computer science, machine learning, data science, statistics, applied mathematics, data engineering\n full proficiency in english + 1 additional language (french, german, arabic, spanish, italian, portuguese...)\n more than 8 years of technical experience in advanced analytics and data science\n\n\n\ntechnical skills\n\nacquisition & preparation\n\n proven hands-on experience in big data environments and languages such as hadoop, hortonworks, cloudera, spark, scala, pyspark etc. &big data querying tools, such as pig, hive, and impala\n proven hands-on experience in python programming language coupled with an additional languages experience if possible (e.g. sas, r, javascript)\n proven hands-on experience in large data sets both structured and unstructured data : snowflake, sql and relational databases, data warehouse, data lake\n experience in nosql databases, such as hbase, cassandra, mongodb\n\n\n\nanalysis\n\n strong skills in analytical concepts such as data correlation, pareto, market-basket analysis, forecasting, creating complex visuals like sunburst, multi-layered maps, etc\n strong skills in statistics & machine learning such as regressions, clustering techniques, time series techniques, bagging & boosting trees, ensemble models, neural networks\n experience in bi/data visualization platforms such as power bi, tableau, looker, qlikview..\n\n\n\ndeployment\n\n proven hands-on experience in api integration using python for extracting data from different sources\n proven hands-on experience in container technologies - docker, kubernetes etc\n proven hands-on experience in solutions development & deployment experience in cloud ecosystems and its associated services aws, azure, google cloud, ibm cloud\n proven hands-on experience in building robust data pipelines using etl techniques and frameworks, such as flume\n experience in the use of various messaging systems such as kafka\n proven hands-on experience to work with large volume of structured and unstructured data and leveraging it to build ai/ml model deployment & monitoring/enhancements for standalone solutions or through end-to-end automated data pipelines\n\n\n\ninterpersonnal skills\n\n ability to step back, analyze problems, find solutions and the drive to implement these\n ability to work & collaborate with variety of stakeholders & clients throughout data project lifecycle\n strong interpersonal skills and organizational skills, high motivation, an attention to detail, flexibility, and ability to cope under stress, a focus on identifying the solutions to problems\n strong communication skills & ability to translate complex solutions into business implications and at the same time being able to explain mathematical concepts when required\n strong management skills with a track record of coordinating workflow and assuring quality with a strong ability to multitask\n\n\n\nwhat we offer\n\n a competitive salary\n a great working environment\n a steep learning curve with interesting and diverse topics to work on\n a healthy work-life balance\n health insurance benefits\n\n\n\nequal opportunity employer\n\ninfomineo is an equal opportunity employer, we prohibit any sort of discrimination (based on color, race, sex, sexual orientation, religion, national origin or any other attributes) in all aspects of employment (recruiting, hiring, wages and salary, promotions, benefits, training and job termination).\n\nif you believe you match our requirements and values, we would be happy to hear from you. visit our website to know more about us, our services and company culture.",
  "company_name": "infomineo",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 8,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consultants-data-office-at-wama-invest-4206536529",
  "titre": "consultants data office",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-10",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": "morocco",
    "remote": false
  },
  "description": "wama invest recrute !\ndans le cadre de notre developpement, nous recherchons les profils suivants pour le compte de lun de nos clients a casablanca, avec minimum 5 ans dexperience :\n data engineer\nmaitrise de scala, python, hadoop, spark, sql. solide experience en calcul distribue et optimisation de workflows.\n data scientist\nexcellente connaissance en machine learning, python, scala, scikit-learn, pandas, pytorch. maitrise des workflows data et documentation technique.\n consultant data gouvernance\nexperience confirmee en gouvernance des donnees, modelisation et architecture data. bonne connaissance des outils et meilleures pratiques du domaine.\n consultant business intelligence\ntres bonne maitrise de qlikview, qlikview server, sql. la connaissance doracle db est un atout.\n postes bases a casablanca",
  "company_name": "wama invest",
  "is_data_profile": true,
  "profile": "unspecified",
  "education_level": null,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/global-is-it-data-professional-it-hub-at-opmobility-4178526971",
  "titre": "global is / it data professional - it hub",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-12",
  "location": {
    "city": "tangier",
    "region": "tanger-tetouan-al hoceima",
    "country": "morocco",
    "remote": false
  },
  "description": "hungry for challenges? join a group with innovation at its heart and contribute to the automotive revolution!\n\nopmobility is a world-leading provider of innovative solutions for a unique, safer and more sustainable mobility experience. innovation-driven since its creation, the group develops and produces intelligent exterior systems, customized complex modules, lighting systems, clean energy systems and electrification solutions for all mobility companies. with a 11.4 billion economic revenue in 2023, a global network of 152 plants and 40 r&d centers, opmobility relies on its 40,300 employees to meet the challenges of transforming mobility.\n\nour ambition? provide automakers with cutting-edge equipment and solutions to develop tomorrows clean and connected car.\n\njoin our dynamic team as we establish an innovative data office dedicated to transforming our data landscape. be at the forefront of data strategy, governance, and analytics, driving impactful decisions across the organization. thrive in a collaborative environment where your expertise will shape the future of data management within opmobility and contribute to cutting-edge projects. make your mark with us!\n\nto support our growth we are looking for senior data engineer(s) working in close cooperation with business stakeholders\n\nproject management\n\n co-construct project plan with business stakeholders (teams, planning, method,....)\n implement project plan and prepare all project governance meetings\n support business stakeholders in the design phase\n conduct post-project evaluations to identify lessons learned and areas for improvement\n monitor project progress and adjust plans as needed to ensure timely delivery\n\n\ndata engineering\n\n collaborate with cross-functional teams to understand data requirements\n design data models & data products with the data managers and data architect(s)\n implement and maintain etl/elt/esb processes\n design optimal data pipelines\n build, document and maintain data pipelines\n build and run data products (data apis, datasets...)\n sets up data quality controls\n monitor and continuously improves data pipelines\n adopt ci/cd practices\n implement access policies for the data sets / data products in his/her scope\n\n\nrequirements\n\n master degree\n 8 years of work experience in an it-related field, preferably within the industry\n programming language applied to data analysis (sql, python, spark, ..)\n good level in english\n ability to design and implementation of secure data acquisition and integration strategies (etl / elt / esb)\n experience with data modeling and warehousing concepts\n excellent communication and collaboration skills\n\n\nlocation\n\n tangier automotive city - cherafate\n 2 days of home office / week\n\n\nas a responsible company, opmobility pays particular attention to diversity and equality within its teams and the group commits to treat all job applications equally.",
  "company_name": "opmobility",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": null,
  "experience_years": 8,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "python",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "problem-solving"
  ],
  "sector": [
    "automotive",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-quality-analyst-h-f-at-labelvie-4221194668",
  "titre": "data quality analyst (h/f)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-06",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "cree en 1986 et cote a la bourse de casablanca depuis 2008, le groupe marocain labelvie est un acteur economique de reference et leader de la grande distribution au maroc.\nen 2009, a travers la signature du contrat de franchise avec le groupe carrefour, il accede a sa centrale dachat pour optimiser et diversifier son sourcing. il devient ainsi le premier acteur multi-formats de la grande distribution au maroc par lexploitation des hypermarches carrefour, des supermarches carrefour market et du format hyper cash atacadao.\nle groupe labelvie presente chaque annee un plan de developpement soutenu renforcant sa presence territoriale avec ses 136 magasins repartis dans 28 villes du royaume et ses 3 plateformes logistiques et un chiffre daffaires realise de 11,7 milliards de dirhams en 2021.\nen 2021, le groupe labelvie a entame sa transformation digitale afin de repondre aux enjeux dinnovation et aux besoins des consommateurs finaux. ce sont ainsi de nombreux projets structurants qui sont actuellement en construction au sein du groupe pilotes par nos equipes si, digital et data ; constituees dexperts reconnus dans leur domaines et animes par la volonte de relever les challenges de linnovation et de la transformation digitale dans un secteur en plein essor.\n\n\nle data quality analyst (h/f) a pour mission dassurer la mesure de la qualite des donnees ainsi que lidentification et la resolution des anomalies relatives a la qualite de ces donnees en collaboration avec les equipes metiers, data et it.\n\n\nles principales responsabilites sont de : \n\n\n definir les standards et les criteres de qualite des donnees;\n definir les kpi de suivi de la qualite des donnees ;\n creer et maintenir les tableaux de bord et les outils de suivi de la qualite des donnees;\n concevoir et gerer la procedure de gestion de la qualite des donnees(profilage des donnees, nettoyage, homogeneisation, dedoublonnage et deduplication,enrichissement et reporting);\n assurer le diagnostic et la surveillance de la qualite des donnees de maniere reguliere;\n identifier les anomalies relatives a la qualite des donnees;\n supporter lanalyse des root causes de ces anomalies et la definition des plans dactions de remediation et de prevention\n assurer le suivi de la realisation de ces plans dactions de remediation et de prevention....\n\n\n\n\n\n\nprofil recherche:\n\n\nde formation bac+5 en ecole dingenieur ou de commerce avec une specialisation en data, dans laquelle vous avez developpe les competences suivantes :\n solides competences en analyse de donnees et en profilage de la qualite\n familiarite avec les problemes et les processus de qualite des donnees\n dynamique et rigueur\n organisation et esprit analytique \n aptitude a communiquer (a l'oral et a l'ecrit) et a convaincre \n esprit danalyse et de synthese ....\n\n\n label'vie sengage a prevenir toute forme de discrimination et notamment celles fondees sur le sexe, la condition physique ou mentale ou la situation et les responsabilites familiales. label'vie sengage a promouvoir legalite des chances entre les hommes et les femmes, en matiere dacces a lemploi et a la formation, de conditions de travail, de remuneration, devolution de carriere et dacces a des postes a responsabilite .",
  "company_name": "labelvie",
  "is_data_profile": true,
  "profile": "data quality analyst",
  "education_level": null,
  "experience_years": null,
  "seniority": "none",
  "hard_skills": [
    "sql",
    "data profiling",
    "data cleaning"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "analysis"
  ],
  "sector": [
    "retail",
    "data"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-x-delivery-at-boston-consulting-group-bcg-4188521639",
  "titre": "data engineer - x delivery",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-27",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": "morocco",
    "remote": false
  },
  "description": "who we are\n\nboston consulting group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. bcg was the pioneer in business strategy when it was founded in 1963. today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\n\nto succeed, organizations must blend digital and human capabilities. our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. bcg delivers solutions through leading-edge management consulting along with technology and design, corporate and digital venturesand business purpose. we work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\n\nwe are bcg x\n\nwere a diverse team of more than 3,000 tech experts united by a drive to make a difference. working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. we go beyond what was once thought possible, creating new and innovative solutions to the worlds most complex problems. leveraging bcgs global network and partnerships with leading organizations, bcg x provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. together, we strive to create solutions that will positively impact the lives of millions.\n\nwhat you'll do\n\nwhat you'll do as a part of bcg's x delivery team, you will work closely with consulting teams on a diverse range of advanced topics. you will have the opportunity to leverage data engineering techniques to deliver value to bcg's consulting & bcg x (case) teams, bcg x product teams and practice areas (domain). you will collaborate with teams to gather requirements, specify, design, develop, deliver and support industrialized solutions serving client needs. you will provide technical support through deep understanding of relevant tools and processes to build high quality and efficient technology solutions.\n\nyou're good at\n\ntechnical skills\n\nmust have strong experience:\n\n python\n cloud computing platforms (aws, azure, google cloud, etc.)\n containerization (docker, kubernetes, etc.)\n relational databases (postgresql, mariadb, mysql, etc.)\n nosql databases (mongodb, neo4j, redis, etc)\n spark or other distributed big data systems (hadoop, pig, hive, etc.)\n stream-processing frameworks (e.g. kafka)\n data pipeline orchestration tools (airflow, prefect, dagster, etc.)\n unix-based command line & development tools\n version control (e.g. git)\n\n\nnice to have\n\n java, scala\n flask, fastapi, django or nodejs (backend)\n ci/cd tools (circleci, octopus deploy, jenkins, etc.)\n infrastructure as code (terraform, chef, puppet, ansible, etc.)\n deployment (helm charts, octopus deploy, etc.)\n monitoring tools (datadog, new relic, app dynamics, etc.)\n security tools (sonarqube, veracode)\n unit testing frameworks (pytest, mocha, jest, etc.)\n automated ui testing tools (selenium, cypress, playwright, etc.)\n postman or other api testing tool\n\n\nfunctional skills\n\n data modeling for analytics and decisioning\n selecting and integrating big data tools\n implementing etl process(s) across on-premise and cloud architectures\n monitoring performance and advising any necessary infrastructure changes\n\n\ncommunicating with confidence and ease\n\nyou will be a clear and confident communicator, able to deliver messages in a concise manner with strong and effective written and verbal communication.\n\nwhat you'll bring\n\njob requirement\n\n bachelor's / master's degree in computer science, engineering/technology or equivalent\n excellent oral and written communication skills in english\n\n\nwork experience\n\n relevant domain of data engineering across industries and work experience providing analytics solutions in a commercial setting\n consulting experience will be considered a plus\n\n\nadditional info\n\nbcg x is the tech build & design unit of bcg. turbocharging bcg's deep industry and functional expertise, bcg x brings together advanced tech knowledge and ambitious entrepreneurship to help organizations enable innovation at scale. with nearly 3,000 technologists, scientists, programmers, engineers, and human-centered designers located across 80+ cities, bcg x builds and designs platforms and software to address the world's most important challenges and opportunities. teaming across our practices, and in close collaboration with our clients, our end-to-end global team unlocks new possibilities. together we're creating the bold and disruptive products, services, and businesses of tomorrow. bcg gamma as part of bcg x is dedicated to building cutting-edge ai and digital systems that go beyond prototypes to transform our clients' core businesses. powered by proprietary data assets, our custom products integrate into clients' unique tech stacks to enable better, faster decision making.\n\nboston consulting group is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\n\nbcg is an e - verify employer. click here  for more information on e-verify.",
  "company_name": "boston consulting group (bcg)",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": null,
  "experience_years": null,
  "seniority": "none",
  "hard_skills": [
    "python",
    "sql",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "problem-solving"
  ],
  "sector": [
    "consulting",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-altados-by-niji-4174453485",
  "titre": "data analyst",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-03-04",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "altados by niji recrute un data analyst avec au moins 5 ans dexperience pour une mission en sous-traitance a casablanca.\n\n\nmissions :\n analyser de grandes quantites de donnees pour identifier des tendances cles\n concevoir des tableaux de bord et des rapports interactifs\n collaborer avec les equipes metier pour traduire leurs besoins en analyses exploitables\n automatiser les processus de reporting et dextraction de donnees\n assurer la qualite et lintegrite des donnees\n\n\ncompetences requises :\n excellente maitrise de sql et python (pandas, numpy, matplotlib, seaborn)\n experience avec power bi, tableau, looker\n bonne comprehension des kpis, reporting et statistiques descriptives\n connaissance des plateformes cloud (aws, gcp, azure)\n experience en gestion et visualisation de donnees (google analytics, snowflake, bigquery, redshift  un plus)",
  "company_name": "altados by niji",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": null,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "python",
    "power bi"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "problem-solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/stagiaire-business-data-analyst-at-digital-virgo-4182908227",
  "titre": "stagiaire business data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-12",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": "morocco",
    "remote": false
  },
  "description": "description de l'entreprise\n\nle groupe digital virgocompte parmi les specialistes mondiaux du paiement mobile via les solutions de facturation des operateurs telecoms. en connectant les marchands aux operateurs, nous repondons au besoin croissant de digitalisation du paiement en utilisant un canal transactionnel simple, rapide et securise, disponible partout dans le monde.\n\nen rejoignantdigital virgo, tu integres un groupeinternational performant et innovantgrace a des equipes locales, a taille humaine qui collaborent au quotidien, fortes de leur complementarite. nous venons tousdunivers et de parcours differents, cest cette diversite qui fait notre richesse.\n\nnos collaborateurs disent de nous, que l'ambiance de travail est un melange parfait de bonne humeur et de projets ambitieux. nous mettons l'accent sur le developpement de chacun et la prise d'initiatives.\n\nplus dinformations sur notre activite et groupe surdigitalvirgo.com\n\ndescription du poste\n\ncollecte et traitement des donnees\n\n extraction des donnees via base de donnees ou outils bi\n sassurer de la fiabilite des donnees avant utilisation\n\n\nanalyse et interpretation\n\n realiser des analyses pour identifier des tendances ou insights business\n construire des tableaux de bord et des rapports pour suivre les perfs cles\n aider a la prise de decision grace a des recommandations basees sur les resultats des analyses\n\n\nvisualisation des donnees\n\n concevoir des graphiques et dashboards interactifs pour rendre les analyses plus accessibles aux equipes metiers\n utiliser des outils comme tableau ou looker\n\n\nsupport aux equipes metier\n\n travailler en collaboration avec les equipes marketing, finance, produit, etc., pour repondre a leurs besoins en data. \n expliquer les resultats des analyses et aider a la prise de decision strategique.\n\n\nqualifications\n\ntechniques :\n\nmaitrise dexcel (tableaux croises dynamiques, formules avancees, etc.)\n\nconnaissance en sql (requetes pour extraire et manipuler des donnees)\n\nfamiliarite avec des outils de data visualisation (tableau, looker.)\n\nbases en python (pour lanalyse et le traitement des donnees, un plus)\n\ncomprehension des statistiques et des modeles analytiques\n\nsoft skills :\n\nesprit analytique et capacite a interpreter des chiffres\n\nrigueur et attention aux details\n\nautonomie et capacite a resoudre des problemes\n\nbonne communication en francais et en anglais",
  "company_name": "digital virgo",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": null,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "excel",
    "sql",
    "tableau"
  ],
  "soft_skills": [
    "analysis",
    "communication",
    "problem-solving"
  ],
  "sector": [
    "finance",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/ia-data-science-%2B-2-ans-d-exp%C3%A9riences-at-indatacore-4225590176",
  "titre": "ia & data science (+ 2 ans d'experiences )",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "indatacore recrute un profil ia & data science avec 2 ans d'experience minimum\n\n\nvotre mission :\nintegre(e) au sein de notre equipe r&d et projets clients, vous serez en charge de :\n la conception, l'entrainement et le deploiement de modeles d'ia pour des cas dusage complexes (vision par ordinateur, nlp, prediction, etc.).\n travailler sur les modeles llm (fine-tuning, evaluation, prompt engineering, integration dans des pipelines).\n le traitement dimages (ocr, detection dobjets, segmentation, classification, etc.) a laide de reseaux de neurones convolutifs ou de modeles avances (vision transformers, yolo, etc.).\n developper des composants backend en java pour lintegration des modeles dans des plateformes dentreprise.\n participer a la mise en production de modeles ia via des api, microservices ou serveurs de modeles.\n collaborer avec les equipes de data engineering pour le traitement et la structuration de grands volumes de donnees.\n maintenir une veille technologique active sur les outils et methodes de lia moderne.\n\n\nprofil recherche :\n 2+ ans dexperience en data science avec maitrise des algorithmes de machine learning et deep learning.\n excellente maitrise de tensorflow et/ou pytorch.\n experience concrete avec les modeles de type llm (gpt, llama, mistral, etc.).\n bon niveau en developpement java, avec pratique dans des environnements dapi rest et services backend.\n experience en deploiement de modeles : docker, fastapi, kubernetes, torchserve, tensorflow serving...\n bases solides en data engineering : pipelines de donnees, spark, airflow, sql/nosql, ingestion temps reel.\n\n\ninteresse(e) ? envoie-nous ton cv a doha.yahia@indatacore.com ou en message prive. \nton futur challenge tattend !\nsecteur services et conseil en informatique\ntype demploitemps plein\n\n\nmodifier la description du poste",
  "company_name": "indatacore",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": null,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "tensorflow",
    "pytorch",
    "java"
  ],
  "soft_skills": [
    "collaboration",
    "problem-solving",
    "communication"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-senior-at-alten-4225741830",
  "titre": "data analyst - senior",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-11",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\nalten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2027. avec plus de 90 recrutements par mois, alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\ndescription du poste\n\nnous travaillons avec les equipes business, product management et design pour concevoir des outils ergonomiques et fiables. nous recherchons un data analyst senior passionne et experimente dans l'analyse de donnees complexes. vous serez responsable de la collecte, du traitement, de l'analyse et de la visualisation des donnees pour fournir des insights strategiques. vous jouerez un role cle dans la prise de decision en collaborant etroitement avec des equipes metier, des developpeurs et des data engineers.\n\nanalyse et visualisation de donnees :\n\n developper des dashboards interactifs et dynamiques sous lokker et looker studio. \n identifier et suivre des kpis critiques pour le pilotage des activites metiers.\n\n\nmodelisation et preparation des donnees :\n\n concevoir des pipelines de donnees optimises dans bigquery. \n assurer la qualite et la fiabilite des donnees pour garantir la coherence des analyses. exploration et extraction des donnees :\n rediger et optimiser des requetes sql complexes sur bigquery. \n automatiser les traitements analytiques pour ameliorer les performances.\n\n\nsupport et collaboration :\n\n travailler en etroite collaboration avec les equipes metier des differents payspour comprendre leurs besoins analytiques. \n former et accompagner les utilisateurs dans l'utilisation des dashboards et des outils danalyse.\n\n\nqualifications\n\ndiplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique, ou justifiant d'une experience significative equivalente\n\nexperience de plus de 8 ans en sql\n\nexperience avec dbt, looker, looker studio et outils bi similaires\n\nmust have:\n\n experience en bases de donnees sql / nosql (dbt, postgresql, mongodb...)\n bonne maitrise de sql et experience dun an avec bigquery. \n bonne maitrise dans la creation et loptimisation de dashboards sous looker studio (experience > 1 an)\n excellente communication ecrite et orale.\n\n\nnice to have:\n\n python\n experience en methodologie agile (scrum, sprint planning, backlog...). \n gestion des versions et ci/cd avec gitlab ci\n\n\ninformations supplementaires\n\nau plaisir de vous lire !",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 8,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "dbt",
    "looker"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "collaboration"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/freelance-contr%C3%B4le-de-gestion-alm-et-data-analyst-at-cost-house-middle-east-africa-4188123614",
  "titre": "freelance controle de gestion / alm et data analyst",
  "via": null,
  "contrat": "other",
  "type_travail": null,
  "publication_date": "2025-03-18",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "controleur de gestion : bac+5, exp : +10 ans\nalm : bac+5, exp : +7 ans\ndata analyst : bac+5, exp : 5 ans.",
  "company_name": "cost house middle east africa",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "mid",
  "hard_skills": [
    "sql",
    "excel",
    "reporting"
  ],
  "soft_skills": [
    "communication",
    "analysis",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-senior-sql-at-alten-4197135049",
  "titre": "data analyst senior sql",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-04",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "alten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2024. avec plus de 90 recrutements par mois, alten maroc est desormais un acteur majeur de linsertion professionnelle des  ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\n\nrejoindre alten maroc cest beneficier :\n\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers.\n des formations certifiantes et diplomantes.\n des evenements reguliers pour combiner bien etre et performance\n\n\ndescription du poste\n\nnous travaillons avec les equipes business, product management et design pour concevoir des outils ergonomiques et fiables. nous recherchons un data analyst senior passionne et experimente dans l'analyse de donnees complexes.\n\n\nvous serez responsable de la collecte, du traitement, de l'analyse et de la visualisation des donnees pour fournir des insights strategiques. vous jouerez un role cle dans la prise de decision en collaborant etroitement avec des equipes metier, des developpeurs et des data engineers.\n\n\nanalyse et visualisation de donnees :\n\n\n developper des dashboards interactifs et dynamiques sous lokker et looker studio.\n identifier et suivre des kpis critiques pour le pilotage des activites metiers.\nmodelisation et preparation des donnees :\n\n\n concevoir des pipelines de donnees optimises dans bigquery.\n assurer la qualite et la fiabilite des donnees pour garantir la coherence des analyses.\nexploration et extraction des donnees :\n\n\n rediger et optimiser des requetes sql complexes sur bigquery.\n automatiser les traitements analytiques pour ameliorer les performances.\nsupport et collaboration :\n\n\n travailler en etroite collaboration avec les equipes metier des differents pays du groupe carrefour pour comprendre leurs besoins analytiques.\n former et accompagner les utilisateurs dans l'utilisation des dashboards et des outils danalyse\n\n\nqualifications\n\n diplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique, ou justifiant d'une experience significative equivalente\n experience de plus de 7 ans en sql\n experience avec dbt, looker, looker studio et outils bi similaires\n une experience dans le secteur du commerce de detail ou de la grande distribution serait un plus.\ncompetences requises :\n\n\n bonne maitrise des bases de donnees sql / nosql (dbl, postgresql, mongodb...)\n excellente maitrise de sql et experience avec bigquery.\n expertise dans la creation et loptimisation de dashboards sous looker studio.\n excellente communication ecrite et orale : aptitude a produire des livrables et des reportings de haute qualite.\n expertise en python (pandas, numpy, pyspark...)\n esprit d'analyse et d'amelioration continue : capacite a evaluer le code et ses impacts, ainsi qu'a remettre en question les solutions existantes pour les ameliorer.\n comprehension des principes devops et cloud (aws, gcp, azure)\n connaissance des architectures data modernes (data lake, data warehouse)\n capacite de prise de recul : aptitude a evaluer les problematiques avec objectivite et a proposer des solutions d'amelioration.\n esprit d'equipe : capacite a collaborer efficacement avec les membres de l'equipe pour atteindre des objectifs communs.\n maitrise des concepts dagilite (scrum, sprint planning, backlog...).\n capacite a travailler de maniere autonome et a gerer son temps efficacement.\n gestion des versions et ci/cd avec gitlab ci",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "dbt",
    "looker"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "analysis"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consultant-data-analyst-at-gec-global-experts-consulting-4191278544",
  "titre": "consultant data analyst",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-03-22",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "gec recherche un consultant data analyst experimente pour renforcer les equipes data dun grand acteur du secteur financier.\n\nobjectif : structurer, modeliser et valoriser les donnees pour optimiser les prises de decision.\n\nmissions :\n\n collecte et nettoyage de donnees \n conception de dashboards et kpis \n creation de datamarts & visualisation dynamique\n\n\nstack : python, sql, tableau, power bi\n\nbonus : dremio\n\nprofil avec au moins 3 ans dexperience dans un environnement data structure, idealement dans la banque ou lassurance.\n\ncasablanca  mode hybride possible\n\ndemarrage rapide",
  "company_name": "gec _ global experts consulting",
  "is_data_profile": true,
  "profile": "data consultant",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "sql",
    "tableau"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-owner-at-orange-business-4181352314",
  "titre": "data owner",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-17",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "au sein de la direction prodcut and marketing, nous recrutons un data owener confirme qui aura pour principales missions:\n comprendre les fondations existantes sur les catalogues et en promouvoir la federation.\n porter le data management des informations catalogue\n identifier les opportunites dalignement, notamment en lien avec les projets de transformation metier et digitaux.\n construction et pilotage de la roadmap des evolutions catalogue\n\n\ndata management des informations catalogue :\n en transverse a lentreprise sur lensemble du domaine b2b, vous portez la definition, la modelisation (y compris lien avec les autres master data), la politique de gestion du cycle de vie (process et acteur pour la creation, usage, mise a jour, obsolescence), implementation du  one truth .\n\n\nroadmap et transformation catalogue :\n ecoute des cas clients, des business lines, des metiers, de lit et des meilleures pratiques du data management.\n identification des niveaux, risques et problemes de qualite et de non alignement.\n consolidation et valorisation des priorites business pour aligner la donnee en anticipant les besoins des projets digitaux ou metiers (data by design), a defaut en reactif.\n organisation et priorisation des projets damelioration. mesure des effets.\n pilotage de la roadmap sur la donnee catalogue : projet referentiel, deploiement et usage par les applications it, evolutions processus, mise a niveau sur la donnee.\n pilotage de certains projets de cette transformation en tant que responsable metier.\n\n\nprofil recherche :\n formation ecole dingenieur ou equivalent universitaire en informatique et/ou telecom.\n experience professionnelle superieure a 5/7 ans\n au sein dun operateur de service, telecom ou pas, en transverse cote processus ou it, et a linterface entre les 2.\n\n\ncompetences requises :\n\n\n-technique et savoir faire\n modelisation processus, information et traitement,\n architecture it fonctionnelle dun operateur de service/telco.\n root cause analysis/ aller chercher le besoin source\n-communication et savoir etre\n tres bon niveau de communication ecrit/oral en francais et en anglais.\n vous etes autonome, dynamique, convaincant(e) et savez etre force de proposition.\n capacite a evoluer dans un ecosysteme riche et anime, voire complexe\n vous savez animer un groupe de travail metier\n vous etes curieux, precis, analytique.\n oriente resultat\n sens du collectif.",
  "company_name": "orange business",
  "is_data_profile": true,
  "profile": "data governance analyst",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "data modeling",
    "process modeling",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/ia-data-science-%2B-2-ans-d-exp%C3%A9rince-at-indatacore-4219660504",
  "titre": "ia & data science ( + 2 ans d'experince )",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-30",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "indatacore recrute un profil ia & data science avec 2 ans d'experience minimum\n\n\nvotre mission :\nintegre(e) au sein de notre equipe r&d et projets clients, vous serez en charge de :\n la conception, l'entrainement et le deploiement de modeles d'ia pour des cas dusage complexes (vision par ordinateur, nlp, prediction, etc.).\n travailler sur les modeles llm (fine-tuning, evaluation, prompt engineering, integration dans des pipelines).\n le traitement dimages (ocr, detection dobjets, segmentation, classification, etc.) a laide de reseaux de neurones convolutifs ou de modeles avances (vision transformers, yolo, etc.).\n developper des composants backend en java pour lintegration des modeles dans des plateformes dentreprise.\n participer a la mise en production de modeles ia via des api, microservices ou serveurs de modeles.\n collaborer avec les equipes de data engineering pour le traitement et la structuration de grands volumes de donnees.\n maintenir une veille technologique active sur les outils et methodes de lia moderne.\n\n\nprofil recherche :\n 2+ ans dexperience en data science avec maitrise des algorithmes de machine learning et deep learning.\n excellente maitrise de tensorflow et/ou pytorch.\n experience concrete avec les modeles de type llm (gpt, llama, mistral, etc.).\n bon niveau en developpement java, avec pratique dans des environnements dapi rest et services backend.\n experience en deploiement de modeles : docker, fastapi, kubernetes, torchserve, tensorflow serving...\n bases solides en data engineering : pipelines de donnees, spark, airflow, sql/nosql, ingestion temps reel.\n\n\ninteresse(e) ? envoie-nous ton cv a doha.yahia@indatacore.com ou en message prive. \nton futur challenge tattend !",
  "company_name": "indatacore",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "tensorflow",
    "pytorch",
    "java"
  ],
  "soft_skills": [
    "teamwork",
    "communication",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-axa-assurance-maroc-4188044527",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-18",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "axa assurance maroc recrute pour le compte de sa direction transformation / data, analytics & ai un /une data analyst :\n\n\nmission du poste :\n\n\nle data analyst a pour mission dexplorer et interpreter les donnees pour en degager des observations business utiles. ainsi, les analyses fournies permettent d'orienter les prises de decision du management et ameliorer les performances et les strategies marketing et commerciales de lentreprise.\n\n\nactivites du poste :\n\n\n collecter, agreger et nettoyer des donnees en vue de realiser des etudes sur les donnees entreprise ;\n modeliser et enrichir les entrepots de donnees et les datamarts (magasins de donnees) dedies a une fonction particuliere dans lentreprise ;\n concevoir et livrer larchitecture applicative et technique necessaire pour la valorisation de donnees (data lake, data warehouse, data viz) ;\n fournir lexpertise technologique necessaire pour developper les solutions data appropriees aux differents cas dusage data emanant des unites metiers de lentreprise ;\n effectuer les croisements de donnees necessaires ainsi que les travaux de validation, correction, qualite ;\n effectuer des analyses decisionnelles sur les donnees traitees...\n\n\nen outre, et de facon non limitative, il peut etre amene a effectuer toute mission a la demande de sa hierarchie, compatible avec sa fonction.\n\n\ncompetences requises : \n\n\n maitrise de la modelisation de donnees decisionnelles (schema en flocons...) ;\n maitrise des solutions etl/elt: talend, informatica, ssis ;\n connaissance des solutions de bases de donnees sql : microsoft sql server, sas base, sap hana ;\n connaissance des systemes nosql : elasticsearch, hbase, cassandra, redshift ;\n maitrise des solutions : powerbi ;\n bonne maitrise des langages de programmation : scala, java, python ;\n bonne connaissance basique sur le machine learning, data science, et lintelligence artificielle ;\n sens de l'organisation et du detail ;\n capacites d'analyse ;\n capacite a travailler methodiquement dans la repetitivite ;\n acceptation du changement, adaptabilite ;\n capacite a innover et proposer ;\n respect de la confidentialite, ethique ;\n ecoute active, empathie, travail en equipe ...\n\n\nprofil recherche :\n\n\n de formation bac+4 ou plus, universite ou ecole dingenieur en data ou bi ;\n experience de minimum 2 ans dans un poste similaire... \n\n\nsi le descriptif correspond a votre profil et motivations professionnelles, merci de nous faire parvenir vos cv.\n\n\npourquoi rejoindre axa assurance maroc ?\n\n\n axa est un des leaders de lassurance et de la gestion dactifs a travers le monde.\n nous aidons nos 108 millions de clients a traverser les petites et grandes difficultes de la vie.\n acceder a des opportunites de developpement professionnel et de formation continue pour favoriser votre croissance au sein de notre entreprise et enrichir votre panel de competences.\n evoluer dans une culture d'entreprise basee sur lagilite, la performance individuelle et collective, la collaboration et l'ethique.\n etre collaborateur axa assurance maroc, cest rejoindre un environnement de travail inclusif et diversifie, ou chaque individu est valorise et a la possibilite de s'epanouir.\n tous nos emplois sont ouverts aux personnes en situation dhandicap.",
  "company_name": "axa assurance maroc",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "powerbi",
    "python"
  ],
  "soft_skills": [
    "communication",
    "analysis",
    "teamwork"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/junior-data-scientist-at-oracle-4181969307",
  "titre": "junior data scientist",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-17",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "job description\n\ndata scientist - oracle labs\n\nlocation: casablanca (onsite)\n\n msc degree in computer science, data science, machine learning, or a related technical field or equivalent practical experience\n 1-3 years of hands-on software development in data science, machine learning, or ai, with proven expertise in coding and system design. \n demonstrated work in generative ai and ai agents is an important plus.\n experience using deep learning toolkits in python like tensorflow, torch, or keras\n experience in formulating analytical problems into actionable research and applying advanced machine learning techniques for problem solving\n working proficiency in verbal and written english\n ability to articulate complex technical topics clearly and concisely to both technical and non-technical audiences. \n a drive to solve hard problems at scale\n thorough understanding of cs fundamentals including data structures, algorithms and complexity analysis\n\n\n\nkey requirements\n\n phd degree in computer science or machine learning or related technical field, or equivalent practical experience.\n distinguished problem-solving skills.\n strong presentation and stakeholder management capabilities to align technical objectives with business goals.\n deep comprehension of the importance of teamwork and demonstrated ability to work with and guide collaborative, high-performing teams.\n experience with cloud platforms like oci, aws or azure.\n familiarity with containerization and orchestration tools such as docker and kubernetes.\n commitment to fostering a culture of teamwork, innovation, and continuous improvement.\n\n\n\ncareer level - ic2\n\nresponsibilities\n\nas a member of the software engineering division, you will apply basic to intermediate knowledge of software architecture to perform software development tasks associated with developing, debugging or designing software applications or operating systems according to provided design specifications. build enhancements within an existing software architecture and occasionally suggest improvements to the architecture.\n\nabout us\n\nas a world leader in cloud solutions, oracle uses tomorrows technology to tackle todays challenges. weve partnered with industry-leaders in almost every sectorand continue to thrive after 40+ years of change by operating with integrity.\n\nwe know that true innovation starts when everyone is empowered to contribute. thats why were committed to growing an inclusive workforce that promotes opportunities for all.\n\noracle careers open the door to global opportunities where work-life balance flourishes. we offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. we also encourage employees to give back to their communities through our volunteer programs.\n\nwere committed to including people with disabilities at all stages of the employment process. if you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the united states.\n\noracle is an equal employment opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans status, or any other characteristic protected by law. oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.",
  "company_name": "oracle",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 4,
  "experience_years": 3,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "tensorflow",
    "machine learning"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-databricks-tech-lead-at-lumenalta-4223166038",
  "titre": "data engineer - databricks - tech lead",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-05",
  "location": {
    "city": null,
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "experience remote done right. with over 20 years of remote experience, all 500+ staff are 100% remote, and we still grow vibrant relationships and provide exceptional opportunities for career growth while working with stellar clients on ambitious projects.\n\n\nwhat we're working on:\nenterprise companies turn to us to help them launch innovative digital products that interact with hundreds of millions of customers, transactions and data points. the problems we solve daily are real and require creativity, grit and determination. we are building a culture that challenges norms while fostering experimentation and personal growth. to grasp the scale of problems we face, ideally, you have some exposure to logistics, fintech, transportation, insurance, media or other complex multifactor industries.\n\n\nrequirements\n 10+ years experience in a senior developer role using python; ideally, you have delivered business-critical software to large enterprises\n you are comfortable manipulating large data sets and handling raw sql\n experience using technologies such as pyspark/aws/databricks is essential\n experience creating etl pipeline from scratch\n experience leading teams and managing projects\n e-commerce and financial services industry experience preferred\n english fluency, verbal and written\n experience dealing with c-suite level stakeholders\n personality traits: professional, problem solver, proactive, passionate, team orientated.\n\n\nwhy lumenalta is an amazing place to work at\nat lumenalta, you can expect that you will:\n be 100% dedicated to one project at a time so that you can innovate and grow.\n be a part of a team of talented and friendly senior-level developers.\n work on projects that allow you to use leading tech.\n\n\nthe result? we produce meaningful outcomes for our clients that break barriers in their industries.\n\n\nthe job is 100% remote; please ensure you have a comfortable office set at your desired work location.\n\n\nlumenalta is committed to hiring exceptional talent from a wide variety of diverse backgrounds. if you share our values and enthusiasm for digital transformation, we encourage you to apply\n\n\nwhat's it like to work at lumenalta?",
  "company_name": "lumenalta",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 10,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "pyspark",
    "sql"
  ],
  "soft_skills": [
    "teamwork",
    "problem-solving",
    "communication"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-aws-h-f-at-cgi-4222605763",
  "titre": "data engineer aws (h/f)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "description de poste\n\nnous recherchons un data engineer aws talentueux pour rejoindre notre equipe dynamique. une expertise approfondie dans la modelisation des donnees, la transformation et la conception de pipelines etl serait fortement recommandee.\n\nvous serez responsable de la conception, configuration, developpement et gestion de pipelines via sdlf et divers services aws tels que glue, lambda, step functions, eventbridge, dynamodb, athena, iceberg,\n\nfonctions et responsabilites\n\n modelisation des donnees, transformation et conception de pipelines etl.\n maitrise des structures de donnees et formats optimises (parquet, orc) pour une interrogation performante.\n conception, configuration, developpement et gestion de pipelines via sdlf et services aws.\n traitement de donnees avec pyspark et python.\n exploitation efficace de s3 et athena.\n mise en place de la supervision via cloudwatch et cloudtrail.\n migration des donnees vers s3 via aws dms.\n application rigoureuse des bonnes pratiques de securite aws (chiffrement, controle dacces, roles iam, etc.).\n\n\nqualites requises pour reussir dans ce role\n\n connaissance et experience autour de sdlf requise\n connaissance avancee de lecosysteme aws : ec2, vpc, api gateway, iam, cloudformation, lakeformation, rds, sns, sqs, sdk, cdk.\n experience avec les outils de traitement de donnees tels que pyspark et python.\n expertise en conception et gestion de pipelines etl.\n bonne capacite a diagnostiquer et resoudre les problematiques techniques, y compris les enjeux de performance.\n comprehension des environnements techniques aws et ssis/sql server.\n aptitude a analyser les logs, identifier les goulets detranglement, optimiser le code et les configurations.\n mise en uvre de solutions perennes garantissant la fiabilite et la performance des traitements.\n\n\ncgi est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap et a levolution de carrieres des hommes et des femmes.\n\nensemble, en tant que proprietaires, mettons notre savoir-faire a luvre.\n\nla vie chez cgi est ancree dans lactionnariat, le travail dequipe, le respect et un sentiment dappartenance. chez nous, vous pourrez exploiter votre plein potentiel parce que...\n\nnous vous invitons a devenir proprietaire des le jour 1 alors que nous travaillons ensemble a faire de notre reve une realite. cest pourquoi nous nous designons comme associes de cgi, plutot que comme employes. nous tirons profit des retombees de notre succes collectif et contribuons activement a lorientation et a la strategie de notre entreprise.\n\nvotre travail cree de la valeur. vous elaborerez des solutions novatrices et developperez des relations durables avec vos collegues et clients, tout en ayant acces a des capacites mondiales pour concretiser vos idees, saisir de nouvelles opportunites, et beneficier dune expertise sectorielle et technologique de pointe.\n\nvous ferez evoluer votre carriere en vous joignant a une entreprise batie pour croitre et durer. vous serez soutenus par des leaders qui ont votre sante et bien-etre a cur et qui vous permettront de saisir des occasions afin de parfaire vos competences et elargir les horizons.\n\njoignez-vous a nous, lune des plus importantes entreprises de conseil en technologie de linformation (ti) et en management au monde.",
  "company_name": "cgi",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "pyspark",
    "python",
    "aws"
  ],
  "soft_skills": [
    "problem-solving",
    "communication",
    "teamwork"
  ],
  "sector": [],
  "salary_range": null
},
{
  "job_url": "https://www.linkedin.com/jobs/view/chef-de-departement-data-analytics-at-orh-assessment-4188840333",
  "titre": "chef de departement data & analytics",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-19",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "orh assessment, cabinet specialise en recrutement et evaluation, fait partie du groupe lms, leader du conseil rh au maroc. nous aidons les entreprises a trouver les meilleurs talents et les candidats a saisir des opportunites de carriere enrichissantes.\n\n\nnous accompagnons aujourdhui notre client dans la recherche de son/sa futur(e) chef de departement data & analytics\n\n\n vos missions principales\nen tant que chef de departement data & analytics, vous serez en charge de piloter lensemble des activites liees a la collecte, lanalyse et la valorisation des donnees pour optimiser le pricing et la veille concurrentielle.\n\n\n collecte & fiabilisation des donnees\n superviser les strategies de collecte (scraping, releves terrain, partenaires).\n garantir la qualite et lintegration des donnees dans les bases internes.\n collaborer avec les equipes it et data engineering pour fluidifier les flux de donnees.\n analyse & production dinsights\n developper des analyses avancees pour optimiser le pricing et les performances commerciales.\n identifier les tendances de marche et proposer des recommandations strategiques.\n produire des dashboards et reportings interactifs pour le top management.\n gestion des outils & technologies\n superviser et ameliorer les outils bi et analytiques.\n implementer des modeles predictifs et algorithmes pour la prise de decision.\n assurer une veille sur les innovations en data science & analytics.\n management & coordination\n encadrer une equipe de 4 personnes (2 data analysts).\n travailler en transverse avec les equipes pricing, commerciales et it.\n mettre en place des bonnes pratiques en gouvernance et gestion des donnees.\n\n\n votre profil\n\n\n competences techniques :\n outils bi : power bi, tableau, qlik sense, looker\n langages : sql, python (pour automatisation et scraping)\n bases de donnees : bigquery, snowflake, redshift\n methodologies : data scraping, api, automatisation\n\n\n soft skills :\n esprit analytique et vision strategique\n leadership et capacite a federer une equipe\n bonne communication et approche orientee business\n\n\n pourquoi nous rejoindre ?\n\n\n un poste cle dans la strategie pricing et data de lentreprise \n une forte exposition aux directions strategiques et operationnelles \n un environnement stimulant et des defis analytiques a fort impact",
  "company_name": "orh assessment",
  "is_data_profile": true,
  "profile": "data strategist",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "python",
    "power bi"
  ],
  "soft_skills": [
    "communication",
    "leadership",
    "problem-solving"
  ],
  "sector": [
    "recruitment",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-casablanca-at-vivadata-4189983821",
  "titre": "data analyst - casablanca",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-27",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": "morocco",
    "remote": false
  },
  "description": "who we are\n\nartefact is a new generation of data service provider, specialised in data consulting and data-driven digital marketing.\n\nour purpose?\n\nevery day we boost our clients data transformation into business impact across the entire value chain of organisations.\n\nour strength?\n\nour data services stand on double expertise: the combination of artificial intelligence and the business prowess acquired from our customers around the world, such as accorhotels, orange, carrefour, engie, samsung, l'oreal, nissan...\n\nartefacts success comes from a unique mix of company assets: cutting-edge data technologies, agile methodologies for fast delivery, cohesive teams assembling the finest business consultants, data analysts, data scientists, data engineers, and digital marketing experts.\n\nartefact is\n\n 20 offices in paris, london, shanghai, dubai...\n +1300 employees\n 4 practices: data consulting, data marketing, activation and creation\n\n\nwhat you will be doing: key responsibilities\n\nas a senior data analyst, your role will encompass\n\n conducting projects to accompany the transformation of your clients businesses through the effective collection, processing, and visualisation of data\n extracting valuable insights from our clients marketing-related data sources.\n designing dashboards for marketing decision-making while taking into account the business needs\n accompanying our clients in the conception and implementation of data architectures and data pipelines, from collection to monitoring.\n actively contributing to the expertise level and competencies of the data & analytics team\n closely collaborate with the other divisions (media & activation, creation, consulting, data science and data engineer) to provide comprehensive services to your clients\n\n\nbeing a great tech role model\n\n demonstrating the skill and credibility required to ensure the success of our clients initiatives\n researching and developing new technical approaches to address problems efficiently\n staying up-to-date on developments within the industry, sharing best practices and actively contributing to artefacts institutional knowledge\n embodying artefacts values and inspiring others to do the same\n\n\nqualifications: education & experience required\n\n having an academic level of education (bachelor or master), in a data-driven working environment, you have experience or have knowledge in :\n a minimum of 3 year of work experience in a data-driven working environment\n 1 or more data collection (google analytics, adobe analytics, sql database, crm database, transactional data)\n 1 or 2 programming languages among sql, python and/or r.\n 1 or more data visualisation tool (tableau, data studio, dataviz, r / python dataviz libraries, ...)\n\nin addition, you have the knowledge in one or more of the following technologies:\n\n google cloud platform resources (big query, google cloud storage) or its equivalent in azure or aws\n you know how to connect to an api through the knowledge of the different authentication method (oauth, http basic, api key)\n advertising tool, linked to tracking and/or analytics in a marketing context (google analytics, adobe analytics, dmp, dsp, adservers, dv 360...) \n etl tool (airflow, dataiku, dataflow, dataprep...) \n web application (r-shiny, python flask) that you have industrialized\n\n\nideally you have\n\n knowledge of statistics \n knowledge of machine learning and data engineering\n\n\nwhat we are looking for\n\n a doer: you get things done and inspire your team to do the same\n an analyst: you love data and think every company should take their decisions based on facts\n a pragmatist: you have a no-nonsense mindset that seeks for practical and realistic solutions\n a mentor: your clients and colleagues naturally seek you out for advice\n an adventurer: youre an entrepreneur constantly looking for business opportunities\n\n\nwhy you should join us\n\n artefact is the place to be: come and build the future of marketing\n progress: every day offers new challenges and new opportunities to learn\n culture: join the best team you could ever imagine\n entrepreneurship: you will be joining a team of driven entrepreneurs. we wont give up until we make a huge dent in this industry!\n\n\ncome join us!\n\napply now\n\napply for this jobapply for this job\n\nshare this offer\n\nsimilar jobs\n\nconsulting\n\nview more\n\ndata engineering\n\nview more\n\ndata science\n\nview more\n\nteamwork makes the dream works.\n\nartefacts teams are made up of the best experts in their fields, and its our biggest responsibility to ensure their professional development and personal wellbeing.\n\nlearn more",
  "company_name": "vivadata",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "sql",
    "python",
    "tableau"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "consulting",
    "marketing"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/expert-en-intelligence-artificielle-big-data-data-science-at-brome-consulting-technology-4200185538",
  "titre": "expert en  intelligence artificielle, big data, data science",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-03",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": "morocco",
    "remote": false
  },
  "description": "pour le compte de notre client, nous sommes a la recherche d'un expert en intelligence aritificielle, big data, data science ayant les competences suivantes\n\ncgeit, cobit, togaf, bpmn2 foundation ou equivalent,\n\npmp, prince2, cmmi, lean six sigma, apmg lean it ou equivalent,\n\nitil v4, itil osa ou equivalent,\n\nmethodes agiles scrum ou equivalent,\n\nsecurite : iso/ifc 27001, cisa, soc security ou equivalent,\n\ncloud : comptia cloud +, azure data, lead cloud security manager ou equivalent,\n\ndba, data dcfc, cdcp ou equivalent,\n\ncertification en ia, data science, big data,\n\ncertifications en technologies educatives.\n\nformation : bac+5\n\nexperience : 10 ans",
  "company_name": "brome consulting & technology",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 5,
  "experience_years": 10,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "machine learning"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "consulting",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/architecte-data-at-altados-by-niji-4217435103",
  "titre": "architecte data",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-04-25",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "dans le cadre dun nouveau besoin client, altadosbyniji est a la recherche dun architecte data experimente (fonctionnelle ou technique) pour une mission en regie a casablanca.\n\n\n profil recherche :\nnous recherchons un profil senior (10 ans dexperience ou plus), capable d'intervenir sur des problematiques data complexes, avec une vision strategique, une capacite danalyse forte, et une expertise confirmee en architecture.\nle candidat peut avoir une dominante :\n fonctionnelle : gouvernance de la donnee, modelisation, urbanisation, architecture fonctionnelle des flux de donnees, besoins metiers.\n technique : conception des architectures data, mise en place de plateformes, integration et traitement des donnees, performance et securite.\n\n\n competences cles :\n experience confirmee en tant quarchitecte data (fonctionnel ou technique)\n bonne comprehension des enjeux data au sein dun si complexe\n capacite a travailler en lien avec des equipes metiers et techniques\n leadership, autonomie, et sens de la communication\n\n\n localisation :\nmission en regie a casablanca, pour lun de nos clients grands comptes.",
  "company_name": "altados by niji",
  "is_data_profile": true,
  "profile": "data architect",
  "education_level": 3,
  "experience_years": 10,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "data modeling",
    "data governance"
  ],
  "soft_skills": [
    "communication",
    "leadership",
    "problem-solving"
  ],
  "sector": [
    "consulting",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consultant-data-at-effyis-group-4188871632",
  "titre": "consultant data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-19",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "your role : \n\n\ndesign and implementation of data pipelines:\n design and implement data pipelines to collect, transform, and integrate data from various sources (databases, files, apis, etc.).\n develop and design integration solutions for both cloud and on-premise platforms.\n develop and maintain database management systems and data warehouses for efficient data storage and organization.\n collaborate with it teams to ensure the correct application of business rules and compliance with regulations during data collection and transformation.\n identify data needs and enhance the data foundation as part of data projects.\n\ndata quality and system maintenance:\n ensure data quality, integrity, and security by implementing appropriate controls and processes.\n optimize the performance of data systems to meet real-time analysis and reporting needs.\n clearly document processes, methods, and results to facilitate knowledge transfer and replication by others.\n develop and maintain incident recovery plans to ensure constant data availability.\n participate in evaluating and adopting new technologies and tools related to data engineering.\n\nyour team : \n\n\n you will be part of the data lab team at effyis.\n\nyour qualifications : \n\n\n engineering degree with over 3 years of experience in similar projects.\n proficiency in the jira tool and scrum methodology.\n mastery of programming languages such as python, java, scala, or others.\n experience with data processing frameworks like apache spark for complex transformations and managing large datasets.\n experience implementing solutions on cloud platforms such as aws, azure, or google cloud.\n strong communication and organizational skills.\n\nbenefits : \n\n\n health insurance coverage\n additional retirement benefits\n monthly mission bonus\n personalized training path\n\nrecruitment process : \n\n\n hr interview\n technical interview\n courtesy interview",
  "company_name": "effyis group",
  "is_data_profile": true,
  "profile": "data consultant",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "sql",
    "aws"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "consulting",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-scientist-analytics-team-lead-at-manpowergroup-4178293307",
  "titre": "data scientist analytics team lead",
  "via": null,
  "contrat": "contract",
  "type_travail": null,
  "publication_date": "2025-03-12",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "nous recherchons un(e) team lead data scientist pour manager une equipe data science et contribuer activement a lelaboration de solutions innovantes basees sur les donnees. vous serez a la fois un(e) expert(e) technique et un(e) leader inspirant(e), capable dorienter strategiquement les projets de data science tout en manageant une equipe de talents. vous disposez dune expertise avancee en modelisation, gestion et traitement de grandes quantites de donnees, optimisation de bases de donnees ainsi que dune experience de management dequipe dans un environnement agile.\n\n\nleadership et pilotage strategique :\n definir et prioriser les projets de data science en collaboration avec les parties prenantes (produit, engineering, head of ai, business, qara, etc.)\n fixer les objectifs cles pour lequipe, assurer le suivi et garantir leur atteinte dans les delais impartis\n evaluer en collaboration avec les parties prenantes les opportunites strategiques ou la data science peut apporter une valeur ajoutee a lentreprise\n communiquer les resultats et les insights de maniere claire et impactante aux stakeholders\nencadrement et mentorat de lequipe :\n superviser, coacher et faire monter en competence une equipe de data scientists.\n sassurer de la bonne cohesion dequipe\n assurer un leadership technique sur les projets complexes et guider lequipe dans le choix des approches et outils appropries\n favoriser un environnement de travail collaboratif et stimulant qui encourage linnovation et la curiosite intellectuelle\n realiser des evaluations de performance et identifier les opportunites de developpement individuel\ngarantir la qualite et limpact des analyses :\n definir des methodologies rigoureuses pour garantir la fiabilite des modeles et des predictions\n superviser la mise en place dindicateurs cles de performance (kpis) pour mesurer limpact des projets\n veiller au respect des bonnes pratiques en termes de documentation, reproductibilite et transparence\n sassurer de la qualite de nos produits et du respect des procedures reglementaires\n\n\nprofil:\n vous etes diplome(e) en informatique, en ingenierie des donnees ou dans un domaine technique similaire\n vous justifiez de 5 ans ou plus dexperience en data science, dont au moins 2 ans avec des responsabilites manageriales dune equipe comprise entre 3 et 10 collaborateurs\n vous avez deja travaille sur des projets complexes a forte valeur ajoutee en entreprise.\n\n\n\n\ncompetences techniques:\n\n\n competence avancee en programmation (python, go) et bibliotheques associees (scikit-learn, tensorflow, pytorch, etc.)\n maitrise des bonnes pratiques mlops et developpement cloud.\n experience avec les llms et frameworks associes (langchain, transformers).\n solides competences en sql et en manipulation de bases de donnees.\n connaissances en gestion de bdds graph (neo4j).\n bonne connaissance des outils de visualisation (superset).\n excellentes competences en leadership et gestion dequipe\n maitrises des processus et outils de gestion de projets.\n esprit analytique et resolument oriente vers la resolution de problemes\n capacite a travailler efficacement dans des environnements dynamiques et sous pression (gestion dincidents)\n passion pour lapprentissage continu et les nouvelles technologies.\n bonne maitrise de la langue francaise & anglaise.",
  "company_name": "manpowergroup",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "machine learning"
  ],
  "soft_skills": [
    "leadership",
    "communication",
    "problem-solving"
  ],
  "sector": [
    "consulting",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/project-analyst-iv-lead-data-analyst-at-kace-company-4198577290",
  "titre": "project analyst iv / lead data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": null,
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "title: project analyst iv\n\nlocation: washington d.c., morroco\n\nsecurity clearance: must have an active ts/sci clearance or be sci eligible with a ts clearance\n\nschedule: due to the nature of law enforcement work and operation, position may require occasional support outside of core working hours, as well as intermittent weekend support, mission dependent.\n\ntravel: some travel will be required (approximately 30%)\n\n***contingent upon award***\n\nabout kace\n\nwhen you make the decision to join kace, you are choosing to work alongside talented professionals that have one thing in common; the passion to make a difference! kace employees bring their diverse talents and experiences to work on critical projects that help shape the nations safety, security, and quality of life. the desire to have a career that is purposeful and forward thinking is woven into every kace employee...its the kace way. kace employees are; purpose driven, forward focused, open-minded, trustworthy and invested. the kace way is our commitment to our employees, to our customers, and to our communities. join kace and make a difference!\n\njob summary\n\nprogram analyst iv will design and perform (1) advanced data capture strategies and processes using various software applications to facilitate and standardize case tracking; (2) coverts data into databases and reporting/graphical software application and produces insightful trends and reports about case tracking; (3) undertake special studies; (4) develop sophisticated presentations; and (5) serve as a technical expert on federal, state, and local crime and caseload statistics as well as other criminal justice data and policy issues.\n\nessential functions and responsibilities\n\n capture of data and information: uses various software applications to best capture and report on desired data elements and information related to transnational criminal organizations and ocdetf operational accomplishments, including but not limited to cases filed, defendants charged and convicted, trials and outcomes, sentences to imprisonment, monetary sanctions, and estimated reductions in illegal drug activity because of criminal enforcement actions. designs input data collection forms to facilitate and standardize data collection; reviews and assesses new software applications to improve efficiency and functionality of case tracking and reporting activities; converts data for inclusion into databases, spreadsheets, and charting or graphical software presentation programs; designs and produces output reports, summary tables, graphs and charts from database information.\n research and analysis: conduct special studies, research, and evaluation activities to assess and inform managers.\n development of presentations: design and produce powerpoint and other graphics presentations for use by managers\n statistical work: serves as technical expert on federal, state and local crime and caseload statistics, as well as other criminal justice data and policy issues. help senior analysts with quantitative analysis and research methodologies regarding ongoing research studies, data analysis and program evaluations. analyzes and interprets data to identify significant findings and trends using statistical or analytical software programs such as sas, spss, microsoft access, and/or excel.\n\n\nminimum qualifications & skills\n\n bachelor's degree with 8 years' experience or masters degree with 6 years' experience in project management, data analysis, or law enforcement support, preferably in a government or law enforcement setting\n must have an active ts/sci clearance or be sci eligible with a ts clearance\n experience utilizing various types of software, such as government- developed software, microsoft office suite including word, excel, and power point\n experience conducting research and analysis of data, and reporting of results.\n ability to plan and organize work effectively.\n knowledge of statistics and quantitative analysis.\n ability to communicate effectively, both orally and in writing.\n ability to work with individuals and groups at all organizational levels.\n\n\nclearance\n\napplicants selected may be subject to a government background investigation and may be required to meet the following conditions of employment.\n\nsecurity requirements/background investigation requirements\n\n must be a u.s citizen or legal permanent resident.\n favorable credit check for all cleared positions\n successfully passing a background investigation including drug screening.\n\n\nphysical requirements/working conditions\n\n standing/walking/mobility: must have mobility to attend meetings with other managers and employees. standing for prolonged and extended periods of time.\n climbing/stooping/kneeling: 0% - 10% of the time.\n lifting/pulling/pushing: 0% - 10% of the time.\n fingering/grasping/feeling: must be able to write, type and use a telephone system 100% of the time.\n sitting: sitting for prolonged and extended periods of time.\n\n\nthis job description reflects managements assignment of essential functions; it does not prescribe or restrict the tasks that may be assigned. management may revise duties as necessary without updating this job description.\n\nfor more information about the company please visit our website at www.kacecompany.com\n\nkace is an equal opportunity employer and does not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, disability or any other federal, state or local protected class.\n\nkace complies with federal and state disability laws and makes reasonable accommodations for applicants and employees with disabilities.\n\nif you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to recruiting@kacecompany.com.",
  "company_name": "kace company",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 8,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "excel",
    "sas"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [
    "law enforcement",
    "government"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/architecte-data-h-f-at-capgemini-4175864072",
  "titre": "architecte data (h/f)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-08",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "capgemini est un leader mondial, responsable et multiculturel, regroupant 350 000 personnes dans plus de 50 pays. partenaire strategique des entreprises pour la transformation de leurs activites en tirant profit de toute la puissance de la technologie, le groupe est guide au quotidien par sa raison detre : liberer les energies humaines par la technologie pour un avenir inclusif et durable.\nfort de 55 ans dexperience et dune grande expertise des differents secteurs dactivite, capgemini est reconnu par ses clients pour repondre a lensemble de leurs besoins, de la strategie et du design jusquau management des operations, en tirant parti des innovations dans les domaines en perpetuelle evolution du cloud, de la data, de lintelligence artificielle, de la connectivite, des logiciels, de lingenierie digitale et des plateformes. le groupe a realise un chiffre d'affaires de 18 milliards d'euros en 2021.\n\n\nposte :\nintegre(e) au sein d'une equipe projets intervenant pour des clients dans des secteurs d'activites variees, vous serez notamment en charge des missions suivantes :\n vous repondez aux problematiques de nos clients en proposant des solutions big data  on premise  et/ou dans le cloud (ms azure, aws et gcp).\n vous adaptez chaque architecture en fonction du contexte grace a votre maitrise des caracteristiques fondamentales de chaque solution (catalogue des offres de services manages, performance, securite, deploiement des data centers ...).\n vous utilisez les solutions dintegration associees et les solutions decisionnelles ainsi quanalytiques qui viennent consommer les donnees manipulees.\n vous etes en mesure dencadrer les equipes de data engineers dans la mise en place des architectures preconisees et/ ou des plateformes big data.\n vous etes en mesure dappuyer les equipes commerciales dans les reponses aux appels doffres big data.\n\n\nprofil recherche :\n formation bac + 5 en ecole dingenieur ou equivalent universitaire avec une specialisation en data\n a partir de 8 ans dexperience,\n vous etes un(e) passionne(e) de la data et maitrisez aussi bien linux et spark que script shell\n hadoop (cloudera/hortonworks/mapr) n'a pas de secret pour vous mais vous avez pris le virage du cloud (aws, gcp, ms azure ),\n english speaker, because we are french but also international.\n\n\njoin us and rewrite the future !",
  "company_name": "capgemini",
  "is_data_profile": true,
  "profile": "data architect",
  "education_level": 3,
  "experience_years": 8,
  "seniority": "senior",
  "hard_skills": [
    "spark",
    "hadoop",
    "aws"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "consulting",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-senior-gcp-at-alten-4175877443",
  "titre": "data engineer senior gcp",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-08",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": "morocco",
    "remote": false
  },
  "description": "alten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2027.  alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\n\nrejoindre alten maroc cest beneficier :\n\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers.\n des formations certifiantes et diplomantes.\n des evenements reguliers pour combiner bien etre et performance.\n\n\ndescription du poste\n\nintegre(e) dans les equipes supply,  le/la consultant(e) aura pour mission de :\n\n\n concevoir, developper et maintenir des solutions de traitement de donnees massives en utilisant les technologies big data et les outils gcp.\n mettre en place et optimiser les pipelines de donnees, de lanalyse des performances et de lamelioration continue des solutions existantes\n\n\nqualifications\n\ndiplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique, ou justifiant d'une experience significative equivalente\n\n\nexperience : de plus de 7 ans en gcp\n\n\nune experience dans le secteur du commerce de detail ou de la grande distribution serait un plus.\n\n\ncompetences techniques :\n\n\n maitriser les technologies cloud de google cloud platform (gcp) pour la gestion des donnees, lorchestration et le deploiement des solutions big data.\n avoir une expertise approfondie de bigquery et bigtable pour le stockage, la manipulation et lanalyse de donnees a grande echelle.\n maitriser les langages de programmation scala ou java pour le developpement de solutions big data, avec une experience significative dans lun des deux.\n avoir une experience pratique avec lecosysteme hadoop et ses outils associes comme spark et apache kafka pour le traitement distribue de donnees.\n etre capable de concevoir et dimplementer des pipelines de donnees complexes en utilisant des outils comme apache kafka et avro pour la gestion des flux de donnees.\n maitriser les concepts de base de kafka pour la conception et la mise en uvre de systemes de messagerie distribues.\n avoir une bonne comprehension des bases de donnees nosql, notamment cassandra et bigtable, pour le stockage et la recuperation de donnees non structurees.\n avoir une experience avec les moteurs de recherche comme elastic search pour la recherche et lanalyse de donnees textuelles.\n maitriser les outils de ci/cd et les pratiques de developpement logiciel pour lautomatisation du deploiement et de lintegration continue.\n avoir une experience pratique avec les outils de deploiement et dorchestration comme jenkins, gitlab, kubernetes, docker et ansible.\n etre capable de travailler avec docker pour la creation et la gestion des conteneurs dapplications.\ncompetences linguistiques :\n\n\n avoir une excellente communication ecrite et orale, avec la capacite de produire des livrables et des reportings de haute qualite.\nsoft skills :\n\n\n avoir un esprit danalyse et damelioration continue, avec la capacite devaluer le code et ses impacts, ainsi que de remettre en question les solutions existantes pour les ameliorer.\n avoir la capacite de prendre du recul et devaluer les problematiques avec objectivite, en proposant des solutions damelioration.\n avoir un esprit dequipe et la capacite de collaborer efficacement avec les membres de lequipe pour atteindre des objectifs communs.\n maitriser les concepts dagilite (scrum, sprint planning, backlog...).\n\n\ninformations supplementaires\n\nau plaisir de vous lire !",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "cloud data engineer",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "java",
    "gcp",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/stage-data-analyst-%E2%80%93-retail-media-crm-ia-marketing-at-nexaverse-data-4223904868",
  "titre": "stage data analyst  retail media, crm & ia marketing",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-05",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": "morocco",
    "remote": false
  },
  "description": "stage data analyst  retail media, crm & ia marketing casablanca |  4 a 6 mois |  stage remunere une opportunite qui peut deboucher sur un cdi si affinites\ntu veux manipuler de vraies donnees operationnelles, pas juste des poc en sandbox ?tu veux voir comment la data alimente concretement le marketing, les activations media et les campagnes dooh ciblees ?\n on cherche une data analyst junior, capable de structurer un entrepot de donnees marketing et dexploiter des briques dia pour booster la segmentation client et declencher des campagnes plus intelligentes.\n\n\n tes missions :\nstructurer des fichiers bruts (ventes, crm, campagnes digitales, evenements...) dans un data warehouse marketing\ncreer des dashboards dynamiques (power bi, looker) pour les equipes marketing et commerciales\ndevelopper un scoring client (rfm, clustering, etc.) et une segmentation activable\nexperimenter avec des outils ia / ml (automl, gpt, scoring comportemental)\ngenerer des insights exploitables pour les campagnes terrain : semaine du vin bio, festival de la biere, etc.\n\n\n ton profil :\nbac+4/5  ecole dinge, de commerce ou universite avec specialisation data / bi / marketing analytique\na laise avec sql, excel/power query, power bi ou looker\nbonus : notions de python, ia marketing, machine learning\nautonome, structuree, curieuxse, avec un vrai sens business\net surtout, tu sais que la data na de valeur que si elle sert une action\n cv a envoyer a : hicham@nexaversedata.com\n#stagedata #retailmedia #crm #casablanca #marketingia #dataanalytics #iamarketing #stagecasablanca",
  "company_name": "nexaverse data",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "power bi",
    "excel"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "marketing",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-engineer-azure-freelance-at-proorga-consulting-4178482446",
  "titre": "senior data engineer-azure - freelance",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-07",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "notre client, un acteur majeur du secteur de la distribution, recherche un senior data engineer pour renforcer ses equipes data & it. ce role cle vise a assurer la collecte, le traitement et le stockage des donnees de maniere optimale, tout en garantissant la fiabilite et la performance des pipelines de donnees.\n\n\n missions principales\n-concevoir et developper des pipelines de donnees (elt) pour optimiser lextraction, la transformation et le chargement des donnees.\n-mettre en place et gerer des bases de donnees et entrepots de donnees.\n-implementer des architectures et des modeles de stockage performants.\n-automatiser les processus pour ameliorer lefficacite et la productivite.\n-optimiser les performances des pipelines et garantir un traitement efficace des donnees.\n-assurer la securite et la protection des donnees sensibles.\n-collaborer avec les equipes metiers, data scientists, data analysts et developpeurs pour repondre aux besoins des utilisateurs.\n-maintenir, monitorer et documenter les pipelines de donnees developpes.\n-assurer une veille technologique pour integrer les meilleures pratiques du data engineering.\n\n\n competences techniques requises\n-experience : minimum 5 ans dans un role similaire, idealement en environnement azure.\n-langages : maitrise de python et sql.\n-big data : bonne connaissance des outils et frameworks comme hadoop, spark, kafka.\n-pipelines elt : conception et developpement avances.\n-bases de donnees : expertise en bases relationnelles et nosql.\n-performance & securite : optimisation des performances et mise en place de solutions securisees.\n-certifications azure (souhaitees).\n\n\n profil recherche\n-formation : bac+5 en ecole dingenieur, specialisation data.\n-langues : bonne maitrise du francais, anglais et arabe.\n\n\n soft skills\n-capacite danalyse et de resolution de problemes.\n-bonnes competences en communication et collaboration.\n-orientation resultats et gestion efficace du temps.\n-capacite a sadapter aux nouvelles technologies et aux changements.\n-proactivite et volonte dapprentissage continu.",
  "company_name": "proorga consulting",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "hadoop",
    "spark",
    "kafka"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving",
    "adaptability"
  ],
  "sector": [
    "distribution"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-powerautomate-powerapps-at-alten-4206699908",
  "titre": "data engineer powerautomate / powerapps",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-11",
  "location": {
    "city": "fez",
    "region": "fes-meknes",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\nalten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2024. alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\nrejoindre alten maroc cest beneficier :\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers. \n des formations certifiantes et diplomantes. \n des evenements reguliers pour combiner bien etre et performance.\n\n\ndescription du poste\n\nle consultant sera en charge de:\n\n dassurer la maintenance corrective et le support utilisateur a terme. \n une transmission des elements fonctionnels et de contexte doit egalement etre assuree.\n\n\nqualifications\n\nbac+ 5 en informatique ou equivalent avec maximum 4ans d'experience.\n\ncompetences requises\n\n maitrise des fichiers excel avances (formules complexes, tableaux croises, macros de base). \n maitrise vba\n connaissance de powerautomate (flux, declencheurs, connecteurs). \n bonne pratique de powerapps (creation dinterfaces simples, integration de donnees). \n notions solides en sql (lecture, correction de requetes, requetes simples a intermediaires)",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 2,
  "experience_years": 4,
  "seniority": "mid",
  "hard_skills": [
    "excel",
    "vba",
    "powerautomate",
    "powerapps",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-a-p-moller-maersk-4176196302",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-08",
  "location": {
    "city": "tangier",
    "region": "tanger-tetouan-al hoceima",
    "country": null,
    "remote": false
  },
  "description": "apm terminals\n\napm terminals plays an important role in enabling the global maersk ocean and logistics network as well as serving other shipping lines, beneficial cargo owners, freight forwarders, intermodal logistics providers and integrating with a wide variety of local port authorities, customs and government bodies across our global network of transhipment, import and export gateway terminals.\n\nin support of the broader maersk strategy, we are accelerating the transformation of our business from a portfolio of independently operated terminals into a safer, better, bigger global terminals operator.\n\nas a data analyst you must be able to translate information requirements into technical solutions. as part of this role, you will contact colleagues and internal customers effortlessly and thanks to excellent communication skills, you will be able to convey and gather information where needed. you be eager to learn and understand the operational processes and can navigate in a complex organization. you are customer oriented, have proactive attitude and you are a real team player.\n\nwe offer\n\nas part of a.p. moller-maersk, apm terminals leverages more than a century of industry experience to design and build high-quality container terminals, and provide port and inland services for cargo handling and transportation between port facilities and inland locations.\n\nwe are building a world class internal technology organisation focusing on driving ownership, predictability, and agility in our technology. to support our technology vision, we are looking for a bi developer/data analyst to be based in tangier and be part of the regional data & analytics team within hubs.\n\nkey responsibilities:\n\n formulate techniques for quality data collection to ensure accuracy and legitimacy of data\n create weekly and monthly dashboards as required by various categories\n conduct regular meetings with team members and business stakeholders on data & analytics request\n work on data ingestion, transformation and presentation of insights\n troubleshoot data-related problems (incidents)\n timely production and maintenance of reports\n work on migrating local bi solutions to the new global data foundation (terminal data lake)\n\n\nwho we are looking for:\n\nour employees represent a wide range of educational backgrounds, work experience and nationalities - most important to us is your personal skills. you must thrive in a fast paced, fast changing and dynamic environment and be a true team player with strong analytical abilities and interpersonal, and communication skills. the ideal candidate would look like the below:\n\n at least a bachelor or masters degree\n data warehousing principles and theory\n backend and frontend developing skills in ms stack (ssms, ssis, ssas, ssrs, powerbi)\n cloud based ms skills (data factory, databricks) + programming languages like python and sql\n eagerness working on both backend and the frontend\n ability to quickly find your way in etl structures and complex business logic\n agile scrum. strong communication. cooperative teamworker\n experience of cooperating closely with the business\n you are located and have full working rights in the morocco\n\n\nmaersk is committed to a diverse and inclusive workplace, and we embrace different styles of thinking. maersk is an equal opportunities employer and welcomes applicants without regard to race, colour, gender, sex, age, religion, creed, national origin, ancestry, citizenship, marital status, sexual orientation, physical or mental disability, medical condition, pregnancy or parental leave, veteran status, gender identity, genetic information, or any other characteristic protected by applicable law. we will consider qualified applicants with criminal histories in a manner consistent with all legal requirements.\n\nwe are happy to support your need for any adjustments during the application and hiring process. if you need special assistance or an accommodation to use our website, apply for a position, or to perform a job, please contact us by emailing accommodationrequests@maersk.com.",
  "company_name": "a.p. moller - maersk",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 2,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "python",
    "powerbi",
    "ssis",
    "ssas"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving",
    "customer-oriented"
  ],
  "sector": [
    "logistics"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-experimente-at-alten-4183931311",
  "titre": "data engineer experimente",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-23",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "alten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2200 consultants et vise un centre dexcellence de 3300 consultants alteniens en fin 2027. avec plus de 90 recrutements par mois, alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\nrejoindre alten maroc c'est beneficier :\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers.\n des formations certifiantes et diplomantes.\n des evenements reguliers pour combiner bien etre et performance.\n\n\njob description\n\nintegre(e) dans les equipes plateforme data le/la consultant(e) aura pour mission de :\n\n concevoir, developper et maintenir des solutions de traitement de donnees a grande echelle, en utilisant des technologies telles que bigquery, bigtable, apache kafka et apache spark.\n collaborer avec les equipes de developpement et de production afin de garantir la qualite et la performance des solutions mises en place.\n\n\nqualifications\n\ndiplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique, ou justifiant d'une experience significative equivalente\n\nexperience de 3 a 7 ans en scala / kafka\n\ncompetences techniques et fonctionnelles :\n\n solide experience en developpement avec des langages comme scala et/ou java, \n apache kafka, et frameworks de traitement de donnees distribuees comme apache spark.\n experience sur des technologies de developpement cloud, notamment gcp (google cloud platform), en particulier les services tels que cloud storage, bigquery, dataproc, kubernetes.\n experience pratique avec des outils de gestion de versions comme git, ainsi qu'une comprehension des pipelines ci/cd\n connaissance approfondie des concepts d'architecture microservices et des bonnes pratiques de developpement devops.\n experience dans l'ecriture de tests unitaires et d'integration pour garantir la qualite du code.\n excellente communication ecrite et orale \n esprit d'analyse et d'amelioration continue : capacite a evaluer le code et ses impacts, ainsi qu'a remettre en question les solutions existantes pour les ameliorer.\n capacite de prise de recul \n esprit d'equipe\n\n\nadditional information\n\nvous etes rigoureux, creatif, curieux et vous aimez travailler en equipe et monter en competence dans un environnement dynamique, les metiers du service vous animent et vous souhaitez evoluer dans un environnement convivial, rejoignez-nous !\n\nau plaisir de vous lire!",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "scala",
    "java",
    "kafka",
    "spark",
    "gcp"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/controleur-de-gestion-data-manager-production-at-duroc-4190904169",
  "titre": "controleur de gestion - data manager production",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-27",
  "location": {
    "city": "agadir",
    "region": "souss-massa",
    "country": null,
    "remote": false
  },
  "description": "mission :\n\n suivi budgetaire de la main duvre et la consommation des intrants\n animation des kpi production ( mo, consommations des instants, tonnage ....)\n elaboration et suivi de la performance financiere par domaine, par zone\n participation a divers projets operationnel incluant lelaboration de nouveaux tableaux de bord\n proposition des recommandations operationnelle pour ameliorer la performance\n elaboration des forecast\n digitalisation des reporting sous pbi\n\n\nprofil recherche :\n\n formation : bac+5 cg / gfc\n experiences : 3 a 5 ans dans un poste similaire\n bonne maitrise d'excel et pbi",
  "company_name": "duroc",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "excel",
    "powerbi",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-snowflake-mid-level-at-lumenalta-4228070569",
  "titre": "data engineer - snowflake - mid level",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-11",
  "location": {
    "city": null,
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "experience remote done right. with over 20 years of remote experience, our 500+ team members are 100% remote, and we continue to cultivate vibrant relationships and provide exceptional opportunities for career growth while working with stellar clients on ambitious projects.\n\n\nwhat we're working on:\nenterprise companies turn to us to help them launch innovative digital products that interact with hundreds of millions of customers, transactions, and data points. the challenges we solve daily are real and require creativity, grit, and determination. we are building a culture that challenges norms while fostering experimentation and personal growth. to grasp the scale of the problems we face, ideally, you have some exposure to logistics, fintech, transportation, insurance, media, or other complex multifactor industries.\n\n\nrequirements\n 3+ years experience in a senior developer role using python; ideally, you have delivered business-critical software to large enterprises\n you are comfortable manipulating large data sets and handling raw sql\n experience using technologies such as snowflake, aws, and etl pipelines is essential.\n have extensive experience with data warehousing and working with scalability of large volumes of structured data\n financial services industry experience preferred\n english fluency, verbal and written\n personality traits: professional, problem solver, proactive, passionate, team player.\n\n\nwhy lumenalta is an amazing place to work at\nat lumenalta, you can expect that you will:\n be 100% dedicated to one project at a time so that you can innovate and grow.\n be a part of a team of talented and friendly senior-level developers.\n work on projects that allow you to use leading tech.\n\n\nthe result? we produce meaningful outcomes for our clients that break barriers in their industries.\n\n\nthe job is 100% remote; please ensure you have a comfortable office set at your desired work location.\n\n\nlumenalta is committed to hiring exceptional talent from a wide variety of diverse backgrounds. if you share our values and enthusiasm for digital transformation, we encourage you to apply\n\n\nwhat's it like to work at lumenalta?",
  "company_name": "lumenalta",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": null,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "sql",
    "snowflake",
    "aws",
    "etl"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "fintech"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-alten-4225748153",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "fez",
    "region": "fes-meknes",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\nalten maroc filiale du leader mondial de lingenierie et du conseil en technologies (ict), avec 46 000 collaborateurs au monde avec plus de 1500 au maroc repartis sur quatre centres dexcellence a fes, rabat, casa et tetouan nous accompagnons nos clients en offrant des solutions dingenierie agiles et novatrices pour les grands donneurs dordre mondiaux dans les secteurs de lautomobile, laeronautique, les reseaux & telecoms, software & outils.\n\nrejoindre alten maroc cest beneficier :\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers. \n des formations certifiantes et diplomantes. \n des evenements reguliers pour combiner bien etre et performance.\n\n\ndescription du poste\n\nnous recherchons un(e) data analyst junior passionne(e) pour rejoindre notre equipe. il/elle sera responsable de :\n\n conception et deploiement des systemes d'ia\n modelisation avancee pour resoudre des problemes complexes\n realisation des recettes des evolutions des outils\n developpement des notebooks en utilisant spark python\n test et validation de non-regression des donnees dessais de roulage\n support et animation de la resolution des incidents\n suivi des incidents aupres de la direction des systemes dinformation\n\n\nqualifications\n\ncompetences requises:\n\n maitrise du langage python\n bon niveau en francais et en anglais (parler & ecrit)\n maitrise de spark python\n maitrise de jupyter\n maitrise des algorithmes ml et dl\n conception et developpementd'infrastructure necessaire pour prendre en charge les projets d'ia,en utilisant les dernieres technologies et outils\n connaissance en git/github\n connaissance de bases de donnees structurees (oracle, mysql, sql server...)\n connaissance en hadoop\n habilite a acquerir de nouvelles connaissances\n\n\ncompetences appreciees:\n\n esprit de synthese\n analyse critique\n rigueur\n gestion relation clientele (communication, serviabilite, ecoute active)\n connaissance en culture automobile\n\n\ninformations supplementaires\n\nvous etes rigoureux, creatif, curieux et vous aimez travailler en equipe et monter en competence dans un environnement dynamique. les metiers du service vous animent et vous souhaitez evoluer dans un environnement convivial, rejoignez-nous !",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": null,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "spark",
    "sql",
    "hadoop",
    "jupyter"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "automotive"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-alten-4221579320",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-06",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "alten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2300 consultants et vise un centre dexcellence de 3100 consultants alteniens en fin 2024. avec plus de 90 recrutements par mois, alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\n\nrejoindre alten maroc c'est beneficier :\n\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers.\n des formations certifiantes et diplomantes.\n des evenements reguliers pour combiner bien etre et performance.\n\n\njob description\n\nnous travaillons avec les equipes business, product management et design pour concevoir des outils ergonomiques et fiables. nous recherchons un data analyst  passionne ayant une 1ere experience en analyse de donnees complexes. vous aurez comme missions :\n\n\n developper des dashboards interactifs et dynamiques sous looker et looker studio.\n identifier et suivre des kpis critiques pour le pilotage des activites metiers.\n concevoir des pipelines de donnees optimises dans bigquery.\n\n\n\n assurer la qualite et la fiabilite des donnees pour garantir la coherence des analyses. exploration et extraction des donnees :\n rediger et optimiser des requetes sql complexes sur bigquery.\n automatiser les traitements analytiques pour ameliorer les performances.\n\n\nqualifications\n\ndiplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique. experience de 1 a 3 ans dans un poste simialire.\n\n\nune experience dans le secteur du commerce de detail ou de la grande distribution serait un plus.\n\n\nmust have :\n\n\n experience en bases de donnees sql / nosql (dbt, postgresql, mongodb...)\n bonne maitrise de sql et experience dun an avec bigquery.\n bonne maitrise dans la creation et loptimisation de dashboards sous looker studio (experience > 1 an)\n excellente communication ecrite et orale.\nnice to have :\n\n\n python\n experience en methodologie agile (scrum, sprint planning, backlog...).\n gestion des versions et ci/cd avec gitlab ci\n\n\nadditional information\n\nvous etes rigoureux, creatif, curieux et vous aimez travailler en equipe et monter en competence dans un environnement dynamique, les metiers du service vous animent et vous souhaitez evoluer dans un environnement convivial, rejoignez-nous !\n\n\nau plaisir de vous lire!",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 3,
  "seniority": "mid",
  "hard_skills": [
    "sql",
    "bigquery",
    "looker studio",
    "python"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "retail"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cbs-postdoctoral-position-artificial-intelligence-applied-to-multi-omics-data-integration-at-um6p-university-mohammed-vi-polytechnic-4221955981",
  "titre": "cbs - postdoctoral position: artificial intelligence applied to multi-omics data integration",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": null,
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position overview\n\nwe are seeking an outstanding postdoctoral researcher in artificial intelligence (ai) and data science with expertise in multi-omics data integration for health and precision medicine. the successful candidate will join a multidisciplinary team developing ai-driven approaches to integrate and analyze genomics, transcriptomics, proteomics, metabolomics, and microbiome datasets to uncover biomarkers, therapeutic targets, and mechanistic insights into complex diseases.\n\nthe project addresses critical challenges in personalized medicine, disease stratification, and multi-modal data fusion, enabling next-generation solutions in precision health and biomedical research.\n\nscientific challenges addressed in the position\n\n heterogeneity and high dimensionality of multi-omics data requiring advanced ai/ml methods for robust analysis and integration.\n data sparsity, batch effects, and missing values across different omics layers and platforms.\n cross-omics data fusion and representation learning for comprehensive systems biology modeling.\n identification of causal relationships and biomarker discovery through integrative approaches.\n time-series and longitudinal multi-omics data analysis for disease progression modeling.\n explainability and interpretability of ai models to support clinical decision-making and regulatory compliance in healthcare settings.\n scalability and computational efficiency in processing and integrating massive multi-omics datasets from clinical cohorts.\n\n\nkey responsibilities\n\n design and implement ai/ml pipelines for multi-omics data integration, including supervised and unsupervised learning methods.\n develop deep learning architectures (e.g., variational autoencoders, graph neural networks, transformers) for cross-omics data representation and feature extraction.\n apply multi-view learning, transfer learning, and data fusion techniques to integrate heterogeneous omics datasets and clinical metadata.\n conduct network-based analysis (gene regulatory networks, protein-protein interaction networks, metabolic networks) to identify key disease drivers and biomarkers.\n build predictive models for disease classification, patient stratification, and treatment response prediction.\n collaborate with biologists, clinicians, and bioinformaticians for data interpretation and validation of computational findings in clinical or experimental settings.\n disseminate research outcomes through publications in high-impact journals, conference presentations, and workshops.\n mentor and support the training of graduate students and early-career researchers in ai and multi-omics integration.\n\n\nrequired qualifications\n\n ph.d. in bioinformatics, computational biology, data science, artificial intelligence, or a related field.\n proven experience in multi-omics data integration, omics data analysis (genomics, transcriptomics, proteomics, metabolomics, microbiome).\n strong expertise in machine learning, deep learning, and advanced ai frameworks (tensorflow, pytorch, scikit-learn). experience with bioinformatics tools and databases (e.g., bioconductor, galaxy, kegg, reactome, string).\n proficiency in python, r, and unix/linux-based environments for high-performance data analysis. knowledge of biological network inference, causal modeling, and graph-based ai approaches.\n experience in multi-modal data fusion, representation learning, and heterogeneous data integration.\n strong publication record in relevant peer-reviewed journals.\n excellent communication skills and ability to work in a multidisciplinary environment.\n familiarity with cloud-based computing platforms (aws, azure, google cloud) and high-performance computing (hpc) environments.\n understanding of data privacy, security, and ethical considerations in handling clinical data.\n\n\napplication process\n\ninterested candidates should submit the following documents in a single pdf:\n\n a cover letter outlining their research interests, motivation, and relevant experience.\n a detailed curriculum vitae (cv) with a list of publications.\n contact details of two academic referees.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "research scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "r",
    "tensorflow",
    "pytorch",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "research"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-at-effyis-group-4212151642",
  "titre": "data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-17",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "votre mission :\nrejoignez le data lab deffyis et integrez une equipe jeune, innovante et multidisciplinaire. vous participerez a la conception et a la mise en uvre de solutions data de pointe dans un environnement agile et collaboratif. laissez libre cours a votre curiosite, experimentez avec des technologies de demain et apprenez aux cotes de professionnels passionnes.\n________________________________________\nvos missions au quotidien :\n\tinnovation data & pipelines modernes :\no\tcontribuer a la mise en place et loptimisation de pipelines modernes pour collecter, transformer et integrer des donnees issues de sources variees (bases de donnees, fichiers, apis...).\no\texperimenter avec des solutions cloud et on-premise pour ameliorer larchitecture data.\no\tparticiper a la conception et a la maintenance de data warehouses agiles.\n\tqualite et fiabilite des donnees :\no\tmettre en uvre des controles pour garantir la qualite, la securite et lintegrite des donnees.\no\tcollaborer avec lequipe pour optimiser les performances et assurer lacces en temps reel aux analyses.\n\tdecouverte des techs de demain :\no\tplonger dans des outils de data engineering : apache nifi, apache spark, dagster/airflow, dbt, sql.\no\texplorer lunivers mlops avec mlflow, hugging face, evidently, weight & biases pour ameliorer le cycle de vie des modeles de machine learning.\no\texperimenter avec des frameworks ml innovants (scikit-learn, transformers, setfit, llama/deepseek/qwq,        gpt-4/gemini/claude, hfrl, mcp).\no\tla maitrise de toutes ces technologies nest pas requise : votre curiosite et votre capacite dapprentissage sont nos plus grands atouts.\n________________________________________\nvotre profil :\n\tformation & experience :\no\tdiplome en informatique, ingenierie, mathematiques ou formation equivalente, ou etudiant(e) en fin de cursus avec des stages/projets pertinents (0 a 2 ans dexperience). une formation post-classes preparatoires constitue un atout apprecie.\n\n\n\tskills techniques :\n\tbase solide en algorithmic programing (python java)\n\tbase solide en software engineering (linux, bash, public cloud aws, azure)\n\tbase fondamentale ml (classic, static, nn, generative)\n\tsoft skills :\no\tdynamisme, esprit dequipe et curiosite.\no\tautonomie et capacite a sadapter dans un environnement en perpetuelle evolution.\no\tsens de la communication et envie de partager vos idees.\n________________________________________\nce que nous offrons :\n\tavantages concrets :\no\tcouverture sante complete\no\tdispositifs de retraite complementaires\no\tbonus mensuel de mission\n\tdeveloppement et formations :\no\tun parcours de formation personnalise pour accelerer votre montee en competences.\no\tdes opportunites de participation a des projets innovants et impactants.\n\tculture dentreprise & environnement :\no\tun cadre de travail flexible, moderne et collaboratif.\no\tune equipe ouverte, qui valorise la prise dinitiative et lesprit dinnovation.\n________________________________________\nprocessus de recrutement :\n\thr interview\n\ttechnical interview\n\tcourtesy interview",
  "company_name": "effyis group",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 2,
  "experience_years": 2,
  "seniority": "mid",
  "hard_skills": [
    "python",
    "java",
    "sql",
    "apache nifi",
    "apache spark"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "adaptability"
  ],
  "sector": [],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/ingenieur-data-at-wexus-consulting-4172396508",
  "titre": "ingenieur data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-07",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "nous recherchons un ingenieur data etl pour concevoir, developper et optimiser les pipelines de donnees et les api.\n\nmissions :\n\n developper et maintenir des pipelines etl robustes pour assurer lintegrite et la qualite des donnees. \n concevoir et integrer des api pour faciliter lacces aux donnees et ameliorer l'interoperabilite des systemes. \n optimiser les performances des traitements etl et api en identifiant les points de blocage et en ameliorant les requetes. \n assurer la validation et la qualite des donnees via des controles et des mecanismes daudit. \n collaborer avec les equipes metier et data pour repondre aux besoins danalyse et de reporting.\n\n\nprofil\n\nprofil recherche :\n\n bac+5 en informatique, genie logiciel ou domaine connexe. \n 2 ans dexperience en developpement etl (talend, informatica, apache nifi, etc.) et api. \n experience en conception et developpement dapi (rest, graphql). \n maitrise de sql, des bases de donnees relationnelles et des langages comme python, java ou scala. \n experience avec les environnements cloud (aws, azure, gcp) appreciee. \n forte capacite analytique et esprit collaboratif.\n\n\ninformations contractuelles",
  "company_name": "wexus consulting",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "sql",
    "etl"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "analytical skills"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-governance-officer-at-klanik-4200386112",
  "titre": "data governance officer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "we are currently looking for a talented data governance officer our team in abu dhabi !!!\n\n\n\n\nresponsabilities:\n\n\n\n\n develop and implement a data governance framework and strategy that aligns with organizational goals and objectives.\n develop and maintain a data governance roadmap that outlines the implementation of the data governance framework and strategy over time.\n identify improvements through data redundancy and appropriate data reuse. in addition, continually assess and identify risks in line with the masdar risk management approach, ensuring they are mitigated and accounted for work within the data governance program.\n monitor and report on the quality of the organization's data, identify data quality issues, and develop solutions to address them.\n ensure implementation of the data governance program and ensure its alignment with the overall ict security and governance objectives, strategy and plans.\n perform data protection impact assessments that enable the organization identify and reduce privacy risks.\n support on the process and documentation for incident escalation, performing incident investigation and closure, and ensuring proper reporting.\n conduct company-wide data classification assessment and security audits and contribute to remediation plans.\n perform daily operations and activities related to security and governance in order to ensure the smooth flow of daily activities with minimal interruption to it services and users.\n ensure that data governance policies and procedures comply with relevant legal and regulatory requirements, such as uae personal data protection law, gdpr, etc.\n build and maintain a detailed audit of masdars core systems and information assets that are held in these systems, as well as the teams and processes that use them.\n assist in monitoring compliance with data governance procedures and policies and report deviations to the management.\n contribute to audits related to data governance issues and ensure that audit findings are closed timely thus safeguarding masdars best interests.\n build and maintain a network of relevant contacts to support daily activities and the long-term objectives of the team.\n engage with and monitor relationships with internal and external stakeholders in order to ensure adequate knowledge transfer and completion of services as per agreed parameters\n develop and maintain a data governance roadmap that outlines the implementation of the data governance framework and strategy over time.\n collaborate with internal and external stakeholders to develop data usage policies and procedures that ensure data is used appropriately and ethically.\n apply consistent approaches/discipline and standardized practices in line with relevant policies, processes, and procedures.\n ensure that data governance policies and procedures comply with relevant legal and regulatory requirements.\n\n\nexperience \n\n\n4 to 5 years of experience in data governance/protection\n\n\n\n\nyou are looking for a great opportunity to be part of an amazing challenge, with great development possibilities ? this job is for you !\n\n\nabout klanik:\n\n\nklanik is an it consulting company providing solutions to some of the worlds largest industrial and services groups for 10 years.\nwe support our clients with the creation and development of their new products and services around 4 main business lines:\n information technology and systems (it & is)\n devops and cloud\n big data and ai\n cybersecurity\n\n\nklanik is a community of +500 passionate experts empowering clients in 6 countries throughout europe, middle east and the americas.\nour team is dedicated to offer our global clients project support while guaranteeing a consistent level of service alongside a commitment to excellence and strong core values.\nwere always looking for smart, talented, driven, down-to-earth, fun-to-work-with people who want to make a positive and meaningful impact!\n\n\n\n\nbeing a klanik\nthat means being an out of the box thinker, a precursor who is keen to create, innovate and collaborate in an environment where you can enjoy being yourself and valued for your ideas. its being part of a community of experts that have a passion for and stay abreast of the latest technologies.\nyou feel like a technology pioneer, full of creative ideas, supported by a strong know how and expertise in the latest technologies? we believe you could be a good fit to our culture!\n\n\n\n\nour culture is our pride\nat klanik, we believe that we are stronger together than we are alone. trust, ethics, respect and transparency are deeply fixed in our culture, alongside with the pride in a job well done.\nour community motto is that people give the best of them when they feel listened, respected and empowered to develop themselves. therefore the better we treat our people, the bigger the success they will achieve. we apply those values on day to day basis among our teams, with our clients and even with our competitors.\nbeing part of the klanik community means relying on each others, learning from each others and growing all together. our community fosters creativity, innovation and development within our teams to tackle more and more complex challenges and deliver the best solutions to our clients.",
  "company_name": "klanik",
  "is_data_profile": true,
  "profile": "data governance analyst",
  "education_level": null,
  "experience_years": 4,
  "seniority": "senior",
  "hard_skills": [
    "data governance",
    "data protection",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-devoteam-4183360252",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-17",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\n\nchez devoteam, nous sommes des  digital transformakers . le respect, la franchise et la passion animent chaque jour notre tribu.\n\nensemble, nous aidons nos clients a remporter la bataille du digital : du conseil a la mise en uvre de technologies innovantes, jusqua ladoption des usages.\n\ncloud, cybersecurity, data, devops, fullstack dev, low code, rpa nont plus aucun secret pour notre tribu !\n\nnos 10 000+ collaborateurs sont certifies, formes et accompagnes au quotidien pour relever de nouveaux challenges innovants.\n\nleader du cloud, de la cybersecurite et de la data en emea, le groupe devoteam a realise en 2022 un chiffre daffaires de 1,036 milliard deuros et se donne pour ambition de le doubler dans les 5 annees a venir.\n\ndevoteam maroc, acteur de reference dans les expertises it depuis plus de 30 ans  (350+ consultants) accelere sa croissance en developpant ses activites dexpertise en nearshore pour repondre aux besoins de nos clients francais, europeens et moyen orientaux.\n\nes-tu pret(e) a nous rejoindre et relever ensemble ce defi ?\n\n\ndescription du poste\n\n\n\n\nle/la consultant(e) aura pour mission de participer a la conception, au developpement et a la maintenance de solutions d'analyse de donnees. il/elle sera amene(e) a travailler sur des projets d'analyse de donnees pour ameliorer les performances et l'efficacite des operations de l'entreprise.\n\n\n\nla digital factory marchandise & commerciale a pour objectif de digitaliser les activites commerciales et de marchandises dans le but de simplifier, d'harmoniser et d'automatiser les processus operationnels de l'entreprise. nous travaillons avec les equipes business, product management et design pour concevoir des outils ergonomiques et fiables.\n\nnous recherchons un data analyst senior passionne et experimente dans l'analyse de donnees complexes. vous serez responsable de la collecte, du traitement, de l'analyse et de la visualisation des donnees pour fournir des insights strategiques. vous jouerez un role cle dans la prise de decision en collaborant etroitement avec des equipes metier, des developpeurs et des data engineers.\n\nanalyse et visualisation de donnees :\n developper des dashboards interactifs et dynamiques sous lokker et  looker studio.\n identifier et suivre des kpis critiques pour le pilotage des activites metiers.\n\n\n\nmodelisation et preparation des donnees :\n concevoir des pipelines de donnees optimises dans bigquery.\n assurer la qualite et la fiabilite des donnees pour garantir la coherence des analyses.\n\n\n\nexploration et extraction des donnees :\n rediger et optimiser des requetes sql complexes sur bigquery.\n automatiser les traitements analytiques pour ameliorer les performances.\n\n\n\nsupport et collaboration :\n travailler en etroite collaboration avec les equipes metier des differents pays du groupe carrefour pour comprendre leurs besoins analytiques.\n former et accompagner les utilisateurs dans l'utilisation des dashboards et des outils danalyse.\n\n\n\n\n\n competences professionnelles.\n bonne maitrise des bases de donnees sql / nosql (dbl, postgresql, mongodb...)\n excellente maitrise de sql et experience avec bigquery.\n expertise dans la creation et loptimisation de dashboards sous looker studio.\n excellente communication ecrite et orale : aptitude a produire des livrables et des reportings de haute qualite.\n expertise en python (pandas, numpy, pyspark...)\n esprit d'analyse et d'amelioration continue : capacite a evaluer le code et ses impacts, ainsi qu'a remettre en question les solutions existantes pour les ameliorer.\n comprehension des principes devops et cloud (aws, gcp, azure)\n connaissance des architectures data modernes (data lake, data warehouse)\n capacite de prise de recul : aptitude a evaluer les problematiques avec objectivite et a proposer des solutions d'amelioration.\n esprit d'equipe : capacite a collaborer efficacement avec les membres de l'equipe pour atteindre des objectifs communs.\n maitrise des concepts dagilite (scrum, sprint planning, backlog...).\n capacite a travailler de maniere autonome et a gerer son temps efficacement.\n gestion des versions et ci/cd avec gitlab ci\n\n\n\n\n\n\n\n\nqualifications\n\n\nprofil recherche.\n\n\n diplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique, ou justifiant d'une experience significative equivalente\n experience de plus de 5 ans en sql\n experience avec dbt, looker, looker studio et outils bi similaires\n une experience dans le secteur du commerce de detail ou de la grande distribution serait un plus.\n\n\n\n\n\n\ninformations supplementaires\n\n  https://www.linkedin.com/company/devoteam\n https://twitter.com/devoteam\n https://www.facebook.com/devoteam",
  "company_name": "devoteam",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "python",
    "bigquery"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cus-postdoctoral-researcher-in-spatial-data-science-at-um6p-university-mohammed-vi-polytechnic-4228204772",
  "titre": "cus - postdoctoral researcher in spatial data science",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-12",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position description\n\nwe are seeking a postdoctoral researcher specializing in urban modeling and cost analysis to develop an innovative model to estimate the direct and indirect costs of urbanization based on urban morphology (compact or sprawling). the candidate will analyze real case studies, integrate variables related to infrastructure, health, and the environment, and simulate scenarios under different climatic and social contexts to provide decision-making tools for sustainable urban planning.\n\nmain tasks and responsibilities\n\n develop a predictive model integrating the direct and indirect costs of urbanization.\n calibrate this model using real data from specific case studies.\n simulate urbanization costs based on various climatic, morphological, and social scenarios.\n formulate innovative methodological approaches.\n produce publications on research in scientific journals.\n participate in teaching activities.\n develop new research proposals.\n\n\nrequired qualifications\n\n ph.d. in data science, urban planning, urban economics, or a related field.\n experience in research projects applied to urban, environmental, or socio-economic issues.\n proficiency in urban modeling tools such as matlab, python (especially libraries like pandas, numpy, scipy, geopandas, etc.), and r.\n advanced skills in predictive modeling and machine learning, particularly for multi-variable simulations.\n knowledge of complex systems modeling applied to urban dynamics.\n publications in scientific journals.\n\n\npersonal and organizational qualifications\n\n ability to develop innovative methods.\n ambition for research excellence.\n interest in african issues.\n entrepreneurial mindset, dynamism, and organizational skills.\n fluency in both french and english (oral and written) is required.\n\n\nwe offer\n\n excellent working conditions and competitive salary on an international scale.\n an opportunity to contribute to the development of research excellence in africa.\n a highly stimulating multicultural working environment and a great team atmosphere.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "geospatial data scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "matlab",
    "r"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "research",
    "education"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-senior-at-alten-4225359988",
  "titre": "data engineer senior",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-11",
  "location": {
    "city": "rabat",
    "region": "rabat-sale-kenitra",
    "country": null,
    "remote": false
  },
  "description": "description de l'entreprise\n\nalten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2200 consultants et vise un centre dexcellence de 3300 consultants alteniens en fin 2027. alten maroc est desormais un acteur majeur de linsertion professionnelle des ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\nrejoindre alten maroc cest beneficier :\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers. \n des formations certifiantes et diplomantes. \n des evenements reguliers pour combiner bien etre et performance\n\n\ndescription du poste\n\nintegre(e) dans les equipes data, le/la consultant(e) aura pour mission de contribuer a des projets data en apportant son expertise autour des etl bigloader  bigquery - bdi/dbt. prise en compte des nouvelles demandes devolution et/ou des corrections provenant dincidents ou danomalies.\n\nqualifications\n\n diplome(e) dun bac+5 en ecole d'ingenieur ou equivalent universitaire avec une specialisation en informatique, ou justifiant d'une experience significative equivalente\n experience de plus de 7 ans en data engineering\n\n\nmust have:\n\n sql avance, nosql, bigquery et bigtable\n dbt et orchestration pipeline de donnees\n gcp (google cloud platform)\n maitrise dun langage de programmation (java, scala ou python)\n excellente communication ecrite et orale\n\n\nnice to have:\n\n experiences sur des outils tels que kafka et spark\n connaissance des moteurs de recherche tels que elasticsearch\n experience sur de lagilite",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 7,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "bigquery",
    "dbt"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-databricks-tech-lead-at-lumenalta-4228072092",
  "titre": "data engineer - databricks - tech lead",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-11",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": true
  },
  "description": "experience remote done right. with over 20 years of remote experience, all 500+ staff are 100% remote, and we still grow vibrant relationships and provide exceptional opportunities for career growth while working with stellar clients on ambitious projects.\n\n\nwhat we're working on:\nenterprise companies turn to us to help them launch innovative digital products that interact with hundreds of millions of customers, transactions and data points. the problems we solve daily are real and require creativity, grit and determination. we are building a culture that challenges norms while fostering experimentation and personal growth. to grasp the scale of problems we face, ideally, you have some exposure to logistics, fintech, transportation, insurance, media or other complex multifactor industries.\n\n\nrequirements\n 10+ years experience in a senior developer role using python; ideally, you have delivered business-critical software to large enterprises\n you are comfortable manipulating large data sets and handling raw sql\n experience using technologies such as pyspark/aws/databricks is essential\n experience creating etl pipeline from scratch\n experience leading teams and managing projects\n e-commerce and financial services industry experience preferred\n english fluency, verbal and written\n experience dealing with c-suite level stakeholders\n personality traits: professional, problem solver, proactive, passionate, team orientated.\n\n\nwhy lumenalta is an amazing place to work at\nat lumenalta, you can expect that you will:\n be 100% dedicated to one project at a time so that you can innovate and grow.\n be a part of a team of talented and friendly senior-level developers.\n work on projects that allow you to use leading tech.\n\n\nthe result? we produce meaningful outcomes for our clients that break barriers in their industries.\n\n\nthe job is 100% remote; please ensure you have a comfortable office set at your desired work location.\n\n\nlumenalta is committed to hiring exceptional talent from a wide variety of diverse backgrounds. if you share our values and enthusiasm for digital transformation, we encourage you to apply\n\n\nwhat's it like to work at lumenalta?",
  "company_name": "lumenalta",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": null,
  "experience_years": 10,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "databricks"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "leadership"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-f-h-at-axa-assurance-maroc-4226147613",
  "titre": "data engineer f/h",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-08",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "axa assurance maroc recrute pour le compte de sa direction transformation / data, analytics & ai un/une data engineer :\n\n\nmissions du poste :\n\n\nle role du data engineer est de soutenir le developpement de la strategie data & bi de la compagnie tout en supportant les collegues et les metiers via conception de datamarts, detudes et de reports interactifs. \n\n\nactivites du poste :\n participer a lelaboration darchitectures cibles pour la collecte, le stockage, le traitement, la visualisation et lanalyse de donnees ;\n developper lensemble des processus dintegration des donnees (etl, elt) ;\n concevoir, developper et deployer des flux de donnees complexes sur des environnements cloud (aws / azure) ;\n participer a la mise en place de plateformes data sur le cloud et au deploiement des outils necessaires pour le traitement et lanalyse des donnees ;\n assurer le suivi de la qualite des donnees collectees et traitees a travers la mise en place de tests automatises ;\n suivre la bonne application des regles de gouvernance des donnees a travers la mise en place doutils dedies ;\n concevoir et deployer les outils necessaires pour la mise a disposition des donnees pour les data scientistes et pour les utilisateurs metiers des donnees...\n\n\nen outre, et de facon non limitative, il peut etre amene a effectuer toute mission a la demande de sa hierarchie, compatible avec sa fonction. \n\n\ncompetences requises :\n expertise sur des technologies cloud data : indispensable sur aws (s3, lambda, redshift, glue, athena...) et idealement sur azure (adls, databricks, data factory, azure ml...) ;\n data engineering (etl/elt) : spark (python, scala, java), airflow, talend, ssis, kafka, hadoop;\n expertise sur une solution de data warehousing/datalake : aws lake formation, teradata, bigquery, redshift, synapse, snowflake, etc. ;\n expertise sur un outil dorchestration de flux : airflow, luigi, etc ;\n connaissance des solutions de bases de donnees sql : cloudera teradata, microsoft sql server, sas base, sap hana ;\n expertise en data vizualisation : powerbi, tableau, qlik ; \n maitrise des outils dintegration et de deploiement continue : jenkins, git, github, gitlab, creation de ci/cd, docker, ansible, kubernetes, etc. ; \n connaissances en machine learning ; \n connaissance des systemes nosql : elasticsearch, hbase, cassandra, redshift ; \n sens de l'organisation et du detail ; \n capacites d'analyse ; \n acceptation du changement, adaptabilite ; \n capacite a innover et proposer ; \n respect de la confidentialite ... \n\n\nprofil recherche :\n\n\n de formation bac+4 ou plus, universite ou ecole dingenieur en data ou bi ;\n experience de minimum 2 ans dans un poste similaire...\n\n\nsi le descriptif correspond a votre profil et motivations professionnelles, merci de nous faire parvenir vos cv.\n\n\npourquoi rejoindre axa assurance maroc ?\n axa est un des leaders de lassurance et de la gestion dactifs a travers le monde.\n nous aidons nos 108 millions de clients a traverser les petites et grandes difficultes de la vie.\n acceder a des opportunites de developpement professionnel et de formation continue pour favoriser votre croissance au sein de notre entreprise et enrichir votre panel de competences.\n evoluer dans une culture d'entreprise basee sur lagilite, la performance individuelle et collective, la collaboration et l'ethique.\n etre collaborateur axa assurance maroc, cest rejoindre un environnement de travail inclusif et diversifie, ou chaque individu est valorise et a la possibilite de s'epanouir.\n tous nos emplois sont ouverts aux personnes en situation dhandicap.",
  "company_name": "axa assurance maroc",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": null,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "aws",
    "spark",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "insurance",
    "finance"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cbs-postdoctoral-position-artificial-intelligence-applied-to-multi-omics-data-integration-at-um6p-university-mohammed-vi-polytechnic-4224860393",
  "titre": "cbs - postdoctoral position: artificial intelligence applied to multi-omics data integration",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position overview\n\nwe are seeking an outstanding postdoctoral researcher in artificial intelligence (ai) and data science with expertise in multi-omics data integration for health and precision medicine. the successful candidate will join a multidisciplinary team developing ai-driven approaches to integrate and analyze genomics, transcriptomics, proteomics, metabolomics, and microbiome datasets to uncover biomarkers, therapeutic targets, and mechanistic insights into complex diseases.\n\nthe project addresses critical challenges in personalized medicine, disease stratification, and multi-modal data fusion, enabling next-generation solutions in precision health and biomedical research.\n\nscientific challenges addressed in the position\n\n heterogeneity and high dimensionality of multi-omics data requiring advanced ai/ml methods for robust analysis and integration.\n data sparsity, batch effects, and missing values across different omics layers and platforms.\n cross-omics data fusion and representation learning for comprehensive systems biology modeling.\n identification of causal relationships and biomarker discovery through integrative approaches.\n time-series and longitudinal multi-omics data analysis for disease progression modeling.\n explainability and interpretability of ai models to support clinical decision-making and regulatory compliance in healthcare settings.\n scalability and computational efficiency in processing and integrating massive multi-omics datasets from clinical cohorts.\n\n\nkey responsibilities\n\n design and implement ai/ml pipelines for multi-omics data integration, including supervised and unsupervised learning methods.\n develop deep learning architectures (e.g., variational autoencoders, graph neural networks, transformers) for cross-omics data representation and feature extraction.\n apply multi-view learning, transfer learning, and data fusion techniques to integrate heterogeneous omics datasets and clinical metadata.\n conduct network-based analysis (gene regulatory networks, protein-protein interaction networks, metabolic networks) to identify key disease drivers and biomarkers.\n build predictive models for disease classification, patient stratification, and treatment response prediction.\n collaborate with biologists, clinicians, and bioinformaticians for data interpretation and validation of computational findings in clinical or experimental settings.\n disseminate research outcomes through publications in high-impact journals, conference presentations, and workshops.\n mentor and support the training of graduate students and early-career researchers in ai and multi-omics integration.\n\n\nrequired qualifications\n\n ph.d. in bioinformatics, computational biology, data science, artificial intelligence, or a related field.\n proven experience in multi-omics data integration, omics data analysis (genomics, transcriptomics, proteomics, metabolomics, microbiome).\n strong expertise in machine learning, deep learning, and advanced ai frameworks (tensorflow, pytorch, scikit-learn). experience with bioinformatics tools and databases (e.g., bioconductor, galaxy, kegg, reactome, string).\n proficiency in python, r, and unix/linux-based environments for high-performance data analysis. knowledge of biological network inference, causal modeling, and graph-based ai approaches.\n experience in multi-modal data fusion, representation learning, and heterogeneous data integration.\n strong publication record in relevant peer-reviewed journals.\n excellent communication skills and ability to work in a multidisciplinary environment.\n familiarity with cloud-based computing platforms (aws, azure, google cloud) and high-performance computing (hpc) environments.\n understanding of data privacy, security, and ethical considerations in handling clinical data.\n\n\napplication process\n\ninterested candidates should submit the following documents in a single pdf:\n\n a cover letter outlining their research interests, motivation, and relevant experience.\n a detailed curriculum vitae (cv) with a list of publications.\n contact details of two academic referees.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "bioinformatics data scientist",
  "education_level": 5,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "r",
    "tensorflow"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "research",
    "education"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-senior-at-attijariwafa-bank-4187259466",
  "titre": "data engineer senior",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-23",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "attijariwafa bank est le premier groupe bancaire et financier du maghreb et un acteur financier de reference en afrique. en plus de lactivite bancaire, le groupe opere, a travers des filiales specialisees, dans tous les metiers financiers : assurance, credit immobilier, credit a la consommation, leasing, gestion dactifs, intermediation boursiere, conseil, location longue duree, factoring... attijariwafa bank est basee au maroc et opere dans 25 pays. avec 20 602 collaborateurs, le groupe attijariwafa bank compte 10,2 millions de clients. il dispose du reseau de distribution le plus large au maroc et le plus dense en afrique avec 5 265 agences.\ndans le cadre de notre developpement,\nnous recrutons un data engineer senior qui rejoindra une equipe dynamique et innovante,\n\n\npour missions :\n\n\nen tant que data engineer senior, vous serez au cur des projets big data & analytics et participerez a la mise en production de modeles analytiques pour repondre aux besoins metiers.\n\n\nvos responsabilites incluront :\n\n\ncollecte et transformation des donnees /encadrement technique et accompagnement des equipes \n extraire, structurer et nettoyer les donnees issues de differentes sources internes et externes.\n assurer loptimisation et la fiabilite des pipelines de donnees.\n accompagner et encadrer techniquement les data engineers juniors.\n mettre en place des bonnes pratiques et assurer la montee en competences des equipes.\ndeveloppement et mise en production de modeles analytiques/conception et amelioration des solutions data:\n adapter et integrer des modeles danalyse dans lenvironnement si de la banque.\n assister les equipes it dans toutes les phases de mise en production et doptimisation.\n contribuer a la definition des architectures data et a lamelioration continue des infrastructures.\n developper et maintenir des solutions scalables et performantes.\nanimation et veille technologique :\n organiser des workshops et animer des formations internes sur les problematiques data.\n assurer une veille active sur les nouvelles technologies et proposer des solutions innovantes.\n travailler en etroite collaboration avec les data scientists et les equipes it.\n garantir la compatibilite des modeles analytiques avec les systemes existants.\n environnement technique & competences requises :\n langages et outils : python, sql, spark, scala, java\n bases de donnees : postgresql, mongodb, cassandra\n cloud & big data : aws, azure, google cloud, hadoop,\n methodologies : agile (scrum, kanban), devops, ci/cd\n soft skills : rigueur, esprit analytique, leadership, pedagogie\n\n\nprofil recherche :\n\n\n niveau detudes : bac+5 (diplome dingenieur en informatique, big data, ou equivalent)\n experience : 2 a 5 ans\nrejoignez-nous et participez a la transformation digitale d'attijariwafa bank !",
  "company_name": "attijariwafa bank",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "leadership"
  ],
  "sector": [
    "finance",
    "banking"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-red-tic-4180454954",
  "titre": "data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-09",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": null,
    "remote": false
  },
  "description": "freelance\n casablanca\n publie il y a 4 mois\n\n\nred tic recrute pour lun de ses clients un profil data analyst.\n\nmission\n\n rassembler des donnees a partir de diverses sources, que ce soit a travers des bases de donnees, des fichiers csv ou des outils de collecte.\n traiter les donnees pour eliminer les incoherences, les valeurs manquantes et les doublons, afin de sassurer que les analyses sont precises.\n realiser des analyses descriptives pour comprendre les tendances, les schemas et les relations dans les donnees.\n creer des graphiques, des tableaux et dautres visualisations pour representer les donnees de maniere claire et accessible, facilitant ainsi la comprehension des resultats.\n elaborer des rapports et des presentations pour communiquer les resultats aux parties prenantes, en traduisant les analyses en recommandations concretes.\n\n\nprofil recherche\n\n langages de programmation : sql, python\n outils de visualisation: tableau\n bases de donnees relationnelles : mysql, postgresql, oracle.\n bases de donnees nosql : cassandra\n\n\nrecruitment consulting management training sourcing job jobs offer internship morocco africa java developpement developpement developpeur developpeur informatique application it jee android consultant devops fullstack. dabord. tout dabord. en premier lieu. ensuite, de plus. finalement. en outre. par ailleurs. en dernier lieu. enfin. dabord, en premier lieu, pour commencer, premierement, en conclusions ur conclure, enfn, finalement, en dernier lieu, bien que. il y a aussi il est vrai que... mais. tout en reconnaissant que... on peut supposer que. par exemple . en fait . prenons le cas de. considerons, par exemple. lexemple le plus r. cependant. mais. pourtant. toutefois. neanmoins. contraste. alors que. tandis que. par contre. en revanche analyst recruitment consulting management training sourcing job jobs offer internship morocco africa java developpement developpement developpeur developpeur informatique application it jee android consultant devops fullstack. dabord. tout dabord. en premier lieu. ensuite, de plus. finalement. en outre. par ailleurs. en dernier lieu. enfin. dabord, en premier lieu, pour commencer, premierement, en conclusions ur conclure, enfn, finalement, en dernier lieu, bien que. il y a aussi il est vrai que... mais. tout en reconnaissant que... on peut supposer que. par exemple . en fait . prenons le cas de. considerons, par exemple. lexemple le plus r. cependant. mais. pourtant. toutefois. neanmoins. contraste. alors que. tandis que. par contre. en revanche analyst\n\nnom et prenom\n\nadresse email\n\nmobile\n\nniveau d etude\n\nbac bac +1 bac +2 bac +3 bac +4 bac +5 bac + x\n\nannees dexperience\n\n0 +1 +2 +3 +4 +5 +6 +7 +8 +9 + 10\n\npreavis\n\ndisponible immediatement -1 mois 1 mois 2 mois +2 mois\n\nmessage\n\nupload cv\n\nteleverser votre cv ou tout autre document relatif. taille max: 2 mb.",
  "company_name": "red tic",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": null,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "sql",
    "python",
    "tableau"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "analytical skills"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-f-h-at-axa-assurance-maroc-4199832653",
  "titre": "data analyst f/h",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-02",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "axa assurance maroc recrute pour le compte de sa direction transformation / data, analytics & ai un /une data analyst :\n\n\nmission du poste :\n\n\nle data analyst a pour mission dexplorer et interpreter les donnees pour en degager des observations business utiles. ainsi, les analyses fournies permettent d'orienter les prises de decision du management et ameliorer les performances et les strategies marketing et commerciales de lentreprise.\n\n\nactivites du poste :\n\n\n collecter, agreger et nettoyer des donnees en vue de realiser des etudes sur les donnees entreprise ;\n modeliser et enrichir les entrepots de donnees et les datamarts (magasins de donnees) dedies a une fonction particuliere dans lentreprise ;\n concevoir et livrer larchitecture applicative et technique necessaire pour la valorisation de donnees (data lake, data warehouse, data viz) ;\n fournir lexpertise technologique necessaire pour developper les solutions data appropriees aux differents cas dusage data emanant des unites metiers de lentreprise ;\n effectuer les croisements de donnees necessaires ainsi que les travaux de validation, correction, qualite ;\n effectuer des analyses decisionnelles sur les donnees traitees...\n\n\nen outre, et de facon non limitative, il peut etre amene a effectuer toute mission a la demande de sa hierarchie, compatible avec sa fonction.\n\n\ncompetences requises : \n\n\n maitrise de la modelisation de donnees decisionnelles (schema en flocons...) ;\n maitrise des solutions etl/elt: talend, informatica, ssis ;\n connaissance des solutions de bases de donnees sql : microsoft sql server, sas base, sap hana ;\n connaissance des systemes nosql : elasticsearch, hbase, cassandra, redshift ;\n maitrise des solutions : powerbi ;\n bonne maitrise des langages de programmation : scala, java, python ;\n bonne connaissance basique sur le machine learning, data science, et lintelligence artificielle ;\n sens de l'organisation et du detail ;\n capacites d'analyse ;\n capacite a travailler methodiquement dans la repetitivite ;\n acceptation du changement, adaptabilite ;\n capacite a innover et proposer ;\n respect de la confidentialite, ethique ;\n ecoute active, empathie, travail en equipe ...\n\n\nprofil recherche :\n\n\n de formation bac+4 ou plus, universite ou ecole dingenieur en data ou bi ;\n experience de minimum 2 ans dans un poste similaire... \n\n\nsi le descriptif correspond a votre profil et motivations professionnelles, merci de nous faire parvenir vos cv.\n\n\npourquoi rejoindre axa assurance maroc ?\n\n\n axa est un des leaders de lassurance et de la gestion dactifs a travers le monde.\n nous aidons nos 108 millions de clients a traverser les petites et grandes difficultes de la vie.\n acceder a des opportunites de developpement professionnel et de formation continue pour favoriser votre croissance au sein de notre entreprise et enrichir votre panel de competences.\n evoluer dans une culture d'entreprise basee sur lagilite, la performance individuelle et collective, la collaboration et l'ethique.\n etre collaborateur axa assurance maroc, cest rejoindre un environnement de travail inclusif et diversifie, ou chaque individu est valorise et a la possibilite de s'epanouir.\n tous nos emplois sont ouverts aux personnes en situation dhandicap.",
  "company_name": "axa assurance maroc",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "python",
    "powerbi"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "adaptability"
  ],
  "sector": [
    "insurance"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/project-manager-data-ia-at-wama-invest-4207846250",
  "titre": "project manager data, ia",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-11",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "wama invest recrute !\nnous recherchons pour le compte de lun de nos clients un(e) project manager experimente(e), avec au moins 5 ans dexperience dans la gestion de projets it.\n poste base a casablanca\n missions principales :\n gerer le portefeuille projets et assurer le suivi budgetaire (en jh)\n animer les reunions de lancement et de suivi\n suivre lavancement des projets et etablir les reportings\n identifier, evaluer et piloter les risques techniques, fonctionnels et budgetaires\n deployer des methodologies de resolution et proposer des solutions damelioration\n standardiser et optimiser les processus de gestion de projets\n competences requises :\n maitrise des outils de gestion de projets (jira, redmine, glpi, gitlab issues...)\n connaissance des bonnes pratiques en gestion de projets\n excellente capacite danalyse et de pilotage dans un environnement complexe",
  "company_name": "wama invest",
  "is_data_profile": true,
  "profile": "unspecified",
  "education_level": null,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "jira",
    "project management",
    "reporting"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cus-postdoctoral-researcher-in-spatial-data-science-at-um6p-university-mohammed-vi-polytechnic-4212739585",
  "titre": "cus - postdoctoral researcher in spatial data science",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-18",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "postdoctoral researcher in spatial data science\n\nposition description\n\nwe are seeking a postdoctoral researcher specializing in urban modeling and cost analysis to develop an innovative model to estimate the direct and indirect costs of urbanization based on urban morphology (compact or sprawling). the candidate will analyze real case studies, integrate variables related to infrastructure, health, and the environment, and simulate scenarios under different climatic and social contexts to provide decision-making tools for sustainable urban planning.\n\nmain tasks and responsibilities\n\n develop a predictive model integrating the direct and indirect costs of urbanization.\n calibrate this model using real data from specific case studies.\n simulate urbanization costs based on various climatic, morphological, and social scenarios.\n formulate innovative methodological approaches.\n produce publications on research in scientific journals.\n participate in teaching activities.\n develop new research proposals.\n\n\nrequired qualifications\n\n ph.d. in data science, urban planning, urban economics, or a related field.\n experience in research projects applied to urban, environmental, or socio-economic issues.\n proficiency in urban modeling tools such as matlab, python (especially libraries like pandas, numpy, scipy, geopandas, etc.), and r.\n advanced skills in predictive modeling and machine learning, particularly for multi-variable simulations.\n knowledge of complex systems modeling applied to urban dynamics.\n publications in scientific journals.\n\n\npersonal and organizational qualifications\n\n ability to develop innovative methods.\n ambition for research excellence.\n interest in african issues.\n entrepreneurial mindset, dynamism, and organizational skills.\n fluency in both french and english (oral and written) is required.\n\n\nwe offer\n\n excellent working conditions and competitive salary on an international scale.\n an opportunity to contribute to the development of research excellence in africa.\n a highly stimulating multicultural working environment and a great team atmosphere.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "geospatial data scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "matlab",
    "r"
  ],
  "soft_skills": [
    "communication",
    "research",
    "problem-solving"
  ],
  "sector": [
    "research",
    "academia"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-at-alten-4217452745",
  "titre": "data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-26",
  "location": {
    "city": "fez",
    "region": "fes-meknes",
    "country": null,
    "remote": false
  },
  "description": "alten delivery center maroc, filiale du leader mondial de lingenierie et du conseil en technologie cree en 2008 et present a fes, rabat, tetouan et casablanca, compte aujourdhui plus de 2200 consultants et vise un centre dexcellence de 3300 consultants alteniens en fin 2027. alten maroc est desormais un acteur majeur de linsertion professionnelle des  ingenieurs. nous accompagnons nos clients, leaders de lindustrie dans leurs strategies de developpement dans les domaines de lautomobile, du ferroviaire, de lit, de la r&d et des telecoms & medias.\n\n\nrejoindre alten maroc cest beneficier :\n\n\n des parcours professionnels diversifies avec des opportunites de carriere, une mobilite interne, sectorielle, geographique et metiers.\n des formations certifiantes et diplomantes.\n des evenements reguliers pour combiner bien etre et performance\n\n\ndescription du poste\n\nen tant que data engineer, vous principales missions seront :\n\n\n conception et deploiement de systemes d'ia\n modelisation avancee pour resoudre des problemes complexes\n realisation des recettes des evolutions des outils\n developpement des notebooks en utilisant spark python\n test et validation de non-regression des donnees dessais de roulage\n support et animation de la resolution des incidents\n assurer le suivi des incidents aupres de la direction des systemes dinformation\n\n\nqualifications\n\ndiplome(e) d'un bac+5 en informatique\n\n\nexperience : debutant ou avec experience (0-2ans)\n\n\ncompetences requises :\n\n\n maitrise du langage python\n bon niveau en francais et en anglais (parler & ecrit)\n maitrise de spark python\n maitrise de jupyter\n maitrise des algorithmes ml et dl\n concevez et developpez l'infrastructure necessaire pour prendre en charge les projets d'ia, en utilisant les dernieres technologies et outils.\n connaissance en git/github\n connaissance de bases de donnees structurees (oracle, mysql, sql server...)\n connaissance en hadoop\n habilite a acquerir de nouvelles connaissances\ncompetences appreciees :\n\n\n esprit de synthese\n analyse critique\n rigueur\n gestion relation clientele (communication, serviabilite, ecoute actif)\n connaissance en culture automobile\n\n\n\n\n\ninformations supplementaires\n\nlooking forward to hearing from you !",
  "company_name": "alten",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "spark",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "it",
    "automotive"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-engineer-at-abberline-4218031144",
  "titre": "senior data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-01",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "abberline est un cabinet de recrutement au caractere bien trempe qui cree les belles rencontres et les grandes histoires. nous accompagnons dans la construction de leur carriere des profils middle & top management en cdi - mais egalement des freelances - en france comme a linternational.\n\n\ncontexte : notre client est un groupe international francais, dans le secteur des  facilities , qui cherche a renforcer ses equipes au maroc. aujourd'hui, le groupe souhaite integrer un(e) senior data engineer.\n\n\n\n\nmissions :\n\n\n est en charge de la mise en uvre, du run et de levolution de la plateforme data :\n- integre de nouveaux flux de donnees.\n- sassure du bon deroulement des batchs dintegration des donnees.\n- sassure de lintegrite et des performances de la plateforme data.\n- veille a maintenir la plateforme data  up to date  en mettant a jour ses composants et en la faisant evoluer en adequation avec les dernieres avancees technologiques.\n\n\n pour etre efficace, le/la data engineer doit avoir une connaissance transverse des flux de donnees qui transitent dans la plateforme data\n\n\n collabore avec les data analysts / scientists pour sassurer de la bonne utilisation des donnees qui sont exposees via la plateforme data :\n- gere la mise a disposition et les droits dacces a la donnee\n- sassure des interactions entre les consommateurs des donnees et la data plateforme dans un soucis de rationalisation et de performance\n- propose des ameliorations techniques (indexation, datamart, pre calcul de kpis...)\n\n\n participe aux travaux damelioration continue de la qualite des donnees.\n\n\n assure le niveau de support n 3 sur la fraicheur, lintegrite et la mise a disposition des donnees.\n\n\n est referent technique du socle data.\n\n\n interagit avec le departement data gouvernance de la direction pour aligner les modeles de donnees avec la strategie data des metiers.\n\n\n travaille en etroite collaboration avec les data managers dans les bus en charge de la definition et de la qualite des objets data pris en charge.\n\n\n participe a la road map de mise en qualite des donnees lancees par les data managers\n\n\n\n\nvotre profil :\n\n\nvous avez un fort interet pour les systemes dinformation et vous avez de bonnes notions en gestion de projet. vous avez un tres bon relationnel et du leadership. vous faites preuve de pedagogie et d'une forte capacite d'analyse, de rigueur et d'empathie.\n\n\n maitrise des bases de donnees sql (sql server, bigquery, postgresql...)\n maitrise des langages de programmation (sql, python, c++, java...)\n maitrise des outils/pratiques devops (chaine ci/cd, azuredevops, git...)\n maitrise des plateformes cloud (gcp)\n maitrise doutils danalyse et reporting serait un plus\n maitrise des fondamentaux de la gouvernance des donnees et du data management\n maitrise de loutil de visualisation de la donnee power bi\n pilotage et coordination transverse\n animation reunions/comites de suivi\n competence technique en business intelligence\n anglais professionnel\n etat d'esprit agile, innovant et collaboratif\n capacite danalyse et de synthese\n capacite a travailler en equipe\n capacite decoute et douverture vers les fonctions non connues\n\n\nposte base a casablanca.",
  "company_name": "abberline",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": null,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "sql",
    "python",
    "gcp"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "leadership"
  ],
  "sector": [
    "recruiting",
    "facilities"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/architecte-data-senior-secteur-assurance-freelance-mission-longue-duree-hybride-casablanca-at-confidentiel-4190787756",
  "titre": "architecte data senior secteur assurance freelance mission longue duree hybride casablanca",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-22",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "bonjour,\nje cherche \n\n\narchitecte data senior senior, secteur assurance freelance mission longue duree hybride casablanca \n disponibilite : 1 mois max\nsi vous etes interesse veuiller envoyer votre candidature",
  "company_name": "confidentiel",
  "is_data_profile": true,
  "profile": "data architect",
  "education_level": null,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [],
  "soft_skills": [],
  "sector": [
    "insurance"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/client-solutions-engineer-data-at-lumenalta-4214842367",
  "titre": "client solutions engineer - data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-04-26",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "about lumenalta\nat lumenalta, we create impactful software solutions that drive innovation and transform businesses. since 2000, weve partnered with visionary leaders to build cutting-edge tech, solve complex challenges, and deliver results faster through our elite teams and tech-driven approach. join us in shaping the future of technology.\n\n\nabout the role:\nwe seek a client solutions engineer to architect and deliver technical solutions while fostering strong client relationships. combining technical expertise, sales acumen, and client-facing skills, youll advise senior leaders, identify challenges, propose tailored solutions, and lead implementations. youll also help shape lumenaltas offerings to support business development and long-term partnerships.\n\n\nresponsibilities\n design and implement data-centric solutions, including data pipelines, warehouses, and analytics platforms.\n support business development efforts by contributing to project scoping, proposals, and technical roadmaps.\n partner with senior stakeholdersmanagers, directors, vps, and c-suite leadersto define data strategies and deliver actionable insights.\n architect and optimize scalable systems for data storage, processing, and visualization across diverse business domains.\n lead teams of developers and data engineers, ensuring high-quality and on-time deliverables.\n employ deep knowledge of modern data engineering tools and frameworks to position lumenaltas offerings and meet client needs.\n drive the implementation of data governance, security, and compliance measures.\n take ownership of deliverables, ensuring solutions achieve business objectives and deliver measurable impact.\n\n\nrequirements\n 6+ years of client-facing experience in data architecture, engineering, or analytics, with strong consulting and business analysis skills.\n proven experience designing and implementing data pipelines, etl processes, and cloud-based data infrastructure (e.g., aws, azure, gcp).\n deep proficiency with modern data tools and platforms such as sql, python, apache spark, and bigquery.\n demonstrated ability to design scalable, robust systems tailored to client needs and business objectives.\n experience engaging with c-suite stakeholders, influencing strategic decisions, and communicating technical solutions effectively.\n strong understanding of data governance, security, and compliance standards.\n a proven track record of contributing to business development efforts, including solution positioning and proposal development.\n evidence of thought leadership, such as speaking engagements, publications, or an online portfolio of work.\n advanced english fluency, with excellent verbal and written communication skills.\n\n\nwhy lumenalta is an amazing place to work at\nat lumenalta, you can expect that you will:\n be 100% dedicated to one project at a time so that you can innovate and grow.\n be a part of a team of talented and friendly senior-level developers.\n work on projects that allow you to use leading tech.\n\n\nthe result? we produce meaningful outcomes for our clients that break barriers in their industries.\n\n\nwhat's it like to work at lumenalta?",
  "company_name": "lumenalta",
  "is_data_profile": true,
  "profile": "data consultant",
  "education_level": null,
  "experience_years": 6,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "python",
    "aws"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "leadership"
  ],
  "sector": [
    "it",
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/cus-postdoctoral-researcher-in-spatial-data-science-at-um6p-university-mohammed-vi-polytechnic-4225920931",
  "titre": "cus - postdoctoral researcher in spatial data science",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-08",
  "location": {
    "city": "morocco",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "position description\n\nwe are seeking a postdoctoral researcher specializing in urban modeling and cost analysis to develop an innovative model to estimate the direct and indirect costs of urbanization based on urban morphology (compact or sprawling). the candidate will analyze real case studies, integrate variables related to infrastructure, health, and the environment, and simulate scenarios under different climatic and social contexts to provide decision-making tools for sustainable urban planning.\n\nmain tasks and responsibilities\n\n develop a predictive model integrating the direct and indirect costs of urbanization.\n calibrate this model using real data from specific case studies.\n simulate urbanization costs based on various climatic, morphological, and social scenarios.\n formulate innovative methodological approaches.\n produce publications on research in scientific journals.\n participate in teaching activities.\n develop new research proposals.\n\n\nrequired qualifications\n\n ph.d. in data science, urban planning, urban economics, or a related field.\n experience in research projects applied to urban, environmental, or socio-economic issues.\n proficiency in urban modeling tools such as matlab, python (especially libraries like pandas, numpy, scipy, geopandas, etc.), and r.\n advanced skills in predictive modeling and machine learning, particularly for multi-variable simulations.\n knowledge of complex systems modeling applied to urban dynamics.\n publications in scientific journals.\n\n\npersonal and organizational qualifications\n\n ability to develop innovative methods.\n ambition for research excellence.\n interest in african issues.\n entrepreneurial mindset, dynamism, and organizational skills.\n fluency in both french and english (oral and written) is required.\n\n\nwe offer\n\n excellent working conditions and competitive salary on an international scale.\n an opportunity to contribute to the development of research excellence in africa.\n a highly stimulating multicultural working environment and a great team atmosphere.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "geospatial data scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "matlab",
    "r"
  ],
  "soft_skills": [
    "communication",
    "research",
    "problem-solving"
  ],
  "sector": [
    "research",
    "academia"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/senior-data-engineer-at-banque-centrale-populaire-bcp-4228408599",
  "titre": "senior data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-12",
  "location": {
    "city": "casablanca metropolitan area",
    "region": null,
    "country": null,
    "remote": false
  },
  "description": "la banque centrale populaire recrute un(e) senior data engineer (h/f) au sein de l'entite data custodian. \n\n\nle senior data engineer aura pour mission d'assurer le tech lead au sein de lequipe data engineering pour lindustrialisation des solutions datalake.\n\n\nmissions detaillees :\n\n\n la mise en place des mecanismes necessaires pour capturer les donnees depuis le systeme operant et lindustrialisation des solutions techniques depuis lingestion de la donnee, modelisation et exposition de la data pour lutilisateur final ; \n la conception et le developpement de lintelligence artificielle et du machine learning pour maintenir et ameliorer les systemes ai existants ;\n la collaboration etroite avec les parties prenantes fonctionnelles et les equipes de run afin de sassurer que les processus de developpement et de deploiement sont efficaces et en adequation avec les besoins ; \n la veille sur les tendances technologiques data et le transfert de competences sur les solutions data au profit des utilisateurs des plateformes data. \n\n\ncompetences / qualites requises :\n bonne maitrise des outils de manipulation de la donnees (sql, nosql, bi, python, spark ...)\n familiarite avec les methodologies agiles \n force de proposition de solution data en respectant les normes de developpement, deploiement et amelioration continue. \n esprit analytique\n prise d'initiative et leadership \n autonomie et esprit d'equipe\n\n\ndomaine d'excellence souhaite :\n-data engineering\n-machine learning\n-big data \n\n\nexperience professionnelle :\n5 ans minimum dans un poste similaire\n\n\nformation:\ngrandes ecoles d'ingenieurs ou de commerce.",
  "company_name": "banque centrale populaire - bcp",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": null,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "sql",
    "python",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "leadership"
  ],
  "sector": [
    "banking"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-h-f-at-labelvie-4223046573",
  "titre": "data engineer (h/f)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-07",
  "location": {
    "city": "casablanca-settat",
    "region": "morocco",
    "country": null,
    "remote": false
  },
  "description": "cree en 1986 et cote a la bourse de casablanca depuis 2008, le groupe marocain labelvie est un acteur economique de reference et leader de la grande distribution au maroc.\nen 2009, a travers la signature du contrat de franchise avec le groupe carrefour, il accede a sa centrale dachat pour optimiser et diversifier son sourcing. il devient ainsi le premier acteur multi-formats de la grande distribution au maroc par lexploitation des hypermarches carrefour, des supermarches carrefour market et du format hyper cash atacadao.\nle groupe labelvie presente chaque annee un plan de developpement soutenu renforcant sa presence territoriale avec ses 136 magasins repartis dans 28 villes du royaume et ses 3 plateformes logistiques et un chiffre daffaires realise de 11,7 milliards de dirhams en 2021.\nen 2021, le groupe labelvie a entame sa transformation digitale afin de repondre aux enjeux dinnovation et aux besoins des consommateurs finaux. ce sont ainsi de nombreux projets structurants qui sont actuellement en construction au sein du groupe pilotes par nos equipes si, digital et data ; constituees dexperts reconnus dans leur domaines et animes par la volonte de relever les challenges de linnovation et de la transformation digitale dans un secteur en plein essor.\n\n\nposte :\n\n\nle data engineer (h/f) a pour mission dassurer la collecte, le traitement et le stockage des donnees dans la plateforme data cloud azure de maniere efficace. il travaille sur limplementation de pipelines optimises et lexposition des donnees repondant aux besoins des cas dusages data ainsi que des applications.\n\n\nles principales responsabilites sont de :\n\n\n conception et developpement de pipelines de donnees pour l'extraction, le chargement et la transformation (elt) des donnees;\n creation et gestion de bases de donnees et d'entrepots de donnees;\n implementation de l'architecture de donnees et des modeles de stockage;\n automatisation des processus de gestion des donnees pour ameliorer l'efficacite et la productivite;\n optimisation des performances des pipelines et assurer un traitement efficace des donnees;\n mise en place de la securite des donnees et des mecanismes de protection des donnees sensibles;\n collaboration avec les parties prenantes (metiers, data scientists, data analysts, developpeurs...) pour soutenir les initiatives liees aux donnees;\n maintenance des pipelines de donnees developpes;\n documentation des processus et des normes lies a la gestion des donnees...\n\n\nprofil recherche :\n\n\nde formation bac+5 d'une ecole dingenierie avec une experience de minimum 2 ans dans la data engineering ou dans un poste similaire, dans laquelle vous avez developpe les competences techniques liees aux technologies suivantes :\n bonne connaissance des technologies data sur azure.\n maitrise des langages de programmation python et sql.\n bonne connaissance des outils et des frameworks de big data tels que hadoop, spark, kafka.\n competences dans la conception et le developpement de pipelines elt.\n competences en modelisation de donnees et gestion des schemas.\n connaissance des bases de donnees relationnelles et non relationnelles.\n capacite a optimiser les performances des bases de donnees...\n\n\n\n\n labelvie sengage a prevenir toute forme de discrimination et notamment celles fondees sur le sexe ou la situation et les responsabilites familiales. labelvie sengage a promouvoir legalite des chances entre les hommes et les femmes, en matiere dacces a lemploi et a la formation, de conditions de travail, de remuneration, devolution de carriere et dacces a des postes a responsabilite .",
  "company_name": "labelvie",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "sql",
    "azure"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "problem-solving"
  ],
  "sector": [
    "retail"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/crsa-postdoctoral-researcher-in-coastal-ecosystem-monitoring-using-satellite-data-at-um6p-university-mohammed-vi-polytechnic-4226712595",
  "titre": "crsa - postdoctoral researcher in coastal ecosystem monitoring using satellite data",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-09",
  "location": {
    "city": "benguerir",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "position title: postdoctoral researcher  coastal ecosystem monitoring and agricultural runoff impacts\n\nduration: 2 years\n\nlocation: mohammed vi polytechnic university (um6p), morocco\n\nabout um6p\n\nlocated at the heart of the future green city of benguerir, mohammed vi polytechnic university (um6p), a higher education institution with international standards, is established to contribute to the development of morocco and the african continent. its vision is honed around research and innovation at the service of education and development. this unique nascent university, with its state-of-the-art campus and infrastructure, has woven a sound academic and research network, and its recruitment process is seeking high-quality academics and professionals in order to boost its quality-oriented research environment in the metropolitan area of marrakech.\n\nabout crsa\n\ncrsa is a transversal structure across several um6p programs. research within the center is organized around several major areas that aim to ensure the challenging food and water security goal in africa, with a special focus on developing methods/tools that use multi-source remotely sensed data. the research aims to improve our understanding of the integrated functioning of continental surfaces and their interaction with climate and humans, with emphasis on sustainable management of natural resources (soil, land, water, agriculture) in the context of climate change. one of the centers goals is to provide a set of services and operational products to users (local, national, and international) that aid in the decision support of water and food systems.\n\nposition overview\n\nthe mohammed vi polytechnic university (um6p) is seeking a highly motivated postdoctoral researcher to work on an interdisciplinary project focused on monitoring the impacts of agricultural runoff on coastal ecosystems along the moroccan coast. the project will utilize advanced satellite remote sensing data (e.g., sentinel-3, landsat, etc.) combined with additional open datasets to assess phytoplankton dynamics, nutrient loading, and harmful algal blooms (habs). the research will contribute to understanding the ecological health of the region.\n\nkey responsibilities\n\n conduct independent research focused on analyzing satellite-derived data (sentinel-3, landsat) to monitor coastal ecosystem changes.\n develop workflows in r, python, or matlab to process and analyze ocean color data, with a focus on chlorophyll-a, suspended particulate matter, and colored dissolved organic matter (cdom).\n assess the impact of agricultural runoff on coastal water quality, particularly nutrient enrichment and its relationship with phytoplankton blooms.\n use remote sensing to detect harmful algal blooms (habs) and assess their spatiotemporal variability along the moroccan coastline.\n investigate links between satellite data and key ecological indicators, including the presence of phytoplankton species indicative of nutrient imbalances.\n collaborate with researchers and institutions (e.g., ocp group) to align the research with sustainable agriculture and environmental monitoring initiatives.\n contribute to scientific publications, project reports, and presentations at international conferences.\n potentially assist in proposal writing to seek additional funding for fieldwork.\n\n\nqualifications\n\n phd in oceanography, environmental sciences, remote sensing, or a related field.\n strong expertise in satellite remote sensing, including atmospheric correction techniques.\n proficiency in r, python, or matlab for data processing, geospatial analysis, and statistical modeling.\n experience with time series analysis, spatial mapping, and oceanographic data interpretation.\n experience in writing scientific papers and presenting research results.\n ability to work independently and collaboratively in an interdisciplinary research environment.",
  "company_name": "um6p - university mohammed vi polytechnic",
  "is_data_profile": true,
  "profile": "research scientist",
  "education_level": 4,
  "experience_years": null,
  "seniority": null,
  "hard_skills": [
    "python",
    "r",
    "matlab"
  ],
  "soft_skills": [
    "research",
    "collaboration",
    "communication"
  ],
  "sector": [
    "research",
    "environmental science"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/bi-data-engineer-at-stellantis-4173595030",
  "titre": "bi data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-04",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "company overview\n\n\nbuild your brand. tell your story. take advantage of a rare opportunity to start from the ground up and build something great.\n\n\nstellantis is a leading global automaker and mobility provider that offers clean, connected, affordable and safe mobility solutions. our companys strength lies in the breadth of our iconic brand portfolio, the diversity and passion of our people, and our deep roots in the communities in which we operate. our ambitious electrification and software strategies and the creation of an innovative ecosystem of strategic, game-changing partnerships are driving our transformation to a sustainable mobility tech company.\n\n\nwith industrial operations in nearly 30 countries, stellantis could consistently exceed the evolving needs and expectations of consumers in more than 130 markets, while creating superior value for all stakeholders.\n\n\nwe are looking for technology game changers to lead stellantis into a fundamental transformation within the automotive industry. technology is going to disrupt the automotive industry significantly in the next decade and our organization is seeking high potential candidates to transform the company with a focus on the customer experience. stellantis software organization (swx) was created to build the most captivating experiences in the latest frontier of automotive technology.\n\n\njob overview\nwe are looking for an experienced data engineer to join our team. you will be responsible for designing, developing, and maintaining data pipelines to support our data-driven decisions. collaborating with data scientists, analysts, and engineers, you will ensure a reliable, scalable, and secure data infrastructure\n\n\nresponsibilities\n design, develop, and maintain scalable data pipelines using spark, sql, and python.\n leverage the databricks platform to build and manage data processing workflows.\n clean, transform, and integrate data from multiple sources into a unified format.\n implement data quality checks and monitoring to ensure accuracy and completeness.\n collaborate with data scientists and analysts to address data requirements and develop solutions.\n document data pipelines and processes clearly and concisely.\n use git for version control and maintain a clean, collaborative development environment.\n follow best practices in software development, including unit testing, code reviews, and ci/cd.\n stay updated on the latest trends and best practices in data engineering.\n\n\nqualifications\n bachelors degree in computer science, information technology, or a related field (or equivalent experience).\n minimum of 2 years of experience as a data engineer or in a similar role.\n strong proficiency in sql, python, and spark.\n familiarity with the databricks platform.\n experience with data warehousing and data lakes (e.g., aws redshift, snowflake) is a plus.\n proficiency in git and knowledge of software development best practices, including unit testing, code reviews, and ci/cd.\n excellent communication and collaboration skills.\n ability to work independently and as part of a team.\n\n\ndiversity engagement\n\n\nat stellantis, we assess candidates based on qualifications, merit and business needs. we welcome applications from people of all gender identities, age, ethnicity, nationality, religion, sexual orientation and disability. diverse teams will allow us to better meet the evolving needs of our customers and care for our future.\n\n\nwhat we offer\n\n\njoining stellantis means gaining access to a wealth of opportunities and benefits, including:\n\n\nprofessional development: opportunities for ongoing professional development and advancement, ensuring you're always at the forefront of industry trends and innovations.\n\n\nglobal exposure: exposure to a global work environment, where you'll collaborate with colleagues from diverse backgrounds and cultures, broadening your horizons and expanding your network.\n\n\ninclusive culture: an inclusive and collaborative company culture, where every voice is valued and respected, fostering a sense of belonging and camaraderie among our team members.\n\n\nexpert mentorship: mentorship from industry experts who are dedicated to sharing their knowledge and guiding you on your career journey, providing invaluable insights and support along the way.",
  "company_name": "stellantis",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 2,
  "experience_years": 2,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "python",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "collaboration",
    "teamwork"
  ],
  "sector": [
    "automotive"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/lead-data-plateforme-freelance-at-proorga-consulting-4223448851",
  "titre": "lead data plateforme (freelance)",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-05-05",
  "location": {
    "city": "casablanca",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "nous recherchons pour un client un profil de data plateforme lead. celui-ci assure l'efficacite de la collecte, du traitement et du stockage des donnees. il collabore avec les equipes metiers et cto/dsi pour repondre aux besoins et mettre en place l'infrastructure. il dirige les data engineers pour implementer des pipelines optimaux et exposer les donnees necessaires.\n\n\nresponsabilites:\n concevoir des frameworks et developper des pipelines pour la collecte, le traitement, et le stockage des donnees sur la plateforme data cloud azure.\n animer et diriger une equipe de data engineers.\n coordonner les projets et repartir les taches au sein de l'equipe.\n developper les competences des membres de l'equipe et assurer leur mentorat.\n etablir des normes et des processus pour la collecte, le stockage, la transformation, et la securisation des donnees.\n garantir la qualite et la fiabilite des donnees en mettant en place des mecanismes de controle et de surveillance.\n collaborer avec les parties prenantes (metiers, data scientists, data analysts, developpeurs...) pour comprendre leurs besoins, fournir des solutions de donnees efficaces et soutenir les initiatives liees aux donnees.\n participer a la veille technologique pour rester informe des avancees dans le domaine du big data et de l'ingenierie des donnees.\nprofil recherche\n diplome bac+5 d'une ecole d'ingenierie avec au moins 5 ans d'experience en data engineering ou dans un poste similaire, ou vous avez developpe des competences techniques liees aux technologies suivantes :\n maitrise des technologies data sur azure.\n maitrise des langages de programmation python et sql.\n expertise dans la conception et le developpement de pipelines de donnees (elt) et la manipulation des donnees.\n connaissance approfondie des outils et des frameworks de big data tels que hadoop, spark, kafka.\n competences en modelisation de donnees et en gestion de schemas.\n maitrise des principes d'optimisation des performances et des techniques de resolution de problemes lies aux bases de donnees.",
  "company_name": "proorga consulting",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 5,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "spark"
  ],
  "soft_skills": [
    "leadership",
    "teamwork",
    "communication"
  ],
  "sector": [
    "consulting",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/stage-business-data-analyst-at-digital-virgo-4182781012",
  "titre": "stage business data analyst",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-12",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": "morocco",
    "remote": false
  },
  "description": "le groupe digital virgo compte parmi les specialistes mondiaux du paiement mobile via les solutions de facturation des operateurs telecoms. en connectant les marchands aux operateurs, nous repondons au besoin croissant de digitalisation du paiement en utilisant un canal transactionnel simple, rapide et securise, disponible partout dans le monde.\n\n\nen rejoignant digital virgo, tu integres un groupe international performant et innovant grace a des equipes locales, a taille humaine qui collaborent au quotidien, fortes de leur complementarite. nous venons tous dunivers et de parcours differents, cest cette diversite qui fait notre richesse.\n\n\nnos collaborateurs disent de nous, que l'ambiance de travail est un melange parfait de bonne humeur et de projets ambitieux. nous mettons l'accent sur le developpement de chacun et la prise d'initiatives.\n\n\nplus dinformations sur notre activite et groupe sur digitalvirgo.com\n\n\n\n\ndescription du poste\n\ncollecte et traitement des donnees\n\n\n extraction des donnees via base de donnees ou outils bi\n sassurer de la fiabilite des donnees avant utilisation\n\n\n\nanalyse et interpretation\n\n\n realiser des analyses pour identifier des tendances ou insights business\n construire des tableaux de bord et des rapports pour suivre les perfs cles\n aider a la prise de decision grace a des recommandations basees sur les resultats des analyses\n\n\n\nvisualisation des donnees\n\n\n concevoir des graphiques et dashboards interactifs pour rendre les analyses plus accessibles aux equipes metiers\n utiliser des outils comme tableau ou looker\n\n\n\nsupport aux equipes metier\n\n\n travailler en collaboration avec les equipes marketing, finance, produit, etc., pour repondre a leurs besoins en data.\n expliquer les resultats des analyses et aider a la prise de decision strategique.\n\n\nqualifications\n\ntechniques :\n\n\nmaitrise dexcel (tableaux croises dynamiques, formules avancees, etc.)\nconnaissance en sql (requetes pour extraire et manipuler des donnees)\nfamiliarite avec des outils de data visualisation (tableau, looker.)\nbases en python  (pour lanalyse et le traitement des donnees, un plus)\ncomprehension des statistiques et des modeles analytiques\n\n\n\n\n\nsoft skills :\n\n\nesprit analytique et capacite a interpreter des chiffres\nrigueur et attention aux details\nautonomie et capacite a resoudre des problemes\nbonne communication en francais et en anglais",
  "company_name": "digital virgo",
  "is_data_profile": true,
  "profile": "business intelligence analyst",
  "education_level": 2,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "sql",
    "excel",
    "python"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "analysis"
  ],
  "sector": [
    "fintech"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/consultant-e-data-science-at-sia-4195886844",
  "titre": "consultant(e) data science",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-28",
  "location": {
    "city": "mechouar",
    "region": "casablanca-settat",
    "country": "morocco",
    "remote": false
  },
  "description": "sia partners reinvente le metier du conseil et apporte un regard innovant et des resultats concrets a ses clients. nous avons developpe des solutions basees sur lintelligence artificielle et le design pour augmenter limpact de nos missions de conseil. notre presence globale et notre expertise dans plus de 30 secteurs et services nous permettent daccompagner nos clients dans le monde entier. a travers notre demarche \"consulting for good\", nous mettons notre expertise au service des objectifs rse de nos clients et faisons du developpement durable un levier de performance pour nos clients.\n\n\n\n\ndescription du poste\n\npour accompagner son developpement, sia partners recrute des consultants data scientist.\n\n\nils auront pour vocation de prendre en charge, en synergie avec nos differentes practices, les travaux et missions necessitant la mise en uvre de modeles complexes pour accompagner nos clients dans leurs problematiques en lien avec :\n\n\n machine learning et statistiques : elaboration de modeles explicatifs et predictifs d'aide a la decision (algorithmes d'apprentissage supervise et non supervise, econometrie, prevision, diagnostic quantitatif, ...)\n recherche operationnelle : assistance a la conception et a la mise en oeuvre de solutions d'optimisation sous contraintes et de modeles de simulation\n big data : connaissances algorithmiques pour le traitement de grand volume de donnees et non structurees\nvous serez egalement amene(e) a vous impliquer dans la vie interne du cabinet, autour de differents sujets :\n\n\n le developpement ou le renforcement de nos offres / decryptages des innovations et des enjeux actuels,\n le developpement de nouvelles opportunites au travers de reponses aux appels doffres et de propositions commerciales,\n la politique de publication de l'equipe (redaction darticles, presentation de decryptage sectoriel, etudes, livres blancs, ...).\n\n\nqualifications\n\nvous avez une formation en ecole d'ingenieur ou une formation de haut niveau dans le domaine du traitement de l'information, de l'ingenierie statistique et de l'econometrie et vous justifiez d'une premiere experience d'au moins un an en big data ou data science.\n\n\nvous avez un excellent niveau en statistiques et analyse quantitative (connaissances theoriques et pratiques, intuition, facilite a comprendre des modeles et les appliquer)\n\n\nvous maitrisez la programmation en r (ou equivalent : sas, matlab...) et possedez des bases solides dans des langages de script (python, perl, js, bash) ou compiles (c++, java) et/ou avez une experience dans les environnements unix/linux\n\n\nvous souhaitez vous impliquer et prendre rapidement des responsabilites sur des missions a forte valeur ajoutee au sein dune structure dynamique.\n\n\nvous etes dote(e) dune capacite a travailler en equipe, dune ouverture desprit, dun sens de lanalyse et vous souhaitez rejoindre un environnement professionnel motivant ou vous partagerez nos valeurs que sont lexcellence, lentrepreneuriat, linnovation, la culture du partage, la bienveillance, lequilibre vie personnelle / vie professionnelle.\n\n\nfrancais, anglais professionnel courant indispensable.\n\n\n\n\ninformations supplementaires\n\npour plus d'information sur notre practice data science, consultez notre showroom de solutions ia : https://www.heka.ai/fr\n\n\net une video de presentation de nos \"ai services & solutions\" : https://www.youtube.com/watch?v=hbneoa9zhqy\n\n\nsia est un employeur qui souscrit au principe de legalite dacces a lemploi. tous les aspects de lemploi, tels que le recrutement, les promotions, la remuneration, ou les sanctions sont bases uniquement sur les performances, les competences, et le comportement des employes ou les besoins de lentreprise.",
  "company_name": "sia",
  "is_data_profile": true,
  "profile": "data scientist",
  "education_level": 3,
  "experience_years": 1,
  "seniority": "junior",
  "hard_skills": [
    "r",
    "python",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "teamwork",
    "analysis"
  ],
  "sector": [
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-analyst-intern-x-delivery-at-boston-consulting-group-bcg-4205211831",
  "titre": "data analyst intern - x delivery",
  "via": null,
  "contrat": "internship",
  "type_travail": null,
  "publication_date": "2025-04-22",
  "location": {
    "city": "casablanca",
    "region": "casablanca-settat",
    "country": "morocco",
    "remote": false
  },
  "description": "who we are\n\nwho we are boston consulting group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. bcg was the pioneer in business strategy when it was founded in 1963. today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.to succeed, organizations must blend digital and human capabilities. our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. bcg delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures-and business purpose. we work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\n\nwe are bcg x\n\nwere a diverse team of more than 3,000 tech experts united by a drive to make a difference. working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. we go beyond what was once thought possible, creating new and innovative solutions to the worlds most complex problems. leveraging bcgs global network and partnerships with leading organizations, bcg x provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. together, we strive to create solutions that will positively impact the lives of millions.\n\nwhat you'll do\n\nas a part of bcg x team you will work closely with consulting teams on a diverse range of advanced analytics topics. you will have the opportunity to leverage analytical methodologies, subject matter expertise, and accelerated execution to deliver value to bcg's consulting (case) teams and practice areas (domain). you will collaborate with case teams to gather requirements, specify, design, develop, deliver, and support analytics solutions serving client needs. you will provide technical support through deeper understanding of relevant data analytics tools and processes to build high quality and efficient solutions.\n\nwhat you'll bring\n\nworking with case (and proposal) team\n\n delivering original analysis and insights to case teams, typically owning all or part of an analytics module\n establishing credibility by thought partnering with case teams on analytics topics; drawing conclusions on a range of external and internal issues related to your module\n executing analytical approaches and creating defined outcomes; contributing to approach selection focussing on problem solving and client value aspects\n applying analytical, statistical and programming skills, building models, creating algorithms and using appropriate tools to discover knowledge from a variety of large and versatile data sources\n wrapping the outcomes of analysis into ready-to-use software modules / minimal viable products / dashboards\n training the project and client teams on advanced analytics approaches in general as well as on the use of tools and methodologies to increase the impact of their work\n communicating analytical insights through sophisticated synthesis and packaging of results (including ppt slides and charts)\n developing broad expertise in at least one analytics topic or platformthinking analytically:\n you should be strong in analytical solutioning with hands on experience in advanced delivery, through the entire life cycle of analytics. strong technical and statistical skills with the ability to develop and codify knowledge and provide analytical advice where required.\n\n\ntechnical skills (must have)\n\n overall fluency in either of python or r: ability to read, create, debug and package code, being comfortable using either of pycharm, r-studio, visual studio or any other ide\n sql scripting, ability to collect data from relational databases, e.g. postgresql, mysql, mssql etc.)\n data wrangling with python (pandas) or r\n hands on statistical inference using python, r as well as ms excel extensions\n experience in data visualization and presentation using either of tableau, powerbi, qlikview, dash, ...\n self-learning and quick ramping in previously unfamiliar technological stack if needed\n\n\ntechnical skills (good to have)\n\n experience in building scalable production ready dashboards and web applications using python or js frameworks e.g. either of django, flask, react, vue, angular etc.\n experience with proprietary low-code data wrangling, predictive analytics and modelling tools (either of alteryx, knime, dataiku, sas, spss etc.)\n experience with customer analytics, pricing optimization, predictive maintenance, supply chain optimization, network optimization, workforce allocation, smart manufacturing and related topics in a global organization or professional services is preferred\n experience in geoanalytics using python or specialized solutions is a plus\n first experience in simulation modelling and optimization approaches (operations research / linear programming / mixed integer programming)\n knowledge of dedicated optimization and simulation tools (aimms, llamasoft, gurobi, anylogic) is a plus\n programming and/or scripting experience a plus: sql, c#, perl, spark, vba\n experience with big data environments a plus: amazon redshift, hadoop/hive, teradata\n experience with collaboration tools & ticketing systems (e.g. jira, confluence, github) is preferred\n\n\nyou bring (experience & qualifications)\n\n bachelor's / master's degree related to computer science, data engineering, data science, statistics, mathematics, or economics is required\n previous internship experience in the domain of advanced analytics \n fluent written and spoken english (other languages desirable)\n\n\nwho you'll work with\n\nour business management and operations team members work to ensure that bcg is running smoothly, efficiently, and productively. we are made up of executive and administrative (or case team) assistants, visual service artists, receptionists, facilities staff, and the team leaders and office coordinators who manage these operations and business management jobs.\n\nboston consulting group is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\n\nbcg is an e - verify employer. click here  for more information on e-verify.",
  "company_name": "boston consulting group (bcg)",
  "is_data_profile": true,
  "profile": "data analyst",
  "education_level": 2,
  "experience_years": null,
  "seniority": "junior",
  "hard_skills": [
    "python",
    "r",
    "sql"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [
    "consulting"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
},
{
  "job_url": "https://www.linkedin.com/jobs/view/data-engineer-at-cnexia-4180000527",
  "titre": "data engineer",
  "via": null,
  "contrat": "full-time",
  "type_travail": null,
  "publication_date": "2025-03-12",
  "location": {
    "city": "fez",
    "region": null,
    "country": "morocco",
    "remote": false
  },
  "description": "joining cnexia is choosing to be part of an ambitious project that values innovation, promotes continuous learning and enables all tech champions to fulfill their creative dreams.\n\n\nat cnexia, we do more than support the clients of our world-class network and services. we develop innovative solutions and create original multiplatform media content. in fact, were revolutionizing how canadians communicate on the web, interact with mobile apps or benefit from an ai-enhanced experience.\n\n\nproud of our status as a fully owned moroccan subsidiary of the largest canadian telecom company, we have been ceaselessly growing our team since 2021. with over 1100 employees, mainly based in fez, we have expanded in the northern region of the kingdom with our brand-new state of the art site in technopolis rabat.\n\n\nif you are ready for this challenge, we invite you to join a community that values bold ideas and professional growth all in an engaging multi-cultural world-class environment.\n\n\nas a data engineer, your main responsibilities will be as follows:\n\n\n builds and optimizes data pipelines with defined service level objectives (slos).\n ensures code quality, maintainability, and documentation in data engineering.\n implements data governance practices, ensuring security, compliance, and integrity.\n enhances data processing efficiency through automation and performance tuning.\n conducts large-scale data analysis and automates data visualization reports.\n\n\n\n\nprofile main requirements (must have qualifications) :\n\n\n university or college degree in engineering, computer sciences, physic, mathematics or relevant experience in equivalent domain\n excellent communication skills in english\n minimum of +6 years experience as a data engineer\n strong experience with python/ sql / nosql, postresql / mongodb, apache kafka and spark, redhat openshift\n worked with data visualizaton, ai, ml & llm models, prometheus / grafana, elk stack\n docker & kubernetes, ci/cd pipelines, pandas, data encryption & acl\n shell scripting, ip networking\n\n\nnice to have:\n\n\n google cloud platform (gcp)\n linux / unix os\n vmware",
  "company_name": "cnexia",
  "is_data_profile": true,
  "profile": "data engineer",
  "education_level": 3,
  "experience_years": 6,
  "seniority": "senior",
  "hard_skills": [
    "python",
    "sql",
    "spark"
  ],
  "soft_skills": [
    "communication",
    "problem-solving",
    "teamwork"
  ],
  "sector": [
    "telecom",
    "it"
  ],
  "salary_range": {
    "min": null,
    "max": null,
    "currency": null,
    "period": null
  }
}
]
